\documentclass[compress,professionalfont]{beamer}
\mode<presentation>
\setbeamertemplate{navigation symbols}{}
\usetheme{Madrid}

% pdf is displayed in full screen mode automatically
\hypersetup{pdfpagemode=FullScreen}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}

\usepackage{graphics, graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{tikz,pgfplots}
\usepackage{pgfplots, epstopdf}
\usepackage{subfigure}
\usepackage{cmap}

\usepackage{ragged2e}

\definecolor{darkred}{RGB}{16,78,139}
\newcommand{\myStandartColoredItem}[1]{{\color{darkred}\bf{{#1}}}}

\titlegraphic{\includegraphics[width=2.5cm]{emblema.eps}}
\title[]{ПРИМЕНЕНИЕ МЕТОДОВ МАШИННОГО ОБУЧЕНИЯ ДЛЯ РЕШЕНИЯ ЗАДАЧИ ФИЛЬТРАЦИИ НЕЖЕЛАТЕЛЬНЫХ ДАННЫХ}
\author{
Выполнил студент группы ФН1-41М Разумов~Т.Е. \\
Научный руководитель профессор кафедры ФН1 Кувыркин~Г.Н.}
\institute[]{МГТУ им. Н.Э.~Баумана}
\date{21 июня 2021 г.}

\graphicspath{{images/}}


\begin{document}

%\justify

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[plain]
	\maketitle
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Актуальность проблемы}

\begin{center}
\includegraphics[width=0.45\textwidth]{actual1.jpg}
\includegraphics[width=0.45\textwidth]{actual2.jpg}
\includegraphics[width=0.45\textwidth]{actual3.jpg}
\includegraphics[width=0.45\textwidth]{actual4.jpg}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Постановка задачи}

В рамках работы требуется реализовать спам--фильтр для следующих продуктов Mail.Ru Group: почта, юла, мой мир, ответы, icq, пульс, агент. Ключевыми требованиями на фильтр являются:
\begin{itemize}
\item Высокая точность --- должно верно классифицироваться не менее 99\% писем.
\item Высокая отказоустойчивость --- сервис, осуществляющий запуск спам--фильтра, должен отвечать не менее чем на 99.99\% запросов.
\item Высокая производительность --- полный цикл проверки письма не должен быть дольше 3--х секунд.
\end{itemize}

Формально постановку задачи можно разбить на 4 этапа:
\begin{enumerate}
\item Предобработка письма.
\item Построение отображения текстовой информации в векторное пространство (векторизация).
\item Классификация объектов.
\item Разработка приложения, имеющего микросервисную архитектуру, для запуска системы на реальных пользователях.
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
Предобработка
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Предобработка}

Письмо в веб--интерфейсе
\begin{center}
\includegraphics[width=.9\textwidth]{eml.jpg}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Предобработка}

Сырое письмо
\begin{center}
\includegraphics[width=.9\textwidth]{eml_raw.jpg}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Предобработка}

\textbf{Текстовая информация}

Для извлечения информации из документов, имеющих текстовый формат, таких как docx, html, calendar и.т.д. реализованы собственные специализированные парсеры написанные на $C$++ и Golang

\textbf{Графическая информация}

Поскольку изображения и pdf не являются текстовыми форматами, то
для автоматического извлечения текста разработано два алгоритма машинного обучения на языке Python
\begin{itemize}
\item Модель сегментации и зондирования
\item Модель извлечения текста
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Предобработка}

После извлечения информации из всех вложений письма текст проходит через следующие этапы:
\begin{itemize}
\item Конкатенация всех частей с заданными разделителями.
\item Декодирование в заданную кодировку (utf8, cp1251) и приведение к одному регистру.
\item Удаление лишних пробелов, отступов и стоп--слов.
\item Нормализация:
\begin{enumerate}
\item Стемминг (``кошек'' $\rightarrow$ ``кош'').
\item Лемматизация (``кошек'' $\rightarrow$ ``кошка'').
\end{enumerate}
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
Векторизация
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Постановка задачи}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Мешок слов (bow)}

Каждому слову или словосочетанию (терму) ставится в соответствие некоторое число. В этом случае текст определяется вектором $\vec{w} = (w_1, ..., w_N)^T$,
где $N$ --- размерность из конечного словаря $X^l$ состоящего из уникальных термов обучающей выборки. \\
$w_i$ определяется как Булевский вес:
$$
w_i = \begin{cases}
1, & \mbox{если элемент присутствует в письме}, \\
0, & \mbox{если элемент не присутствует в письме}.
\end{cases}
$$

\begin{center}
\includegraphics[width=0.6\textwidth]{bow.png}
\end{center}

Основной проблемой bow--векторизации является потеря контекстной связи между словами и чрезмерно большое потребление памяти.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{word2vec}

Учитывая последовательность обучающих слов $w_1, w_2, w_3, ..., w_N$, требуется максимизировать среднюю логарифмическую вероятность
$$
\dfrac{1}{N}\sum_{i=1}^{N}\sum_{-c \leqslant j \leqslant c, j \neq 0} \ln p(w_{i+j}|w_i) \rightarrow \max,
$$
где $c$ --- размер обучающего контекста для слова $w_i$. Вероятность $p(w_O|w_I)$ нахождения слова $w_O$ в контексте со словом $w_I$ определяется через фукцию softmax
$$
p(w_O|w_I) = \dfrac{\exp({\vec{u}_{w_O}\cdot\vec{v}_{w_I}})}{\sum_{i=1}^{N} \exp({\vec{u}_{i} \cdot \vec{v}_{w_I}})},
$$
где $\vec{v}_{w_I}$ --- некий контекстный вектор для слова $w_I$, $\vec{u}_{w_O}$ --- word2vec представление слова $w_O$.

Cтоимость вычисления функции softmax пропорциональна $O(N)$, которое на практике является очень большим (порядка $10^6$--$10^9$).

%\begin{center}
%\includegraphics[width=0.25\textwidth]{skip_gram.png}
%\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Оптимизация word2vec}

Оптимизации заключается в том, что на основе словаря текста строится двоичное дерево Хаффмана
\begin{center}
\includegraphics[width=0.35\textwidth]{huffman.jpg}
\end{center}

Тогда выражение для вычисления вероятности $p(w_O|w_I)$ нахождения слова $w_O$ в контексте с $w_I$ имеет вид
$$
p(w_O|w_I) = \prod\limits_{j=1}^{L(w)-1} \sigma \Big(\delta_{n(w,j+1), n_l(w,j)} \vec{u}_{n(w,j)} \cdot \vec{v}_{w_I} \Big),
$$
где $L(w)$ --- расстояние от вершины до слова $w$, $n(w, j)$ --- узел дерева под номером $j$ на пути от вершины до слова $w$, $n_l(w,j)$ --- левый потомок для узла $n(w,j)$, $\sigma(x) = 1 / (1 + e^{-x})$, $\delta_{i,j}$ --- символ Кронекера.

Стоимость вычисления $O(\log_2 N)$.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
Классификация
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Постановка задачи}

Требуется построить отображение из $\mu^{*} : X =  \mathbb{R}^n \rightarrow Y = \{-1,+1\}$ по обучающей выборке $X^l = (\vec{x}_i, y_i)_{i=1}^l$, таким образом, что

$$
\mu^{*}\left(X^l\right) = \operatorname*{argmin}_{\mu \in A}  Q\left(\mu, X^l\right), \quad Q\left(\mu, X^l\right) = \dfrac{1}{l} \sum_{i=1}^{l} Z(a, x_i).
$$
где $X$ --- признаковое пространство векторизованных текстов, \\
$\mu$ --- решающая функция, $A$ --- множество решающих функций, \\
$Z$ --- функция потерь, характеризующая величину ошибки функции $\mu$ на объекте $\vec{x}$, $Q$ --- функция эмперического риска, \\
$Y$ --- множество допустимых ответов, \\
Для нашего случая $-1$ --- спам, $+1$ --- не спам. \\

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Вероятностная постановка задачи}

Минимизация функционала эмпирического риска эквивалетна задаче максимизации функции правдоподобия
$$
L(\vec{\theta}, X^l) = \prod\limits_{i=1}^l f(\vec{x}_i, y_i, \vec{\theta}) \rightarrow \max_{\vec{\theta}},
$$
$$
\ln L(\vec{\theta}, X^l) = \sum_{i=1}^{l} \ln f(\vec{x}_i, y_i, \vec{\theta}) \rightarrow \max_{\vec{\theta}},
$$
где $L$ --- функция правдоподобия, $X^l$ --- обучающая выборка, \\
$f(\vec{x}, y)$ --- совместная плотность распределения случайных величин $\vec{x}$~и~$y$,
$\vec{\theta}$ --- параметры решающей функции.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Логистическая регрессия}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Полносвязная нейронная сеть}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Сравнение моделей}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\begin{center}
Построение приложения и верификация модели
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Архитектура приложения}

\begin{center}
\includegraphics[width=.8\textwidth]{architecture.jpg}
\end{center}

k8s (kubernetes) --- открытое программное обеспечение для оркестровки контейнеризированных приложений и автоматизации их развертывания, масштабирования и координации в условиях кластера.

Redis --- резидентная система управления базами данных класса NoSQL с открытым исходным кодом, работающая со структурами данных типа ``ключ--значение''. Используется как для баз данных, так и для реализации кэшей, брокеров сообщений. Ориентирована на достижение максимальной производительности на атомарных операциях.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Графики}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Графики}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Заключение}

\begin{center}
Выводы
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
\frametitle{Заключение}

Публикации
\begin{center}

\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{Заключение}

\begin{center}
СПАСИБО ЗА ВНИМАНИЕ!
\end{center}

\end{frame}

\end{document}
