\documentclass[14pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[footnotes,oglav,spisok,boldsect,eqwhole,kursrab,remarks,hyperprint]{project}

\usepackage{hhline}
\usepackage{multirow}
\usepackage{anyfontsize}
\usepackage{t1enc}
\usepackage{cancel}
\usepackage{float}

\usepackage{extsizes}
\linespread{1.5}
\parindent=1.25cm

\usepackage{geometry}
\geometry{left=3cm, right=1cm, top=2cm, bottom=2cm}

\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}  

\usepackage{comment}

\usepackage{subcaption}
\renewcommand\thesubfigure{\asbuk{subfigure}}

\usepackage{xcolor}
\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}
\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}
\definecolor{ao}{rgb}{0.0, 0.0, 1.0}

\graphicspath{ {./images/} }

\begin{document}

\thispagestyle{empty}

\begin{minipage}{0.05\textwidth}
	\hspace{-1.4cm}\vspace{0.5cm}\includegraphics[scale=0.1]{emblema}
\end{minipage}
\hfill
\begin{minipage}{0.95\textwidth}
	\centering
	\linespread{1.0}
	\fontsize{11}{14pt}\selectfont
	\textbf{Министерство образования и науки Российской Федерации \\
	Федеральное государственное бюджетное образовательное учреждение\\высшего профессионального образования\\%
	<<Московский\ государственный\ технический\ университет\\ имени\ Н.\,Э.\,Баумана\\(национальный исследовательский университет)>>\\(МГТУ им. Н.\,Э.\,Баумана)}\\[3mm]
\end{minipage}
\hrule height .7mm

\bigskip

\noindentФАКУЛЬТЕТ <<Фундаментальные науки>> \\
КАФЕДРА <<Высшая математика>>

\bigskip

\begin{center}
	\begingroup
	\fontsize{20pt}{20pt}\selectfont
	\textbf{РАСЧЁТНО-ПОЯСНИТЕЛЬНАЯ ЗАПИСКА} \\ 
	\fontsize{16pt}{20pt}\selectfont
	\textbf{\textit{К~ВЫПУСКНОЙ~КВАЛИФИКАЦИОННОЙ~РАБОТЕ}}\\ 
	\textbf{\textit{НА ТЕМУ:}}
	
	\medskip
	\fontsize{16pt}{20pt}\selectfont 
	\textbf{\textit{
		\underline{ПРИМЕНЕНИЕ МЕТОДОВ МАШИННОГО} 
		\underline{ОБУЧЕНИЯ ДЛЯ РЕШЕНИЯ ЗАДАЧИ}
		\underline{ФИЛЬТРАЦИИ НЕЖЕЛАТЕЛЬНЫХ ДАННЫХ}
	}}
	\endgroup
\end{center}

\bigskip

\noindent
\begin{tabular}{lp{6em}cl}
Студент группы ФН1-41М & & \hspace{3.5cm} & Т.Е. Разумов\\ \cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Руководитель ВКР & & \hspace{3.5cm} & В.Ф. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Консультант & & \hspace{3.5cm} & О.В. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Нормоконтролер & & \hspace{3.5cm} & Н.С. Климова\\
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\
\end{tabular}

\vspace*{\fill}

\begin{center}
	2021 г.
\end{center}



\newpage
\section-{АННОТАЦИЯ}
В настоящей работе решается задача построения модели для обнаружения и фильтрации нежелательных спам--сообщений. В качестве модели классификатора нежелательных писем в электронной почте выбрана полносвязная свёрточная нейронная сеть (\textsf{FCNN}). Она позволяет разделить письма на две категории: \emph{спам} и \emph{не спам}. 

Основным результатом исследования является программное приложение на языке \textsf{C++}, имеющее микро--сервисную архитектуру, и решающее задачу классификации изображений. Приложение способно выдерживать более $10^6$ запросов в минуту в режиме реального времени.


\tableofcontents


\newpage
\section-{ВВЕДЕНИЕ}
В настоящее время, объемы производимой человечеством информации
увеличиваются в геометрической прогрессии. Значительную пользу из этой информации можно извлечь лишь при правильной обработке и анализе этих данных. 

С другой стороны, актуальной задачей обработки данных является задача
фильтрации нежелательных данных, а применительно к IT--технологиям --- это задача фильтрации спам--сообщений. Последнее связано с тем, что обмена информацией различной информации по умолчанию используется электронная почта. Электронная почта является одним из самых дешевых, простых в использовании, легкодоступных, наиболее официальных и надежных способов обмена информацией. 

Спам--сообщения, в общем случае могут содержать разнородную тестово--визуальную информацию. Алгоритмы глубокого обучения применяются для анализа спам--писем с различной информацией, поступающих в реальном времени, в \cite{Makkar2021}. При этом, сначала из изображения извлекаются признаки (характеристики), а затем происходит принятие решения. 


Среди других подходов классификации можно выделить, метод опорных векторов и метод случайного леса. В работе \cite{Taylor2020} приводится сравнение этих методов для решения задачи фильтрации спам--сообщений.

Алгоритмы фильтрации являются, как правило, стохастическими \cite{Garg2021} 
и применяются в комбинации с методами оптимизации некоторой целевой функции. 
Для решения задачи классификации электронной почты применяют различные вероятностные модели. Наиболее употребимой среди них является наивный байесовский классификатор. Метод роя частиц является одним из численных методов стохастической оптимизации, его применяют в задачах фильтрации данных, так как не требуется задавать аналитическое выражение градиента оптимизируемой функции. 
Метод роя частиц относится к методам стохастической оптимизации и применяется для эвристической глобальной оптимизации параметров наивного Байесовского классификатора. Комплексный подход с использованием наивного алгоритма Байеса вместе с методом оптимизации роя частиц применялся в \cite{Parmar2020}. 
Эволюционная модель классификации спама представлена в \cite{Mohammad2020}. 


{
\bf\color{amaranth}
Добавить абзацы про задачу и её решение настоящей статьи.
}


\newpage
\section{ОСНОВНЫЕ СВЕДЕНЬЯ ТЕОРИИ МАШИННОГО ОБУЧЕНИЯ}

\subsection{Объекты и признаки}

Пусть задано множество объектов $X$, множество допустимых ответов $Y$, и существует целевая функция (target function) $y^*:X \rightarrow Y$, значения которой $ y_i = y^*(x_i)$ известны только на конечном подмножестве объектов $\{x_1, \ldots, x_k\} \subset X$. Пары "объект-ответ" $(x_i, y_i)$ называются прецедентами. Совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ называется обучающей выборкой (training sample).

Задача обучения по прецедентам заключается в том, чтобы по выборке $X^l$ восстановить зависимость $y^*$, то есть построить решающую функцию (decision function) $a: X \rightarrow Y$, которая приближала бы целевую функцию $y^*(x)$, причём
не только на объектах обучающей выборки, но и на всём множестве X. Решающая функция $a$ должна допускать эффективную компьютерную реализацию, по этой причине её называют алгоритмом.

Признак (feature) $f$ объекта $x$ -- это результат измерения некоторой характеристики объекта. Формально признаком называется отображение $f: X \rightarrow D_f$, где $D_f$ -- множество допустимых значений признака. В частности, любой алгоритм $a: X \rightarrow Y$ также можно рассматривать как признак.

В зависимости от природы множества $D_f$ признаки делятся на несколько типов:

\begin{itemize}
  \item  Если $D_f = \{0,1\}$, то $f$ -- бинарный признак
  \item  Если $D_f$ -- конечное множество, то $f$ -- номинальный признак
  \item Если $D_f$ -- конечное упорядоченное множество, то $f$ -- порядковый признак
  \item Если $D_f = \mathbb{R}$, то $f$ -- количественный признак
\end{itemize}

Если все признаки имеют одинаковый тип, $D_{f_1} = \ldots = D_{f_n}$, то исходные данные называются однородными, в противном случае -- разнородными.

Пусть имеется набор признаков $f_1, \ldots , f_n$. Вектор $\big( f1(x), \ldots , fn(x) \big)$ называют признаковым описанием объекта $x \in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания, полагая $X = D_{f_1} \times \ldots \times D_{f_n}$. Совокупность признаковых описаний всех объектов выборки $X^l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов-признаков:

\begin{equation*}
F = \| f_j(x_i) \|_{l \times n} = \left(
\begin{array}{ccc}
f_1 (x_1) & \ldots & f_n (x_1)\\
\vdots & \ddots & \vdots\\
f_1 (x_l) & \ldots & f_n (x_l)
\end{array}
\right).
\end{equation*}

\subsection{Обучение и функционал качества}

Моделью алгоритмов называется параметрическое семейство отображений $A = \{g(x, \theta) | \theta \in \Theta \}$, где $g : X \times \Theta \rightarrow Y$ -- некоторая фиксированная функция,
$\Theta$ -- множество допустимых значений параметра $\theta$, называемое пространством параметров или пространством поиска (search space).

Процесс подбора оптимального параметра модели $\theta$ по обучающей выборке $X^l$ называют настройкой (fitting) или обучением (training, learning) алгоритма $a \in A$. Метод обучения (learning algorithm) -- это отображение $\mu: (X \times Y)^l \rightarrow A$, которое произвольной конечной выборке $X^l = (x_i, y_i)_{i=1}^l$ ставит в соответствие некоторый алгоритм $a \in A$. Метод обучения должен допускать эффективную программную реализацию.

Итак, в задачах обучения по прецедентам чётко различаются два этапа:
\begin{enumerate}
  \item На этапе обучения метод $\mu$ по выборке $X^l$
строит алгоритм $a = \mu(X^l)$
  \item На этапе применения алгоритм $a$ для новых объектов $x$ выдаёт ответы $y = a(x)$
\end{enumerate}

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров модели, доставляющих оптимальное значение заданному функционалу качества.

Функция потерь (loss function) -- это неотрицательная функция $Z(a, x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если $Z(a, x) = 0$, то ответ $a(x)$ называется корректным.

Функционал качества алгоритма $a$ на выборке $X^l$:

$$
Q(a, X^l) = \dfrac{1}{l} \sum_{i=1}^{l} Z(a, x_i).
$$

Функционал $Q$ называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным $(x_i, y_i)_{i=1}^l$.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели $A$ алгоритм $a$, доставляющий минимальное значение функционалу качества $Q$ на заданной обучающей выборке $X^l$:

$$
\mu(X^l) = \operatorname*{argmin}_{a \in A} Q(a, X^l).
$$

\subsection{Вероятностная постановка задачи обучения}

В задачах обучения по прецедентам элементы множества $X$ -- это не реальные объекты, а лишь доступные данные о них. Данные могут быть неточными, поскольку измерения значений признаков $f_j(x)$ и целевой зависимости $y^* (x)$ обычно выполняются с погрешностями. Данные могут быть неполными, поскольку измеряются не все мыслимые признаки, а лишь физически доступные для измерения. В результате одному и тому же описанию $x$ могут соответствовать различные объекты и различные ответы. В таком случае $y^* (x)$, строго говоря, не является функцией. Устранить эту некорректность позволяет вероятностная постановка задачи.

Вместо существования неизвестной целевой зависимости $y^* (x)$ предположим существование неизвестного вероятностного распределения на множестве $X \times Y$ с плотностью $p(x, y)$, из которого случайно и независимо выбираются $l$ наблюдений $X^l = (x_i, y_i)_{i=1}^l$. Такие выборки называются простыми или случайными одинаково распределёнными (independent identically distributed, i.i.d.).

Вероятностная постановка задачи считается более общей, так как функциональную зависимость $y^* (x)$ можно представить в виде вероятностного распределения $p(x, y) = p(x)p(y|x)$, положив $p(y|x) = \delta(y - y^* (x))$, где $\delta(z)$ -- дельта-функция.

При вероятностной постановке задачи вместо модели алгоритмов $g(x, \theta)$, аппроксимирующей неизвестную зависимость $y^* (x)$, задаётся модель совместной плотности распределения объектов и ответов $\varphi(x, y, \theta)$, аппроксимирующая неизвестную плотность $p(x, y)$. Затем определяется значение параметра $\theta$, при котором выборка данных $X^l$ максимально правдоподобна, то есть наилучшим образом согласуется с моделью плотности.

Если наблюдения в выборке $X^l$ независимы, то совместная плотность распределения всех наблюдений равна произведению плотностей $p(x, y)$ в каждом наблюдении: $p(X^l) = p \big( (x_1, y_1), \ldots,  (x_l, y_l) \big)$.  Подставляя вместо $p(x, y)$ модель плотности $\varphi(x, y, \theta)$, получаем функцию правдоподобия (likelihood):

$$
L(\theta, X^l) = \prod\limits_{i=1}^l \varphi(x_i, y_i, \theta).
$$

Чем выше значение правдоподобия, тем лучше выборка согласуется с моделью. Значит, нужно искать значение параметра $\theta$, при котором значение $L(\theta, X^l)$ максимально. После того, как значение параметра $\theta$ найдено, искомый алгоритм $a_\theta(x)$ строится по плотности $\varphi(x, y, \theta)$ несложно.

Вместо максимизации $L$ удобнее минимизировать функционал -- $\ln L$, поскольку он аддитивен по объектам выборки:
$$
-\ln L(\theta, X^l) = - \sum_{i=1}^{l} \ln \varphi(x_i, y_i, \theta) \rightarrow \min_{\theta}
$$

Этот функционал совпадает с функционалом эмпирического риска (...), если определить вероятностную функцию потерь $L(a_{\theta}, x) = -l \ln \varphi(x_i, y_i, \theta)$. Такое определение потери вполне естественно -- чем хуже пара $(x_i, y_i)$ согласуется с моделью $\varphi$, тем меньше значение плотности $\varphi(x_i, y_i, \theta)$ и выше величина потери $L(a_{\theta}, x)$.

Верно и обратное -- для многих функций потерь возможно подобрать модель плотности $\varphi(x, y, \theta)$ таким образом, чтобы минимизация эмпирического риска была эквивалентна максимизации правдоподобия.

Таким образом, существуют два родственных подхода к формализации задачи обучения: первый основан на введении функции потерь, второй — на введении вероятностной модели порождения данных. Оба в итоге приводят к схожим (иногда даже в точности одинаковым) оптимизационным задачам.

\subsection{Проблема переобучения}

Минимизацию эмпирического риска следует применять с известной долей осторожнсти. Если минимум функционала $Q(a, X^l)$ достигается на алгоритме $a$, то это ещё не гарантирует, что $a$ будет хорошо приближать целевую зависимость на произвольной контрольной выборке $X^k = (x'_i, y'_i)_{i=1}^k$.

Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте переобучения (overtraining) или переподгонки (overfitting). При решении практических задач с этим явлением приходится сталкиваться очень часто.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{overfitting.png}
	\caption{Пример переобучения нейронной сети}
	\label{fig:02}
\end{figure}

Легко представить себе метод, который минимизирует эмпирический риск до нуля, но при этом абсолютно не способен обучаться. Получив обучающую выборку $X^l$, он запоминает её и строит алгоритм, который сравнивает предъявляемый объект $x$ с обучающими объектами $x_i$ из $X^l$. В случае совпадения $x = x_i$ алгоритм выдаёт правильный ответ $y_i$. Иначе выдаётся произвольный ответ. Эмпирический риск принимает наименьшее возможное значение, равное нулю. Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

Обобщающая способность (generalization ability) метода $\mu$ характеризуется величиной $Q(\mu(X^l), X^k)$ при условии, что выборки $X^l$ и $X^k$ являются представительными. Для формализации понятия "представительная выборка" обычно принимается стандартное предположение, что выборки $X^l$ и $X^k$ -- простые, полученные из одного и того же неизвестного вероятностного распределения на множестве $X$.

Метод обучения $\mu$ называется состоятельным, если при заданных достаточно малых значениях $\varepsilon$ и $\eta$ справедливо неравенство

$$
P_{X^l, X^k} \big\{ Q(\mu(X^l), X^k  > \varepsilon \big\} < \eta.
$$

Параметр $\varepsilon$ называется точностью, параметр $(1 - \eta)$ -- надёжностью.

Получение оценок вида (...) является фундаментальной проблемой статистической теории обучения. Первые оценки были получены в конце 60-х годов В. Н. Вапником и А. Я. Червоненкисом. В настоящее время статистическая  теория развивается очень активно, однако для многих практически интересных случаев оценки обобщающей способности либо неизвестны, либо сильно завышены.

Эмпирические оценки обобщающей способности применяются в тех случаях,
когда не удаётся воспользоваться теоретическими.


Пусть дана выборка $X^L = (x_i, y_i)_{i=1}^L$. Разобьём её $N$ различными способами на две непересекающиеся подвыборки -- обучающую $X_n^l$ длины $l$ и контрольную $X_n^k$ длины $k = L - l$. Для каждого разбиения $n = 1,\ldots,N$ построим алгоритм $a_n = \mu(X_n^l)$ и вычислим значение $Q_n = Q(a_n, X_n^k)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называется оценкой скользящего контроля (cross validation, CV):

$$
CV(\mu, X^L) =  \dfrac{1}{N} \sum_{i=1}^{N} Q(\mu(X_n^l), X_n^k).
$$

Возможны различные варианты скользящего контроля, отличающиеся способами разбиения выборки $X^L$. В простейшем варианте разбиения генерируются случайным образом, число $N$ берётся в диапазоне от 20 до 100. Стандартом считается методика $(t \times q)$-кратного скользящего контроля,
когда выборка случайным образом разбивается на $q$ блоков равной (или почти равной) длины, каждый блок по очереди становится контрольной выборкой, а объединение всех остальных блоков -- обучающей. Выборка $X^L$ по-разному $t$ раз разбивается на $q$ блоков. Итого получается $N = tq$ разбиений. Данная методика даёт более точные
оценки за счёт того, что все объекты ровно по $t$ раз встречаются в контроле.

Недостатками скользящего контроля являются: вычислительная неэффективность, высокая дисперсия, неполное использование имеющихся данных для обучения из-за сокращения длины обучающей выборки с $L$ до $l$.


\newpage
\section{ПОСТАНОВКА ЗАДАЧИ}

\subsection{Естественная постановка}

\subsection{Математическая постановка}

Пусть задано некоторое множество объектов $X = X_L \cup X_T $, где 
$X_L$ --- обучающая выборка, 
$X_T$ --- тестовая выборка, 
$Y$ --- множество допустимых ответов. Считаем, что существует некоторая целевая функция $g: X \rightarrow Y$, значения которой известны только на множестве $X_L$. Пусть данные распределены в соответствии с некоторым неизвестным распределением $P(x,y) = P(x) P(y|x)$, при этом задана некоторая функция потерь
$$
R(g(x), y) = 
\begin{cases} 
\phantom{>}0, & y = g(x), \\
> 0, & y \neq g(x).
\end{cases}
$$

В соответствии с принципом минимизации эмпирического риска 
{\bf\color{amaranth} (что за принцип?)} нам надо минимизировать функцию потерь, то есть найти такую решающую функцию $g(x)$, которая в среднем будет приводить к наименьшей погрешности. Формально, требуется решить следующую задачу минимизации
$$
g(x) = \operatorname*{argmin}_{f: X \rightarrow Y} E_{X,Y} R(f(x), y).
$$

Для задачи фильтрации нежелательных данных множество $Y$ состоит из двух элементов $\{0, 1\}$, где $0$ и $1$ желательные и нежелательные данные соответственно. В силу грубости методов дискретных вычислений, на практике обычно используется $Y = R[0, 1]$, а результат работы классификатора $y' = g(x)$ {\bf\color{amaranth} (почему стоит штрих?)} отноcится к нужному классу с заданной пороговой вероятностью $\alpha$, минимизирующей ошибку первого и второго рода.


От момента получения сообщения до момента принятия решения о его типе, вся информация из письма проходит через несколько этапов обработки:

\begin{enumerate}
\item Предобработка.
\item Векторизация.
\item Классификация.
\end{enumerate}


\newpage
\section{ПРЕДОБРАБОТКА ДАННЫХ}

Поскольку текст имеет сильно неоднородную структуру и при этом одно слово может быть записано множеством разных способов (разный шрифт, кодировка, регистр итд), но при этом иметь тот же смысл, то применяются различные методы предобработки текста или их комбинация.

Первым шагом текст производится парсинг и декодирование текста в заданную кодировку. Затем приведение к нижнему (или верхнему) регистру, удаление лишних пробелов, отступов. Производится замена символов по заданному правилу. После этого применяются следующие методы:

\subsection{Stop words}

Текст часто содержит много символов, которые не несут смысловой нагрузки для общего смысла (два пробела, абзацный отступ), а также стоп слова (stop words).
Стоп слова -- это слова на любом языке, которые не добавляют особого смысла предложению. 	Часто к стоп словам относят знаки пунктуации, местоимения и предлоги. Часто спамеры используют их для зашумления текстов с целью скрыть спам контент сообщения. Так как их можно спокойно игнорировать, не жертвуя смыслом предложения, то в задачах классификации часто прибегают к их удалению из исходного сообщения.

\subsection{Стемминг и лемматизация}

Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Используя разные алгоритмы лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме.


Стемминг -- это грубый эвристический процесс, который отрезает "лишнее" от корня слов, часто это приводит к потере словообразовательных суффиксов. Основная проблема, возникающая при использовании стеммера -- это обработка слов, которые при образовании разных грамматических форм меняют не только окончание, но и основу слова. Например, существительное "кошка" в винительном и родительном падеже множественного числа имеет форму "кошек". Из-за таких беглых гласных стеммер должен либо игнорировать подобные формы, усекая "кошки" до "кошк" и теряя часть форм слова, либо усекать слово до безусловно неизменяющейся основы, получая "кош", что впоследствии может привести к полной потере контекста. Чтобы минимизировать негативные последствия слишком агрессивного усечения слов стеммером, необходимо выполнять стемминг искомого ключевого слова, а затем сравнивать результат с выходом стеммера для каждого из слов в обрабатываемом тексте. Но даже в этом случае буду встречаться совпадения стемов для совершенно несвязанных слов.


Лемматизация -- это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме (лемме). Однако он применяет упрощенный анализ слов, не учитывая контекст. Это приводит к неоднозначностям при определении части речи. Например, лемматизация слов в словосочетании "мы роем яму" даст для второго слова два варианта лемматизации: существительное рой и глагол рыть. Эта неоднозначность не может быть разрешена без привлечения морфологического анализатора.

Как правило лемматизация дает наиболее точные результаты и именно этот подход используется в работе.


\newpage
\section{ВЕКТОРИЗАЦИЯ ДАННЫХ}

Современные алгоримы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо построить отображение текста в векторное пространство. Это называется извлечением признаков. Рассмотрим несколько подходов для построения данного отображения.

\subsection{Мешок слов}

Модель "мешок слов" - это упрощенное представления текстовой информации, используемое в задачах обработки естественных языков и поиска информации. В этой модели текст представляется в виде мешка (мультимножества) его слов или словосочетаний в случае комбинаций термов, игнорируя грамматику и в некоторых случаях даже порядок слов, но сохраняя множественность. Каждому такому терму (слову или словосочетанию) ставится в соответствие некоторое число. В этом случае текст определяется вектором $x=(x_1, ..., x_N)^T$, где $N$ - размерность из конечного словаря $X_L$ состоящего из уникальных термов обучающей выборки. Возможны следующие варинаты определения $x_i$
\begin{itemize}
\item Булевский вес: $\begin{cases} 1, & \mbox{если элемент присутствует в письме} \\ 0, & \mbox{если элемент не присутствует в письме}  \end{cases}$
\item Количество вхождений i-го терма в тексте: $x_i = n_i$
\item Частота терма: $x_i = \dfrac{n_i}{\sum n_k}$
\end{itemize}

В данной работе для определения $x_i$ мы взяли частоту терма.


\subsection{Word2Vec}

Основной проблемой BOW является потеря контекста между словами. Поскольку в естественном языке перестановка даже двух слов предложения  может полностью изменить его смысл, то данный подход к классификации может иметь низкую точность.

Word2Vec иструмент векториции текста с учетом контекстной связи между словами. В основе алгоритма лежат такие методы как huffman binary tree, skip-gram, negative sampling. Основной проблемой Word2Vec является поиск контекста для редких слов.

\textbf{Skip-gram}

Цель обучения модели Skip-gram -- найти представления слов, которые полезны для предсказания окружающих слов в предложении или документе. Более формально: учитывая последовательность обучающих слов $w_1, w_2, w_3, ..., w_T$, требуется максимизировать среднюю логарифмическую вероятность

$$
\dfrac{1}{T}\sum_{t=1}^{T}\sum_{-c \leqslant j \leqslant c, j \neq 0} \log p(w_{t+j}|w_t) \rightarrow \max,
$$

где $c$ - размер обучающего контекста для слова $w_t$. Вероятность близости слов $p(w_O|w_I)$ определяется через фукцию softmax

$$
p(w_O|w_I) = \dfrac{\exp({\vec{v}_{w_O}\cdot\vec{v}_{w_I}})}{}
$$

\subsection{Fast Text}

FastText --- это расширение Word2Vec, предложенное Facebook в 2016 году. Вместо ввода отдельных слов в нейронную сеть, FastText разбивает слова на несколько n-грамм (подслов). Например, триграммы для слова "apple"  ---  это "app", "ppl" и "ple" (без учета начала и конца границ слов). Вектор для слова "apple" образуется при помощи суммы всех n-грамм. После обучения нейронной сети у нас будут эмбединги слов для всех n-грамм из обучающего набора данных.

С помощью данного подхода алгоритм становится более чувствительным к редким словам так как весьма вероятно, что некоторые из их n-грамм также присутствуют в других словах. Для обучения модели FastText требуется больше времени, но она работает лучше, чем Word2Vec, и позволяет правильно представлять редкие слова.


\newpage
\section{КЛАССИФИКАЦИЯ ДАННЫХ}

После векторизации текста мы должны построить преобразование из множества признаков во множество классифицируемых объектов $g: X \rightarrow Y$ 

Согласно статье [twitter threshold p. 4.6] была произведена разметка уникальных точек по бинам и вычеслена оптимальная пороговая точность $\alpha = 0.75$, которая обеспечивает оптимальный pressision и recall для нашей модели и минимизует дисперсию ошибки.

\subsection{Логистическая регрессия}
Наиболее частым методом используемым в задаче классификации используется метод логистической регрессии:
$$
g(x) = \left(1 + \exp{ \left( \sum_{i=0}^n w_i x_i  \right) }\right)^{-1},
$$
где $w=(w_1, ..., w_N)^T$ --- веса модели, полученные при обучении.

Приведем результаты расчетов для разных способов векторизации текста.

Для BOW эмбедингов мы имеем следующие результаты:
\begin{center}
  \begin{tabular}{ | c | c |}
    \hline
     precision & recall \\ \hline
     0.91143 & 0.99961 \\ \hline
  \end{tabular}
\end{center}


Для Fast Text эмбедингов мы имеем следующие результаты:
\begin{center}
  \begin{tabular}{ | c | c |}
    \hline
     precision & recall \\ \hline
     0.95523 & 0.89164  \\ \hline
  \end{tabular}
\end{center}

\subsection{Fully convolutional neural network}

Fully convolutional neural network для нашей задачи имеет 3 слоя. На первых двух используется функция активации $ReLU$, на последнем $Sigmoid$. На каждом слое производится регуляризация данных. В нашем случае нейронную сеть можно определить формулой:

$$
g(x) = h_2 \left(\sum_{k=0}^{n_2} w''_k h_1\left(\sum_{j=0}^{n_1} w'_j h_0\left( \sum_{i=0}^{n_0} w_i x_i \right)\right)\right),
$$

где $h_i$ -- функция активации для соответствующего слоя. Для нахождения весов $\{w_i\}$, $\{w'_j\}$, $\{w''_k\}$ на этапе обучения модели используется метод Адама.

Для BOW эмбедингов мы имеем следующие результаты:
\begin{center}
  \begin{tabular}{ | c | c |}
    \hline
     precision & recall \\ \hline
     0.93604 & 0.95643 \\ \hline
  \end{tabular}
\end{center}

Для Fast Text эмбедингов мы имеем следующие результаты:
\begin{center}
  \begin{tabular}{ | c | c |}
    \hline
     precision & recall \\ \hline
     0.99931 & 0.91263 \\ \hline
  \end{tabular}
\end{center}


\newpage
\section{ПОСТРОЕНИЕ МИКРОСЕРВИСНОЙ АРХИТЕКТУРЫ}

\subsection{Обзор библиотек}

Поскольку от сервисов требуется высокая производительность, то для его написания выбран язык C++ (stl17, grpc, boost), как один из самых производительных современных языков. Для анализа данных и обучения fcnn модели использовался язык Python3 и фреймврок pyTorch за счет высокой эффективности и возможности проведения параллельных вычислений, как на cpu, так и на gpu ядрах машины.

Отказоустойчивость микросервисов обеспечивается за счет их развертки в kubernetes (k8s) кластере, так как при падении любого пода по какой-либо причине запросы равномерно сбалансируются по оставшимся живым подам, до тех пор, пока кластер самостоятельно не вернется к прежнему состоянию. Внутри него можно настроить: автоматическую балансировку нагрузки с помощью постоянного мониторинга сведений о производительности и используемых ресурсах (autoscaling) и грамотное размещение подов внутри кластера по дата центрам (affinity).

\subsection{Построение архитектуры приложения}

Поскольку сервис должен работать под высокими нагрузками важно обеспечить архитектуру, при которой выход из строя одной компоненты не приведет к деградации всей системы. Реализована следующая клиент-серверная архитектура (рис. 1). Antispam daemon (mrasd) парсит входящие сообщение и извлекает оттуда текст, изображения, файлы.  Поскольку нежелательные данные часто содержатся внутри вложенных изображений и документов, то из них также необходимо извлечь текст. Для этого через отложенную redis очередь документы оправляются в OCR сервис, который извлекает текст и сохраняет результат в redis cache.

Так как, с большой вероятностью письмо может быть дубликатом (например в случае ddos атаки или оффлайн перепроверки), то чтобы не нагрузать лишний раз OCR сервис, производится первичная проверка redis cache на наличие уже обработанных данных по заданному хэшу документа.

После полного извлечения текста сервис mrasd производит все этапы предобработки текста (приведение к одному регистру, удаление стоп слов, нормализация), а затем отправляет текст в сервис mlapi по протоколу grpc для векторизации текста при помощи fast text и дальнейшего получения предсказания fcnn модели по котому принимается решение о "нежелательности"  входящего сообщения.

Предложенная архитектура хороша тем, что при выходе из строя OCR сериса, одного (или нескольких) инстансов redis сluster, не деградирует вся система в целом.
 
\begin{figure}[h!]
	\center
	\includegraphics[scale=0.25]{deploy.jpg}
	\caption{Deploy}
	\label{fig:02}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{timings.png}
	\caption{Среднее время обработки письма}
	\label{fig:03}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{processed_messages.png}
	\caption{Среднее количество запросов в минуту с одной из ферм}
	\label{fig:04}
\end{figure}


\newpage
\section-{ЗАКЛЮЧЕНИЕ}

В данной статье приведены результаты, полученные в ходе обучения модели на реальных потоковых данных пользователей. По приведенным данным можно сделать заключение о том, что $FCNN$ модель на основе $Fast Text$ эмбедингов имеет наивысшую точность классификации, по сравнению с методами классической логистической регрессии и $FCNN$ модели на основе мешка слов.


Приведена высокопризводительная отказоустойчивая микросервисная архитектура, которая выдерживает в среднем более $10^6$ запросов в минуту. При этом деградация конкретной компоненты, машины или датацентра не приводит к полной неработоспособности приложения.


\newpage
\begin{thebibliography}{17}
\bibitem{Makkar2021} 
Aaisha Makkar, Uttam Ghosh, Pradip Kumar Sharma.
2021. \emph{Artificial Intelligence and Edge Computing-enabled
	Web Spam Detection for Next Generation IoT
	Applications} // IEEE Sensors Journal

\bibitem{Taylor2020}
Taylor O.E., Ezekiel P.S.
2020. \emph{A Model to Detect Spam Email Using Support Vector Classifier and Random Forest Classifier} //
International Journal of Computer Science and Mathematical Theory

\bibitem{Garg2021}
Pranjul Garg, Nancy Girdhar.
2021. \emph{A systematic review on spam filtering techniques based on
natural language processing framework} // 2021 11th International Conference on Cloud Computing, Data Science \& Engineering (Confluence 2021)

\bibitem{Parmar2020}
Nandan Parmar, Ankita Sharma, Harshita Jain, Amol K. Kadam.
2020. \emph{Email Spam Detection using Na?ve Bayes and Particle Swarm Optimization} // IJIRT

\bibitem{Mohammad2020}
Rami Mustafa A. Mohammad.
2020. \emph{A lifelong spam emails 	classification model} //
Applied Computing and Informatics

\end{thebibliography}

\end{document}