\documentclass[14pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[footnotes,oglav,spisok,boldsect,eqwhole,kursrab,remarks,hyperprint]{project}

\usepackage{hhline}
\usepackage{multirow}
\usepackage{anyfontsize}
\usepackage{t1enc}
\usepackage{cancel}
\usepackage{float}

\usepackage{extsizes}
\linespread{1.5}
\parindent=1.25cm

\usepackage{geometry}
\geometry{left=3cm, right=1cm, top=2cm, bottom=2cm}

\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}  

\usepackage{comment}

\usepackage{subcaption}
\renewcommand\thesubfigure{\asbuk{subfigure}}

\usepackage{xcolor}
\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}
\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}
\definecolor{ao}{rgb}{0.0, 0.0, 1.0}

\graphicspath{ {./images/} }

\begin{document}

\thispagestyle{empty}

\begin{minipage}{0.05\textwidth}
	\hspace{-1.4cm}\vspace{0.5cm}\includegraphics[scale=0.1]{emblema}
\end{minipage}
\hfill
\begin{minipage}{0.95\textwidth}
	\centering
	\linespread{1.0}
	\fontsize{11}{14pt}\selectfont
	\textbf{Министерство образования и науки Российской Федерации \\
	Федеральное государственное бюджетное образовательное учреждение\\высшего профессионального образования\\%
	<<Московский\ государственный\ технический\ университет\\ имени\ Н.\,Э.\,Баумана\\(национальный исследовательский университет)>>\\(МГТУ им. Н.\,Э.\,Баумана)}\\[3mm]
\end{minipage}
\hrule height .7mm

\bigskip

\noindentФАКУЛЬТЕТ <<Фундаментальные науки>> \\
КАФЕДРА <<Высшая математика>>

\bigskip

\begin{center}
	\begingroup
	\fontsize{20pt}{20pt}\selectfont
	\textbf{РАСЧЁТНО-ПОЯСНИТЕЛЬНАЯ ЗАПИСКА} \\ 
	\fontsize{16pt}{20pt}\selectfont
	\textbf{\textit{К~ВЫПУСКНОЙ~КВАЛИФИКАЦИОННОЙ~РАБОТЕ}}\\ 
	\textbf{\textit{НА ТЕМУ:}}
	
	\medskip
	\fontsize{16pt}{20pt}\selectfont 
	\textbf{\textit{
		\underline{ПРИМЕНЕНИЕ МЕТОДОВ МАШИННОГО} 
		\underline{ОБУЧЕНИЯ ДЛЯ РЕШЕНИЯ ЗАДАЧИ}
		\underline{ФИЛЬТРАЦИИ НЕЖЕЛАТЕЛЬНЫХ ДАННЫХ}
	}}
	\endgroup
\end{center}

\bigskip

\noindent
\begin{tabular}{lp{6em}cl}
Студент группы ФН1-41М & & \hspace{3.5cm} & Т.Е. Разумов\\ \cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Руководитель ВКР & & \hspace{3.5cm} & В.Ф. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Консультант & & \hspace{3.5cm} & О.В. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Нормоконтролер & & \hspace{3.5cm} & Н.И. Сидняев\\
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\
\end{tabular}

\vspace*{\fill}

\begin{center}
	2021 г.
\end{center}



\newpage
\section-{АННОТАЦИЯ}

В настоящей работе решается задача построения модели для обнаружения и фильтрации нежелательных спам-сообщений. В качестве модели классификатора нежелательных писем в электронной почте выбрана полносвязная свёрточная нейронная сеть (\textsf{FCNN}). Она позволяет разделить письма на две категории: \emph{спам} и \emph{не спам}. 

Основным результатом исследования является программное приложение на языке \textsf{C++}, имеющее микро-сервисную архитектуру, и решающее задачу классификации писем. Приложение способно выдерживать более $10^6$ запросов в минуту в режиме реального времени.


\tableofcontents


\newpage
\section-{ВВЕДЕНИЕ}

В настоящее время, объемы производимой человечеством информации
увеличиваются в геометрической прогрессии. Значительную пользу из этой информации можно извлечь лишь при правильной обработке и анализе этих данных. 

С другой стороны, актуальной задачей обработки данных является задача
фильтрации нежелательных данных, а применительно к IT-технологиям --- это задача фильтрации спам-сообщений. Последнее связано с тем, что обмена информацией различной информации по умолчанию используется электронная почта. Электронная почта является одним из самых дешевых, простых в использовании, легкодоступных, наиболее официальных и надежных способов обмена информацией. 

Спам-сообщения, в общем случае могут содержать разнородную тестово-визуальную информацию. Алгоритмы глубокого обучения применяются для анализа спам-писем с различной информацией, поступающих в реальном времени, в \cite{Makkar2021}. При этом, сначала из изображения извлекаются признаки (характеристики), а затем происходит принятие решения. 


Среди других подходов классификации можно выделить, метод опорных векторов и метод случайного леса. В работе \cite{Taylor2020} приводится сравнение этих методов для решения задачи фильтрации спам-сообщений.

Алгоритмы фильтрации являются, как правило, стохастическими \cite{Garg2021} 
и применяются в комбинации с методами оптимизации некоторой целевой функции. 
Для решения задачи классификации электронной почты применяют различные вероятностные модели. Наиболее употребимой среди них является наивный байесовский классификатор. Метод роя частиц является одним из численных методов стохастической оптимизации, его применяют в задачах фильтрации данных, так как не требуется задавать аналитическое выражение градиента оптимизируемой функции. 
Метод роя частиц относится к методам стохастической оптимизации и применяется для эвристической глобальной оптимизации параметров наивного Байесовского классификатора. Комплексный подход с использованием наивного алгоритма Байеса вместе с методом оптимизации роя частиц применялся в \cite{Parmar2020}. 
Эволюционная модель классификации спама представлена в \cite{Mohammad2020}. 


{
\bf\color{amaranth}
Добавить абзацы про задачу и её решение настоящей статьи.
}


\newpage
\section{ОСНОВНЫЕ СВЕДЕНИЯ}

\subsection{Объекты и признаки}

Пусть задано множество объектов $X$, множество допустимых ответов $Y$, и существует целевая функция (target function) $y^*:X \rightarrow Y$, значения которой $ y_i = y^*(x_i)$ известны только на конечном подмножестве объектов $\{x_1, \ldots, x_k\} \subset X$. Пары "объект-ответ" $(x_i, y_i)$ называются прецедентами. Совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ называется обучающей выборкой (training sample).

Задача обучения по прецедентам заключается в том, чтобы по выборке $X^l$ восстановить зависимость $y^*$, то есть построить решающую функцию (decision function) $a: X \rightarrow Y$, которая приближала бы целевую функцию $y^*(x)$, причём
не только на объектах обучающей выборки, но и на всём множестве X. Решающая функция $a$ должна допускать эффективную компьютерную реализацию, по этой причине её называют алгоритмом.

Признак (feature) $f$ объекта $x$ --- это результат измерения некоторой характеристики объекта. Формально признаком называется отображение $f: X \rightarrow D_f$, где $D_f$ --- множество допустимых значений признака. В частности, любой алгоритм $a: X \rightarrow Y$ также можно рассматривать как признак.

В зависимости от природы множества $D_f$ признаки делятся на несколько типов:

\begin{itemize}
  \item  Если $D_f = \{0,1\}$, то $f$ --- бинарный признак
  \item  Если $D_f$ --- конечное множество, то $f$ --- номинальный признак
  \item Если $D_f$ --- конечное упорядоченное множество, то $f$ --- порядковый признак
  \item Если $D_f = \mathbb{R}$, то $f$ --- количественный признак
\end{itemize}

Если все признаки имеют одинаковый тип, $D_{f_1} = \ldots = D_{f_n}$, то исходные данные называются однородными, в противном случае --- разнородными.

Пусть имеется набор признаков $f_1, \ldots , f_n$. Вектор $\big( f1(x), \ldots , fn(x) \big)$ называют признаковым описанием объекта $x \in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания, полагая $X = D_{f_1} \times \ldots \times D_{f_n}$. Совокупность признаковых описаний всех объектов выборки $X^l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов-признаков:

\begin{equation*}
F = \| f_j(x_i) \|_{l \times n} = \left(
\begin{array}{ccc}
f_1 (x_1) & \ldots & f_n (x_1)\\
\vdots & \ddots & \vdots\\
f_1 (x_l) & \ldots & f_n (x_l)
\end{array}
\right).
\end{equation*}

\subsection{Обучение и функционал качества}

Моделью алгоритмов называется параметрическое семейство отображений $A = \{g(x, \theta) | \theta \in \Theta \}$, где $g : X \times \Theta \rightarrow Y$ --- некоторая фиксированная функция,
$\Theta$ --- множество допустимых значений параметра $\theta$, называемое пространством параметров или пространством поиска (search space).

Процесс подбора оптимального параметра модели $\theta$ по обучающей выборке $X^l$ называют настройкой (fitting) или обучением (training, learning) алгоритма $a \in A$. Метод обучения (learning algorithm) --- это отображение $\mu: (X \times Y)^l \rightarrow A$, которое произвольной конечной выборке $X^l = (x_i, y_i)_{i=1}^l$ ставит в соответствие некоторый алгоритм $a \in A$. Метод обучения должен допускать эффективную программную реализацию.

Итак, в задачах обучения по прецедентам чётко различаются два этапа:
\begin{enumerate}
  \item На этапе обучения метод $\mu$ по выборке $X^l$
строит алгоритм $a = \mu(X^l)$
  \item На этапе применения алгоритм $a$ для новых объектов $x$ выдаёт ответы $y = a(x)$
\end{enumerate}

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров модели, доставляющих оптимальное значение заданному функционалу качества.

Функция потерь (loss function) --- это неотрицательная функция $Z(a, x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если $Z(a, x) = 0$, то ответ $a(x)$ называется корректным.

Функционал качества алгоритма $a$ на выборке $X^l$:

$$
Q(a, X^l) = \dfrac{1}{l} \sum_{i=1}^{l} Z(a, x_i).
$$
Функционал $Q$ называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным $(x_i, y_i)_{i=1}^l$.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели $A$ алгоритм $a$, доставляющий минимальное значение функционалу качества $Q$ на заданной обучающей выборке $X^l$:

$$
\mu(X^l) = \operatorname*{argmin}_{a \in A} Q(a, X^l).
$$

\subsection{Вероятностная постановка задачи обучения}

В задачах обучения по прецедентам элементы множества $X$ --- это не реальные объекты, а лишь доступные данные о них. Данные могут быть неточными, поскольку измерения значений признаков $f_j(x)$ и целевой зависимости $y^* (x)$ обычно выполняются с погрешностями. Данные могут быть неполными, поскольку измеряются не все мыслимые признаки, а лишь физически доступные для измерения. В результате одному и тому же описанию $x$ могут соответствовать различные объекты и различные ответы. В таком случае $y^* (x)$, строго говоря, не является функцией. Устранить эту некорректность позволяет вероятностная постановка задачи.

Вместо существования неизвестной целевой зависимости $y^* (x)$ предположим существование неизвестного вероятностного распределения на множестве $X \times Y$ с плотностью $p(x, y)$, из которого случайно и независимо выбираются $l$ наблюдений $X^l = (x_i, y_i)_{i=1}^l$. Такие выборки называются простыми или случайными одинаково распределёнными (independent identically distributed, i.i.d.).

Вероятностная постановка задачи считается более общей, так как функциональную зависимость $y^* (x)$ можно представить в виде вероятностного распределения $p(x, y) = p(x)p(y|x)$, положив $p(y|x) = \delta(y - y^* (x))$, где $\delta(z)$ --- дельта-функция.

При вероятностной постановке задачи вместо модели алгоритмов $g(x, \theta)$, аппроксимирующей неизвестную зависимость $y^* (x)$, задаётся модель совместной плотности распределения объектов и ответов $\varphi(x, y, \theta)$, аппроксимирующая неизвестную плотность $p(x, y)$. Затем определяется значение параметра $\theta$, при котором выборка данных $X^l$ максимально правдоподобна, то есть наилучшим образом согласуется с моделью плотности.

Если наблюдения в выборке $X^l$ независимы, то совместная плотность распределения всех наблюдений равна произведению плотностей $p(x, y)$ в каждом наблюдении: $p(X^l) = p \big( (x_1, y_1), \ldots,  (x_l, y_l) \big)$.  Подставляя вместо $p(x, y)$ модель плотности $\varphi(x, y, \theta)$, получаем функцию правдоподобия (likelihood):

$$
L(\theta, X^l) = \prod\limits_{i=1}^l \varphi(x_i, y_i, \theta).
$$

Чем выше значение правдоподобия, тем лучше выборка согласуется с моделью. Значит, нужно искать значение параметра $\theta$, при котором значение $L(\theta, X^l)$ максимально. После того, как значение параметра $\theta$ найдено, искомый алгоритм $a_\theta(x)$ строится по плотности $\varphi(x, y, \theta)$ несложно.

Вместо максимизации $L$ удобнее минимизировать функционал --- $\ln L$, поскольку он аддитивен по объектам выборки:
$$
-\ln L(\theta, X^l) = - \sum_{i=1}^{l} \ln \varphi(x_i, y_i, \theta) \rightarrow \min_{\theta}
$$

Этот функционал совпадает с функционалом эмпирического риска (...), если определить вероятностную функцию потерь $L(a_{\theta}, x) = -l \ln \varphi(x_i, y_i, \theta)$. Такое определение потери вполне естественно --- чем хуже пара $(x_i, y_i)$ согласуется с моделью $\varphi$, тем меньше значение плотности $\varphi(x_i, y_i, \theta)$ и выше величина потери $L(a_{\theta}, x)$.

Верно и обратное --- для многих функций потерь возможно подобрать модель плотности $\varphi(x, y, \theta)$ таким образом, чтобы минимизация эмпирического риска была эквивалентна максимизации правдоподобия.

Таким образом, существуют два родственных подхода к формализации задачи обучения: первый основан на введении функции потерь, второй — на введении вероятностной модели порождения данных. Оба в итоге приводят к схожим (иногда даже в точности одинаковым) оптимизационным задачам.

\subsection{Метрики качества обучения}

\subsection{Проблема переобучения}

Минимизацию эмпирического риска следует применять с известной долей осторожнсти. Если минимум функционала $Q(a, X^l)$ достигается на алгоритме $a$, то это ещё не гарантирует, что $a$ будет хорошо приближать целевую зависимость на произвольной контрольной выборке $X^k = (x'_i, y'_i)_{i=1}^k$.

Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте переобучения (overtraining) или переподгонки (overfitting). При решении практических задач с этим явлением приходится сталкиваться очень часто.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.8]{overfitting.png}
	\caption{Пример переобучения нейронной сети}
	\label{fig:01}
\end{figure}

Легко представить себе метод, который минимизирует эмпирический риск до нуля, но при этом абсолютно не способен обучаться. Получив обучающую выборку $X^l$, он запоминает её и строит алгоритм, который сравнивает предъявляемый объект $x$ с обучающими объектами $x_i$ из $X^l$. В случае совпадения $x = x_i$ алгоритм выдаёт правильный ответ $y_i$. Иначе выдаётся произвольный ответ. Эмпирический риск принимает наименьшее возможное значение, равное нулю. Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

Обобщающая способность (generalization ability) метода $\mu$ характеризуется величиной $Q(\mu(X^l), X^k)$ при условии, что выборки $X^l$ и $X^k$ являются представительными. Для формализации понятия "представительная выборка" обычно принимается стандартное предположение, что выборки $X^l$ и $X^k$ --- простые, полученные из одного и того же неизвестного вероятностного распределения на множестве $X$.

Метод обучения $\mu$ называется состоятельным, если при заданных достаточно малых значениях $\varepsilon$ и $\eta$ справедливо неравенство

$$
P_{X^l, X^k} \big\{ Q(\mu(X^l), X^k  > \varepsilon \big\} < \eta.
$$
Параметр $\varepsilon$ называется точностью, параметр $(1 - \eta)$ --- надёжностью.

Получение оценок вида (...) является фундаментальной проблемой статистической теории обучения. Первые оценки были получены в конце 60-х годов В. Н. Вапником и А. Я. Червоненкисом. В настоящее время статистическая  теория развивается очень активно, однако для многих практически интересных случаев оценки обобщающей способности либо неизвестны, либо сильно завышены.

Эмпирические оценки обобщающей способности применяются в тех случаях,
когда не удаётся воспользоваться теоретическими.


Пусть дана выборка $X^L = (x_i, y_i)_{i=1}^L$. Разобьём её $N$ различными способами на две непересекающиеся подвыборки --- обучающую $X_n^l$ длины $l$ и контрольную $X_n^k$ длины $k = L - l$. Для каждого разбиения $n = 1,\ldots,N$ построим алгоритм $a_n = \mu(X_n^l)$ и вычислим значение $Q_n = Q(a_n, X_n^k)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называется оценкой скользящего контроля (cross validation, CV):

$$
CV(\mu, X^L) =  \dfrac{1}{N} \sum_{i=1}^{N} Q(\mu(X_n^l), X_n^k).
$$

Возможны различные варианты скользящего контроля, отличающиеся способами разбиения выборки $X^L$. В простейшем варианте разбиения генерируются случайным образом, число $N$ берётся в диапазоне от 20 до 100. Стандартом считается методика $(t \times q)$-кратного скользящего контроля,
когда выборка случайным образом разбивается на $q$ блоков равной (или почти равной) длины, каждый блок по очереди становится контрольной выборкой, а объединение всех остальных блоков --- обучающей. Выборка $X^L$ по-разному $t$ раз разбивается на $q$ блоков. Итого получается $N = tq$ разбиений. Данная методика даёт более точные
оценки за счёт того, что все объекты ровно по $t$ раз встречаются в контроле.

Недостатками скользящего контроля являются: вычислительная неэффективность, высокая дисперсия, неполное использование имеющихся данных для обучения из-за сокращения длины обучающей выборки с $L$ до $l$.


\newpage
\section{ПОСТАНОВКА ЗАДАЧИ}

\subsection{Естественная постановка}

\subsection{Математическая постановка}

Пусть задано некоторое множество объектов $X = X_L \cup X_T $, где 
$X_L$ --- обучающая выборка, 
$X_T$ --- тестовая выборка, 
$Y$ --- множество допустимых ответов. Считаем, что существует некоторая целевая функция $g: X \rightarrow Y$, значения которой известны только на множестве $X_L$. Пусть данные распределены в соответствии с некоторым неизвестным распределением $P(x,y) = P(x) P(y|x)$, при этом задана некоторая функция потерь
$$
R(g(x), y) = 
\begin{cases} 
\phantom{>}0, & y = g(x), \\
> 0, & y \neq g(x).
\end{cases}
$$

В соответствии с принципом минимизации эмпирического риска нам надо минимизировать функцию потерь, то есть найти такую решающую функцию $g(x)$, которая в среднем будет приводить к наименьшей погрешности. Формально, требуется решить следующую задачу минимизации
$$
g(x) = \operatorname*{argmin}_{f: X \rightarrow Y} E_{X,Y} R(f(x), y).
$$

Для задачи фильтрации нежелательных данных множество $Y$ состоит из двух элементов $\{0, 1\}$, где $0$ и $1$ желательные и нежелательные данные соответственно. В силу грубости методов дискретных вычислений, на практике обычно используется $Y = R[0, 1]$, а результат работы классификатора $y' = g(x)$ отноcится к нужному классу с заданной пороговой вероятностью $\alpha$, минимизирующей ошибку первого и второго рода.


От момента получения сообщения до момента принятия решения о его типе, вся информация из письма проходит через несколько этапов обработки:

\begin{enumerate}
\item Предобработка.
\item Векторизация.
\item Классификация.
\end{enumerate}


\newpage
\section{ПРЕДОБРАБОТКА ДАННЫХ}

\subsection{Струкртура письма}

Содержимое письма очень сильно отличается от того, что видит пользователь в веб интерфейсе (рис. ). Оно содержит очень много служебных заголовков, которые не несут никакого смысла для анализа (рис. ).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml.jpg}
	\caption{Письмо в веб интерфейсе}
	\label{fig:01}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml_raw.jpg}
	\caption{Сырое письмо}
	\label{fig:01}
\end{figure}

В первую очередь требуется валидировать ту инфрмацию, которую видит пользователь, поэтому для нас представляют интерес только заголовки subject (тема письма) и body (содержимое письма). При этом body делится на несколько частей (партов). Каждый парт может иметь абсолютно любой тип: текст, изображения, pdf, docx, html, calenar, итд. Каждый из этих типов нуждается в индивидуальной обработке. Для определения типа используется вложенный заголовок Content-Type.

Поскольку письмо имеет сильно неоднородную структуру (служебные заголовки, вложеные документы различных форматов) и при этом одно слово может быть записано множеством разных способов (разный шрифт, кодировка, регистр итд), но при этом иметь тот же смысл, то применяется множество различных методов предобработки.

\subsection{Извлечение данных}

\subsubsection{Текстовый формат}
Для извлечения информации из документов имеющих текстовый формат, таких как docx, html, calendar используются собственные специализированные парсеры написанные на C++. Они производят декодирование и ивлекают только нужную информацию, удаляя из текста тэги и служебные символы. Пример html страницы изображен на (рис. )

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{html.jpg}
	\caption{Пример DOM дерева HTML}
	\label{fig:01}
\end{figure}

\subsubsection{Изображения и PDF}

Поскольку изображения и PDF не являются текстовыми форматами, то для извлечения текста необходимо использовать машинное обучение. Так как извлечения текста из многих сырых изображений имеет низкое качество, то было разработано две модели на языке Python с использованием фреймворка PyTorch. 

Первая модель отвечает за разметку и сегментацию изображения. Благодяря ей улучшается качество распознавания и увеличивается производительность, за счет того, что мы не пытаемся извлечь текст из тех фрагментов изображения, где его нет (рис. ).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{segmentation.png}
	\caption{Пример сегментации изображения}
	\label{fig:01}
\end{figure}

Вторая модель реализована на основе полносвязной нейронной сети, которая возвращает вектор вероятностей по заданному фрагменту изображения. С её помощью извлекается весь текст из изображения (рис. ).

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{fcnn_img.jpg}
	\caption{Архитектура полносвязной нейронной сети для изображений}
	\label{fig:01}
\end{figure}

Для обработки PDF используется известная библиотека poppler. Она конвектирует PDF в несколько изображения, которые далее отправляются в модели сегментации и извлечения текста.

\subsection{Конкатенация и удаление стоп слов}

После извлечения текста из всех документов производится конкатенация всех его частей с заданными разделителями и декодирование в заданную кодировку. Затем приведение к нижнему регистру, удаление лишних пробелов, отступов. 

Текст часто содержит много символов, которые не несут смысловой нагрузки для общего смысла (два пробела, абзацный отступ), а также стоп слова (stop words).
Стоп слова --- это слова, которые не добавляют особого смысла предложению. К стоп словам относят знаки пунктуации, местоимения и предлоги. Часто спамеры используют их для зашумления текстов с целью скрыть спам контент сообщения. Так как их можно спокойно игнорировать, не жертвуя смыслом предложения, то в задачах классификации часто прибегают к их удалению из исходного сообщения.

\subsection{Нормализация}

Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Используя разные алгоритмы лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме.


Стемминг --- это грубый эвристический процесс, который отрезает "лишнее" от корня слов, часто это приводит к потере словообразовательных суффиксов. Основная проблема, возникающая при использовании стеммера --- это обработка слов, которые при образовании разных грамматических форм меняют не только окончание, но и основу слова. Например, существительное "кошка" в винительном и родительном падеже множественного числа имеет форму "кошек". Из-за таких беглых гласных стеммер должен либо игнорировать подобные формы, усекая "кошки" до "кошк" и теряя часть форм слова, либо усекать слово до безусловно неизменяющейся основы, получая "кош", что впоследствии может привести к полной потере контекста. Чтобы минимизировать негативные последствия слишком агрессивного усечения слов стеммером, необходимо выполнять стемминг искомого ключевого слова, а затем сравнивать результат с выходом стеммера для каждого из слов в обрабатываемом тексте. Но даже в этом случае буду встречаться совпадения стемов для совершенно несвязанных слов.


Лемматизация --- это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме (лемме). Однако он применяет упрощенный анализ слов, не учитывая контекст. Это приводит к неоднозначностям при определении части речи. Например, лемматизация слов в словосочетании "мы роем яму" даст для второго слова два варианта лемматизации: существительное рой и глагол рыть. Эта неоднозначность не может быть разрешена без привлечения морфологического анализатора.

Как правило лемматизация дает наиболее точные результаты и именно этот подход используется в работе.


\newpage
\section{ВЕКТОРИЗАЦИЯ ДАННЫХ}

Современные алгоримы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо построить отображение текста в векторное пространство. Это называется извлечением признаков. Рассмотрим несколько подходов для построения данного отображения.

\subsection{Мешок слов}

Модель мешока слов (BOW) --- это упрощенное представления текстовой информации, используемое в задачах обработки естественных языков и поиска информации. В этой модели текст представляется в виде мешка (мультимножества) его слов или словосочетаний в случае комбинаций термов, игнорируя грамматику и в некоторых случаях даже порядок слов, но сохраняя множественность. Каждому такому терму (слову или словосочетанию) ставится в соответствие некоторое число. В этом случае текст определяется вектором $x=(w_1, ..., w_N)^T$, где $N$ - размерность из конечного словаря $X_L$ состоящего из уникальных термов обучающей выборки (рис. ).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{bow_ex.jpg}
	\caption{Векторизация при помощи мешка слов}
	\label{fig:01}
\end{figure}

Возможны следующие варинаты определения $w_i$
\begin{itemize}
\item Булевский вес: $\begin{cases} 1, & \mbox{если элемент присутствует в письме} \\ 0, & \mbox{если элемент не присутствует в письме}  \end{cases}$
\item Количество вхождений i-го терма в тексте: $w_i = n_i$
\item Частота терма: $w_i = \dfrac{n_i}{\sum_{j=1}^{N} n_j}$
\end{itemize}
В данной работе для определения $w_i$ взят булевский вес.


\subsection{Word2Vec}

Основной проблемой BOW является потеря контекста между словами. Поскольку в естественном языке перестановка даже двух слов предложения  может полностью изменить его смысл, то данный подход к классификации может иметь низкую точность.

Word2Vec иструмент векториции текста с учетом контекстной связи между словами. В основе алгоритма лежат такие методы как huffman binary tree, skip-gram. Основной проблемой Word2Vec является поиск контекста для редких слов.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{skip_gram.png}
	\caption{Принцип работы skip-gram модели}
	\label{fig:01}
\end{figure}

Цель обучения модели word2Vec это поиск skip-gram, то есть нахождение представления слов, которые полезны для предсказания окружающих слов в письме. Более формально: учитывая последовательность обучающих слов $w_1, w_2, w_3, ..., w_N$, требуется максимизировать среднюю логарифмическую вероятность

$$
\dfrac{1}{N}\sum_{i=1}^{N}\sum_{-c \leqslant j \leqslant c, j \neq 0} \ln p(w_{i+j}|w_i) \rightarrow \max,
$$
где $c$ --- размер обучающего контекста для слова $w_i$. Вероятность $p(w_O|w_I)$ нахождения слова $w_O$ в контексте со словом $w_I$ определяется через фукцию softmax

$$
p(w_O|w_I) = \dfrac{\exp({\vec{u}_{w_O}\cdot\vec{v}_{w_I}})}{\sum_{i=1}^{N} \exp({\vec{u}_{i} \cdot \vec{v}_{w_I}})},
$$
где $\vec{v}_{w_I}$ --- некий контекстный вектор для слова $w_I$, $\vec{u}_{w_O}$ --- word2vec представление слова $w_O$.

Поскольку стоимость вычисления (p ...) пропорциональна $O(N)$, которое на практике является очень большим (порядка $10^6$-$10^9$), что вызывает очень много вычислительных затрат и времени, то обычно вместо (p ...), используют иерархический softmax. В контексте языковых моделей нейронных сетей он был впервые представлен Морином и Бенжио [..]. Основное преимущество заключается в том, что вместо оценки $N$ выходных узлов в нейронной сети для получения
распределения вероятностей, можно оценить только около $\log_2 N$ узлов.

Идея оптимизации заключается в том, что на основе словаря текста строится двоичное дерево. В каждом листе дерева закодированно слово. Обозначим расстояние от вершины (root) до слова $w$ как $L(w)$. Узел дерева под номером $j$ на пути от вершины до слова $w$ как $n(w, j)$, при этом $n(w, 1) = $ root и $n(w, L(w)) = w$. Пусть $n_l(w,j)$ --- левый потомок для узла $n(w,j)$. Тогда выражение для вычисления вероятности $p(w_O|w_I)$ нахождения слова $w_O$ в контексте с $w_I$ имеет вид:
$$
p(w_O|w_I) = \prod\limits_{j=1}^{L(w)-1} \sigma \Big(\delta_{n(w,j+1), n_l(w,j)} \vec{u}_{n(w,j)} \cdot \vec{v}_{w_I} \Big),
$$ 
где $\sigma(x) = 1 / (1 + e^{-x})$, $\delta_{i,j}$ --- символ Кронекера.

Структура дерева, используемая иерархическим softmax, оказывает значительное влияние на производительность. Мних и Хинтон исследовали ряд методов построения древовидной структуры и влияние как на время обучения, так и на точность получаемой модели [...]. В этой работе используется двоичное
дерево Хаффмана, так как оно присваивает короткие коды частым словам, что приводит к более быстрому обучению.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{huffman.jpg}
	\caption{Бинарное дерево Хаффмана}
	\label{fig:01}
\end{figure}

Натренированная модель word2vec может улавливать некоторые семантические и синтаксические свойства слов, несмотря на то, что в модель явно не  заложено никакой семантики. Слово "мужчина" (man) относится к слову женщина (woman), также, как слово "дядя"(uncle) к слову "тётя"(aunt). Для человека это естественно и понятно, но в других ситуациях моделям добиться такого же соотношения векторов можно только с помощью специальных ухищрений.

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{word2vec.jpg}
	\caption{Семантическая близость слов в word2vec модели}
	\label{fig:01}
\end{figure}

\subsection{Fast Text}

FastText --- это расширение Word2Vec, предложенное Facebook в 2016 году. Вместо ввода отдельных слов в нейронную сеть, FastText разбивает слова на несколько n-грамм (подслов). Например, триграммы для слова "apple"  ---  это "app", "ppl" и "ple" (без учета начала и конца границ слов). Вектор для слова "apple" образуется при помощи суммы всех n-грамм. После обучения нейронной сети у нас будут эмбединги слов для всех n-грамм из обучающего набора данных.

С помощью данного подхода алгоритм становится более чувствительным к редким словам, так как весьма вероятно, что некоторые из их n-грамм также присутствуют в других словах. Для обучения модели FastText требуется больше времени, но она работает лучше, чем Word2Vec, и позволяет правильно представлять редкие слова.


\newpage
\section{КЛАССИФИКАЦИЯ ДАННЫХ}

После векторизации текста мы должны построить преобразование из множества признаков во множество классифицируемых объектов $g: X \rightarrow Y$ 

Согласно статье [twitter threshold p. 4.6] была произведена разметка уникальных точек по бинам и вычеслена оптимальная пороговая точность $\alpha = 0.75$, которая обеспечивает оптимальный pressision и recall для нашей модели и минимизует дисперсию ошибки.

\subsection{Логистическая регрессия}

\subsubsection{Описание работы алгоритма}

Метод логистической регрессии основан на довольно сильных вероятностных предположениях, которые имеют сразу несколько интересных последствий. Во-первых, линейный алгоритм классификации оказывается оптимальным байесовским
классификатором. Во-вторых, однозначно определяется функция потерь. В-третьих,
возникает интересная дополнительная возможность наряду с классификацией объекта получать численные оценки вероятности его принадлежности каждому из классов.


В нормальном дискриминантном анализе доказывается, что если плотности классов нормальны и имеют равные матрицы ковариации, то оптимальный байесовский классификатор линеен. Покажем, что классификатор остается линейным при менее жестких предположениях.

Пусть классов два, $Y = \{-1,+1\}$, объекты описываются $n$ числовыми признаками $f_j : X \to R, j = 1, \ldots,n$. Будем полагать $X = R^n$, отождествляя объекты с их признаковыми описаниями: $x \equiv (f_1(x), \ldots, f_n(x))$.

\textbf{Гипотеза 1.} Множество прецедентов $X \times Y$ является вероятностным пространством. Выборка прецедентов $X^l = (x_i, y_i)^l_{i=1}$ получена случайно и независимо согласно вероятностному распределению с плотностью $p(x,y) = P_y p_y(x) = P(y|x)p(x)$, где $P_y$ --- априорные вероятности, $p_y(x)$ --- функции правдоподобия, $P(y|x)$ --- апостериорные вероятности классов $y \in Y$ .

Плотность распределения $p(x)$, $x \in \mathbb{R}^n$ называется экспонентной, если $p(x) = \exp(c(\delta) \langle \theta, x\rangle + b(\delta, \theta) + d(x, \delta)$, где параметр $\theta \in \mathbb{R}^n$ называется сдвигом, параметр $\delta$ называется разбросом, $b, c, d$ — произвольные числовые функции. Класс экспонентных распределений очень широк. К нему относятся многие непрерывные и дискретные распределения: равномерное, нормальное, гипергеометрическое, пуассоновское, биномиальное, Г-распределение, и другие.

\textbf{Гипотеза 2.} Если функции правдоподобия классов $p_y(x)$ принадлежат экспонентному семейству плотностей, то они имеют равные значения параметров $d$ и $\delta$, но отличаются значениями параметра сдвига $\theta_y$.

Оптимальный байесовский классификатор имеет вид 
$$
a(x) = \operatorname*{argmax}_{y \in Y} \lambda_y P(y|x),
$$
где $\lambda_y$ — штраф за ошибку на объектах класса $y$.
В случае двух классов
$$
a(x) = \operatorname*{sign}(\lambda_+ P(+1|x) - \lambda_-P(-1|x)) = \operatorname*{sign} \Big( \dfrac{P(+1|x) }{P(-1|x) } - \dfrac{\lambda_-}{\lambda_+} \Big).
$$
Если справедливы гипотезы 1, 2 и среди признаков $f_1(x), \ldots , f_n(x)$ есть константа, то:

{\bf\color{amaranth} дописать про разделяющую плоскость}

\begin{itemize}
\item  Байесовский классификатор является линейным: 
$$
a(x) = \operatorname*{sign} (\langle w, x\rangle - w_0),
$$
где $w_0 = \ln(\lambda_-/\lambda_+)$, а вектор $w$ не зависит от штрафов $\lambda_-, \lambda_+$

\item Апостериорная вероятность принадлежности произвольного объекта $x \in X$ классу $y \in \{-1, +1\}$ может быть вычислена по значению дискриминантной функции: 
$$
P(y|x) = \sigma (\langle w, x\rangle y),
$$
где $ \sigma(z) = \dfrac{1}{1+ e^{-z}}$ — сигмоидная функция

\end{itemize}


\subsubsection{Результаты расчетов}

Для BOW и Fast Text эмбедингов мы имеем следующие метрики классификации:
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
               & precision & recall \\ \hline
     BOW       & 0.91143 & 0.99961 \\ \hline
     Fast Text & 0.95523 & 0.89164  \\ \hline
  \end{tabular}
\end{center}

\subsection{Искусственная нейронная сеть}

\subsubsection{Вычислительные возможности нейронных сетей}

Человеку и высшим животным буквально на каждом шагу приходится распознавать, принимать решения и обучаться. Нейросетевой подход возник из стремления
понять, каким образом мозг решает столь сложные задачи, и реализовать эти принципы в автоматических устройствах. Пока искусственные нейронные сети (artificial neural networks, ANN) являются лишь предельно упрощёнными аналогами естественных нейронных сетей. Нервные системы животных и человека гораздо сложнее тех устройств, которые можно создать с помощью современных технологий. Однако для успешного решения многих практических задач оказалось вполне достаточно "подсмотреть" лишь общие принципы функционирования нервной системы. Некоторые разновидности ANN представляют собой математические модели, имеющие лишь отдалённое сходство с нейрофизиологией, что отнюдь не препятствует их практическому применению.

Итак, отдельно взятый нейрон вида (...) позволяет реализовать линейный классификатор или линейную регрессию. При решении практических задач линейность
оказывается чрезмерно сильным ограничением. На ограниченность персептрона указывали Минский и Пайперт в своей знаменитой книге "Персептроны" [54].

Следующие факты показывают, что любую функцию можно аппроксимировать с помощью нейронной сети.

\begin{enumerate}
\item Любая булева функция представима в виде двухслойной сети. Это тривиальное следствие нейронной представимости функций И, ИЛИ, НЕ и представимости
произвольной булевой функции в виде дизъюнктивной нормальной формы [...].
\item Из простых геометрических соображений вытекает, что двухслойная сеть
с пороговыми функциями активации позволяет выделить произвольный выпуклый
многогранник в $n$-мерном пространстве признаков. Трёхслойная сеть позволяет вычислить любую конечную линейную комбинацию характеристических функций выпуклых многогранников, следовательно, аппроксимировать любые области с непрерывной границей, включая невыпуклые и даже неодносвязные, а также аппроксимировать любые непрерывные функции.
\item В 1900 году Гильберт предложил список из 23 нерешённых задач, которые,
по его мнению, должны были стать вызовом для математиков XX века. Тринадцатая проблема заключалась в следующем: возможно ли произвольную непрерывную
функцию n аргументов представить в виде суперпозиции функций меньшего числа
аргументов. Ответ был дан А. Н. Колмогоровым в [14]. Теорема Колмогорова утверждает, что любая непрерывная функция $n$ аргументов на единичном кубе $[0, 1]^n$ представима в виде суперпозиции непрерывных функций одного аргумента и операции сложения:

$$
f(x_1, \ldots, x_n) = \sum_{k=1}^{2n+1} h_k \left(\sum_{i=1}^{n} \varphi_{i,k}(x_i) \right),
$$
где $h_k$, $\varphi_{i,k}$ --- непрерывные функции, причём $\varphi_{i,k}$ не зависят от выбора $f$. Нетрудно видеть, что записанное здесь выражение имеет структуру нейронной сети с одним скрытым слоем из $2n + 1$ нейронов. Таким образом, двух слоёв уже
достаточно, чтобы вычислять произвольные непрерывные функции, и не приближённо, а точно. К сожалению, представление Колмогорова не является персептроном:
функции $\varphi_{i,k}$ не линейны, а функции $h_k$ зависят от $f$, и в общем случае не являются
дифференцируемыми.

\item Известна классическая теорема Вейерштрасса о том, что любую непрерывную функцию $n$ переменных можно равномерно приблизить полиномом с любой степенью точности. Более общая теорема Стоуна утверждает, что любую непрерывную
функцию на произвольном компакте $X$ можно приблизить не только многочленом
от исходных переменных, но и многочленом от любого конечного набора функций $F$,
разделяющих точки [.....].

\end{enumerate}


Таким образом, нейронные сети являются универсальными аппроксиматорами
функций. Возможности сети возрастают с увеличением числа слоёв и числа нейронов в них. Двух-трёх слоёв, как правило, достаточно для решения подавляющего
большинства практических задач классификации, регрессии и прогнозирования.

\subsubsection{Метод обратного распространения ошибки}

Рассмотрим многослойную сеть, в который каждый нейрон предыдущего слоя
связан со всеми нейронами последующего слоя (рис. ...). Такая сеть называется полносвязной. Для большей общности положим $X = \mathbb{R}^n, Y = \mathbb{R}^M$.

Пусть выходной слой состоит из $M$ нейронов с функциями активации $\sigma_m$ и выходами $a^m, m=1,\ldots,M$. Перед ним находится скрытый слой из $H$ нейронов с функциями активации $\sigma_h$ и выходами $u^h, h=1,\ldots,H$.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.55]{fcnn_ex.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:01}
\end{figure}

Веса синаптических связей между $h$-м нейроном скрытого слоя и $m$-м нейроном выходного слоя будем обозначать через $w_{h,m}$. Перед этим слоем может находиться либо входной слой признаков (называемый также распределительным слоем), либо ещё один скрытый слой с выходами $v^j, j = 1,\ldots, J$ и синаптическими весами $w_{j,h}$. В общем случае число слоёв может быть произвольным. Если сеть двухслойная, то $v^j$
есть просто $j$-й признак: $v^j(x) = f_j(x) = x^j$ и, $J = n$. Обозначим через $w$ вектор всех синаптических весов сети. 

Выходные значения сети на объекте $x_i$ вычисляются как суперпозиция:

$$
a^m(x_i) = \sigma_m \left( \sum_{h=0}^{H} w_{h,m} u^h(x_i) \right),
\quad
u^h(x_i) = \sigma_h \left( \sum_{j=0}^{J} w_{j,h} u^j(x_i) \right).
$$

Зафиксируем объект $x_i$ и запишем функционал среднеквадратичной ошибки
(для других функций потерь выкладки могут быть проделаны аналогично):

$$
Q(w) = \frac{1}{2} \sum_{m=1}^{M} (a^m(x_i) - y_i^m)^2.
$$

В дальнейшем нам понадобятся частные производные Q по выходам нейронов.
Выпишем их сначала для выходного слоя

$$
\dfrac{\partial Q}{\partial a^m} = a^m(x_i) - y_i^m = \varepsilon_i^m,
$$
Из данного выражения видно, что частная производная $Q$ по $a^m$ равна величине ошибки $\varepsilon_i^m$ на объекте $x_i$. Теперь выпишем частные производные по выходам скрытого слоя
$$
\dfrac{\partial Q}{\partial u^h} = \sum_{m=1}^{M} (a^m(x_i) - y_i^m) \sigma'_m w_{h,m} = \sum_{m=1}^{M} \varepsilon_i^m \sigma'_m w_{h,m} = \varepsilon_i^h.
$$

Эту величину, по аналогии с $\varepsilon_i^m$, будем называть ошибкой сети на скрытом слое и обозначать через $\varepsilon_i^h$. Через $\sigma'_m$ обозначена производная функции активации,
вычисленная при том же значении аргумента, что и в (...). Если используется сигмоидная функция активации, то для эффективного вычисления производной можно
воспользоваться формулой
$$
\sigma'_m = \sigma_m (1 - \sigma_m) = a^m(x_i) (1 - a^m(x_i)).
$$

Стоит заметить, что $\varepsilon_i^h$ вычисляется по $\varepsilon_i^m$, если запустить сеть "задом наперёд", подав на выходы нейронов скрытого слоя значения $\varepsilon_i^m \sigma'_m$, а результат $\varepsilon_i^h$ получив на входе. При этом входной вектор скалярно умножается на вектор весов $w_{hm}$, находящихся справа от нейрона, а не слева, как при прямом вычислении (рис.), отсюда и название алгоритма --- обратное распространение ошибок.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.7]{backpropagation.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:01}
\end{figure}

Имея частные производные по $a^m$ и $u^h$, можно выписать градиент $Q$ по весам:
\begin{align*}
 & \dfrac{\partial Q}{\partial w_{h,m}} = \dfrac{\partial Q}{\partial a^m} \dfrac{\partial a^m}{\partial w_{h,m}} = \varepsilon_i^m \sigma'_m u^h(x_i), \quad m=1,\ldots,M, \quad h=0,\ldots,H;\\
 & \dfrac{\partial Q}{\partial w_{j,h}} = \dfrac{\partial Q}{\partial u^h} \dfrac{\partial u^h}{\partial w_{j,h}} = \varepsilon_i^h \sigma'_h u^j(x_i), \quad h=1,\ldots,H, \quad j=0,\ldots,J;
\end{align*}
и так далее для каждого слоя. Если слоёв больше двух, то остальные частные производные вычисляются аналогично --- обратным ходом по слоям сети справа налево. 

Теперь мы обладаем всем необходимым, чтобы полностью выписать алгоритм обратного распространения


К достоинствам метода обратного распространения можно отнести следующие свойства

\begin{itemize}
  \item   Достаточно высокая эффективность. В случае двухслойной сети прямой ход, обратный ход и вычисления градиента требуют порядка $O(Hn+HM)$ операций.
  \item   Через каждый нейрон проходит информация только о связных с ним нейронах. Поэтому back-propagation легко реализуется на вычислительных устройствах с параллельной архитектурой
  \item  Высокая степень общности. Алгоритм легко записать для произвольного числа слоёв, произвольной размерности выходов и выходов, произвольной функции потерь и произвольных функций активации, возможно, различных у разных нейронов. Кроме того, back-propagation можно применять совместно с различными градиентными методами оптимизации: методом скорейшего спуска, сопряженных градиентов, Ньютона-Рафсона и др.
\end{itemize}

Недостатками метода обратного распространения являются следующие факты
\begin{itemize}
  \item Метод наследует известные недостатки градиентной настройки весов в однослойном персептроне. Здесь также возникают проблемы медленной сходимости или расходимости, "застревания" в локальных минимумах функционала $Q$, переобучения и паралича. Причём парализоваться могут отдельные связи, нейроны, или вся сеть в целом.
  \item Приходится заранее фиксировать число нейронов скрытого слоя $H$. В то же время, это критичный параметр сложности сети, от которого может существенно зависеть качество обучения и скорость сходимости.
\end{itemize}


\subsubsection{Выбор параметров и результаты расчетов}

Fully convolutional neural network для нашей задачи имеет 3 слоя. На первых двух используется функция активации $ReLU$, на последнем $Sigmoid$. На каждом слое производится регуляризация данных. В нашем случае нейронную сеть можно определить формулой:

$$
g(x) = h_2 \left(\sum_{k=0}^{n_2} w''_k h_1\left(\sum_{j=0}^{n_1} w'_j h_0\left( \sum_{i=0}^{n_0} w_i x_i \right)\right)\right),
$$

где $h_i$ --- функция активации для соответствующего слоя. Для нахождения весов $\{w_i\}$, $\{w'_j\}$, $\{w''_k\}$ на этапе обучения модели используется метод Адама.

Для BOW и Fast Text эмбедингов мы имеем следующие метрики классификации:
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
               & precision & recall \\ \hline
     BOW       & 0.93604 & 0.95643 \\ \hline
     Fast Text & 0.99931 & 0.91263 \\ \hline
  \end{tabular}
\end{center}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.65]{dist_prob.jpg}
	\caption{Распределение вероятностей классификатора}
	\label{fig:02}
\end{figure}

\subsection{Сравнение моделей}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{old_vs_new_fp.jpg}
	\caption{Сравнение жалоб на старый и новый классификатор}
	\label{fig:02}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{old_vs_new_ps.jpg}
	\caption{Сравнение блокировок старого и нового классификатора}
	\label{fig:02}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{old_vs_new_status.jpg}
	\caption{Сравнение статусов старого и нового классификатора}
	\label{fig:02}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{is_not_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:02}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{is_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб "это спам" за этот и прошлый год}
	\label{fig:02}
\end{figure}


\newpage
\section{ПОСТРОЕНИЕ МИКРОСЕРВИСНОЙ АРХИТЕКТУРЫ}

\subsection{Обзор библиотек}

Поскольку от сервисов требуется высокая производительность, то для его написания выбран язык C++ (stl17, grpc, boost), как один из самых производительных современных языков. Для анализа данных и обучения fcnn модели использовался язык Python3 и фреймврок pyTorch за счет высокой эффективности и возможности проведения параллельных вычислений, как на cpu, так и на gpu ядрах машины.

Отказоустойчивость микросервисов обеспечивается за счет их развертки в kubernetes (k8s) кластере, так как при падении любого пода по какой-либо причине запросы равномерно сбалансируются по оставшимся живым подам, до тех пор, пока кластер самостоятельно не вернется к прежнему состоянию. Внутри него можно настроить: автоматическую балансировку нагрузки с помощью постоянного мониторинга сведений о производительности и используемых ресурсах (autoscaling) и грамотное размещение подов внутри кластера по дата центрам (affinity).

\subsection{Построение архитектуры приложения}

Поскольку сервис должен работать под высокими нагрузками важно обеспечить архитектуру, при которой выход из строя одной компоненты не приведет к деградации всей системы. Реализована следующая клиент-серверная архитектура (рис. 1). Antispam daemon (mrasd) парсит входящие сообщение и извлекает оттуда текст, изображения, файлы.  Поскольку нежелательные данные часто содержатся внутри вложенных изображений и документов, то из них также необходимо извлечь текст. Для этого через отложенную redis очередь документы оправляются в OCR сервис, который извлекает текст и сохраняет результат в redis cache.

Так как, с большой вероятностью письмо может быть дубликатом (например в случае ddos атаки или оффлайн перепроверки), то чтобы не нагрузать лишний раз OCR сервис, производится первичная проверка redis cache на наличие уже обработанных данных по заданному хэшу документа.

После полного извлечения текста сервис mrasd производит все этапы предобработки текста (приведение к одному регистру, удаление стоп слов, нормализация), а затем отправляет текст в сервис mlapi по протоколу grpc для векторизации текста при помощи fast text и дальнейшего получения предсказания fcnn модели по котому принимается решение о "нежелательности"  входящего сообщения.

Предложенная архитектура хороша тем, что при выходе из строя OCR сериса, одного (или нескольких) инстансов redis сluster, не деградирует вся система в целом.
 
\begin{figure}[h!]
	\center
	\includegraphics[scale=0.25]{deploy.jpg}
	\caption{Архитектура приложения}
	\label{fig:02}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{timings.png}
	\caption{Среднее время обработки письма}
	\label{fig:03}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{processed_messages.png}
	\caption{Среднее количество запросов в минуту с одной из ферм}
	\label{fig:04}
\end{figure}


\newpage
\section-{ЗАКЛЮЧЕНИЕ}

В данной работе приведены результаты, полученные в ходе обучения модели на реальных потоковых данных пользователей. По приведенным данным можно сделать заключение о том, что $FCNN$ модель на основе $Fast Text$ эмбедингов имеет наивысшую точность классификации, по сравнению с методами классической логистической регрессии и $FCNN$ модели на основе мешка слов.


Приведена высокопризводительная отказоустойчивая микросервисная архитектура, которая выдерживает в среднем более $10^6$ запросов в минуту. При этом деградация конкретной компоненты, машины или датацентра не приводит к полной неработоспособности приложения.


\newpage
\begin{thebibliography}{17}
\bibitem{Makkar2021} 
Aaisha Makkar, Uttam Ghosh, Pradip Kumar Sharma.
2021. \emph{Artificial Intelligence and Edge Computing-enabled
	Web Spam Detection for Next Generation IoT
	Applications} // IEEE Sensors Journal

\bibitem{Taylor2020}
Taylor O.E., Ezekiel P.S.
2020. \emph{A Model to Detect Spam Email Using Support Vector Classifier and Random Forest Classifier} //
International Journal of Computer Science and Mathematical Theory

\bibitem{Garg2021}
Pranjul Garg, Nancy Girdhar.
2021. \emph{A systematic review on spam filtering techniques based on
natural language processing framework} // 2021 11th International Conference on Cloud Computing, Data Science \& Engineering (Confluence 2021)

\bibitem{Parmar2020}
Nandan Parmar, Ankita Sharma, Harshita Jain, Amol K. Kadam.
2020. \emph{Email Spam Detection using Nave Bayes and Particle Swarm Optimization} // IJIRT

\bibitem{Mohammad2020}
Rami Mustafa A. Mohammad.
2020. \emph{A lifelong spam emails 	classification model} //
Applied Computing and Informatics

\end{thebibliography}

\newpage
\section-{ПРИЛОЖЕНИЕ А}

\end{document}