\documentclass[14pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{listings}

\usepackage{hhline}
\usepackage{multirow}
\usepackage{anyfontsize}
\usepackage{t1enc}
\usepackage{cancel}
\usepackage{float}
\usepackage[footnotes,oglav,spisok,boldsect,eqwhole,kursrab,remarks,hyperprint]{project}
\usepackage{extsizes}
\linespread{1.5}
\parindent=1.25cm

\usepackage{geometry}
\geometry{left=3cm, right=1cm, top=2cm, bottom=2cm}

\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}  

\usepackage{comment}

\usepackage{subcaption}
\renewcommand\thesubfigure{\asbuk{subfigure}}

\usepackage{xcolor}
\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}
\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}
\definecolor{ao}{rgb}{0.0, 0.0, 1.0}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{codestyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\small,
    language=python,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=t,                    
    keepspaces=true,                 
    numbers=right,                    
    numbersep=-10pt,                  
    showspaces=false,                
    showstringspaces=false,
	linewidth = 0.93\linewidth,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=codestyle,xleftmargin=0em}

\graphicspath{ {./images/} }

\begin{document}

\thispagestyle{empty}

\begin{minipage}{0.05\textwidth}
	\hspace{-1.4cm}\vspace{0.5cm}\includegraphics[scale=0.1]{emblema}
\end{minipage}
\hfill
\begin{minipage}{0.95\textwidth}
	\centering
	\linespread{1.0}
	\fontsize{11}{14pt}\selectfont
	\textbf{Министерство образования и науки Российской Федерации \\
	Федеральное государственное бюджетное образовательное учреждение\\высшего профессионального образования\\%
	<<Московский\ государственный\ технический\ университет\\ имени\ Н.\,Э.\,Баумана\\(национальный исследовательский университет)>>\\(МГТУ им. Н.\,Э.\,Баумана)}\\[3mm]
\end{minipage}
\hrule height .7mm

\bigskip

\noindentФАКУЛЬТЕТ <<Фундаментальные науки>> \\
КАФЕДРА <<Высшая математика>>

\bigskip

\begin{center}
	\begingroup
	\fontsize{20pt}{20pt}\selectfont
	\textbf{РАСЧЁТНО-ПОЯСНИТЕЛЬНАЯ ЗАПИСКА} \\ 
	\fontsize{16pt}{20pt}\selectfont
	\textbf{\textit{К~ВЫПУСКНОЙ~КВАЛИФИКАЦИОННОЙ~РАБОТЕ}}\\ 
	\textbf{\textit{НА ТЕМУ:}}
	
	\medskip
	\fontsize{16pt}{20pt}\selectfont 
	\textbf{\textit{
		\underline{ПРИМЕНЕНИЕ МЕТОДОВ МАШИННОГО} 
		\underline{ОБУЧЕНИЯ ДЛЯ РЕШЕНИЯ ЗАДАЧИ}
		\underline{ФИЛЬТРАЦИИ НЕЖЕЛАТЕЛЬНЫХ ДАННЫХ}
	}}
	\endgroup
\end{center}

\bigskip

\noindent
\begin{tabular}{lp{6em}cl}
Студент группы ФН1-41М & & \hspace{3.5cm} & Т.Е. Разумов\\ \cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Руководитель ВКР & & \hspace{3.5cm} & В.Ф. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Консультант & & \hspace{3.5cm} & О.В. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Нормоконтролер & & \hspace{3.5cm} & Н.И. Сидняев\\
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\
\end{tabular}

\vspace*{\fill}

\begin{center}
	2021 г.
\end{center}


\newpage
\section-{АННОТАЦИЯ}

В работе решается задача построения модели для обнаружения и фильтрации нежелательных спам--сообщений. Спам--фильтр позволяет разделить письма на две категории: ``спам'' и ``не спам''. 

Проведено исследование различных подходов к предобработке, векторизации и классификации данных. Произведена разметка данных для провеки качества модели. Приведены результаты, полученные в ходе обучения модели на реальных потоковых данных пользователей. Проведено сравнение исследуемых алгоритмов. 
Спроектировано и реализовано высокопроизводительное отказоустойчивое приложенение имеющее микросервисную архитектуру, которое выдерживает в среднем более $10^6$ запросов в минуту, имеет высокое время отклика и надежность.


\tableofcontents


\newpage
\section-{ВВЕДЕНИЕ}

Объемы производимой человечеством информации увеличиваются в геометрической прогрессии. Значительную пользу из этой информации можно извлечь лишь при правильной обработке и анализе полученных данных. В настоящее время для мгновенного обмена информацией наиболее часто используется электронная почта, которая является самой дешевой, простой в использовании, легкодоступный передачей данных из официальных и надежных способов обмена информацией.

В мире наблюдается рост массовой рассылки нежелательной корреспонденции различного характера посредством электронной почты. Не запрошенные сообщения в системах мгновенного обмена информацией получили название ``спам''. Доля спама в мировом трафике составляет более 80\%. Наиболее распространенными видами нежелательной электронной почтовой информации являются рекламные предложения, различные виды услуг. Часто нежелательные письма поступают от мошенников для выманивания у получателей писем денег, либо получения личных данных.

Актуальной задачей обработки данных является обнаружение и фильтрация нежелательных данных, а применительно к IT--технологиям --- это применение методов машинного обучения для классификации данных. Таким образом, существует потребность в разработке методов и алгоритмов машинного обучения для решения задачи классификации нежелательных электронных сообщений, что подтверждает актуальность исследования в рамках выбранной темы.

Целью предлагаемой выпускной квалификационной работы является построение модели машинного обучения для обнаружения и фильтрации писем в электронной почте позволяющей разделить письма на две категории: ``спам'' и ``не спам''. Для решения поставленной задачи рассмотрены различные алгоритмы и проведено их сравнение. Для достижения поставленной цели в ходе исследования необходимо решить следующие задачи:
\begin{itemize}
  \item Cбор и разметка выборки.
  \item Предобработка данных.
  \item Векторизация данных.
  \item Классификация данных.
  \item Запуск на реальных пользователях.
\end{itemize}

Объектом исследования является российская технологическая компания Mail.Ru Group. Предмет исследования --- продукты Mail.Ru Group: почта, юла, мой мир, ответы, icq, пульс, агент. В рамках работы будет спроектирован спам--фильтр для продуктов Mail.Ru Group. Ключевыми требованиями на фильтр являются:
\begin{itemize}
  \item Высокая точность --- должно верно классифицироваться не менее 99\% писем.
  \item Выская отказоустойчивость --- сервис осуществляющий запуск фильтра спама должен отвечать не менее чем на 99.99\% запросов.
  \item Выская производительность --- полный цикл проверки письма не должен быть дольше 3--х секунд.
\end{itemize} 

Все типы методов машинного обучения по прецедентам объединяет общая постановка задачи. В частности, выделяется множество ситуаций (объектов) и множество возможных реакций (откликов, ответов) на ситуацию. Предполагается, что существует некая неизвестная зависимость между реакциями и ситуацией. Однако известна конечная совокупность прецедентов --- пар ''объект--ответ``, которая является ''обучающей выборкой``. На основе обучающей выборки необходимо определить неизвестную зависимость, то есть построить алгоритм, который для любого входного объекта способен предложить достаточно точный классифицирующий ответ.   При этом не всегда требуется выразить зависимость аналитически, предлагается возможность использования принципа эмпирически формируемого решения. Одной из важнейшей особенностью таких методов машинного обучения выделяется способность обучаемой системы к обобщению, то есть адекватному отклику на данные, выходящие за пределы имеющейся обучающей выборки. Для измерения точности реакции (ответов, откликов) вводится оценочный функционал качества.

Общая постановка задач машинного обучения по прецедентам обобщает классический подход к задачам аппроксимации функций. В классическом подходе в задачах аппроксимации объектами исследования являются числа или вектора, но в реальных прикладных исследованиях входные данные не всегда полные, точные и возможна разнородная и нечисловая информация. Разнообразие входных данных порождает разнообразие методов машинного обучения.

Спам--сообщения, в общем случае могут содержать разнородную текстовую и  визуальную информацию. Алгоритмы глубокого обучения применяются для анализа спам--писем с различной информацией, поступающих в реальном времени \cite{Makkar2021}. При этом, сначала из изображения извлекаются признаки (характеристики), а затем происходит принятие решения. Среди других подходов классификации можно выделить, метод опорных векторов и метод случайного леса. В работе \cite{Taylor2020} приводится сравнение этих методов для решения задачи фильтрации спам--сообщений.

Алгоритмы фильтрации являются, как правило, стохастическими \cite{Garg2021} и применяются в комбинации с методами оптимизации некоторой целевой функции. Для решения задачи классификации электронной почты применяют различные вероятностные модели. Наиболее употребимой среди них является наивный байесовский классификатор \cite{Sidn2019}. Метод роя частиц является одним из численных методов стохастической оптимизации, его применяют в задачах фильтрации данных, так как не требуется задавать аналитическое выражение градиента оптимизируемой функции. 
Метод роя частиц относится к методам стохастической оптимизации и применяется для эвристической глобальной оптимизации параметров наивного Байесовского классификатора. Комплексный подход с использованием наивного алгоритма Байеса вместе с методом оптимизации роя частиц применялся в \cite{Parmar2020}. 
Эволюционная модель классификации спама представлена в \cite{Mohammad2020}.

\newpage
\section{ОСНОВНЫЕ СВЕДЕНИЯ}

\subsection{Объекты и признаки}

Пусть заданы множества объектов $X$, допустимых ответов $Y$, и существует целевая функция (target function) $y^*:X \rightarrow Y$, значения которой $ y_i~=~y^*(x_i)$ известны только на конечном подмножестве $\{x_1, \ldots, x_k\} \subset X$ объектов. Пары ``объект--ответ'' $(x_i, y_i)$ называются прецедентами. Совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ называется обучающей выборкой (training sample).

Суть задачи обучения по прецедентам состоит в следующем: необходимо по выборке $X^l$ восстановить зависимость $y^*$, то есть построить решающую функцию (decision function) $a: X \rightarrow Y$, которая способна приблизить целевую функцию $y^*(x)$, не только на объектах обучающей выборки, но и на всём множестве $X$. От решающей функции $a$ требуется эффективная компьютерная реализация, по этой причине её называют \emph{алгоритмом}.

Признак (feature) $f$ объекта $x$ --- это результат измерения некоторой характеристики объекта. Формально признаком называется отображение вида $f: X \rightarrow D_f$, где $D_f$ --- множество допустимых значений признака. В частности, любой алгоритм $a: X \rightarrow Y$ также можно рассматривать как признак.

В зависимости от природы множества $D_f$ признаки делят на несколько типов \cite{Zagugoiko1985}.
\begin{enumerate}
  \item  Если $D_f = \{0,1\}$, то $f$ --- двоичный признак.
  \item  Если $D_f$ --- конечное множество, то $f$ --- номинальный признак.
  \item Если $D_f$ --- конечное упорядоченное множество, то $f$ --- порядковый признак.
  \item Если $D_f = \mathbb{R}$, то $f$ --- количественный признак.
\end{enumerate}
Если все признаки имеют одинаковый тип, то есть $D_{f_1} = \ldots = D_{f_n}$, то исходные данные называются однородными, в противном случае --- разнородными.

Зададим набор признаков $f_1, \ldots , f_n$. Признаковым описанием объекта $x \in X$ будем называть вектор $\big( f_1(x), \ldots , f_n(x) \big)$. В дальнейшем положим, что множество объектов представляет собой декартово произведение $X = D_{f_1} \times \ldots \times D_{f_n}$, не различая объекты из $X$ и их признаковые описания. Совокупность признаковых описаний всех объектов выборки $X^l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов-признаков

\begin{equation*}
F = \| f_j(x_i) \|_{l \times n} = \left(
\begin{array}{ccc}
f_1 (x_1) & \ldots & f_n (x_1)\\
\vdots & \ddots & \vdots\\
f_1 (x_l) & \ldots & f_n (x_l)
\end{array}
\right).
\end{equation*}

\subsection{Обучение и функционал качества}

Моделью алгоритмов называется параметрическое семейство отображений $A = \{g(x, \theta) | \theta \in \Theta \}$, где $g : X \times \Theta \rightarrow Y$ --- некоторая фиксированная функция,
$\Theta$ --- множество допустимых значений параметра $\theta$, называемое пространством параметров или пространством поиска (search space).

Настройкой (fitting) или обучением (training, learning) алгоритма $a \in A$ называют процесс подбора оптимального параметра модели $\theta$ по обучающей выборке $X^l$. Метод обучения (learning algorithm) --- это отображение $\mu: (X \times Y)^l \rightarrow A$, ставящее в соответствие произвольной конечной выборке $X^l = (x_i, y_i)_{i=1}^l$ некоторый алгоритм $a \in A$. Метод обучения должен иметь эффективную программную реализацию.\\
Задачи обучения по прецедентам чётко различаются два этапа:
\begin{enumerate}
  \item На этапе обучения метод $\mu$ по выборке $X^l$
строит алгоритм $a = \mu(X^l)$.
  \item На этапе применения алгоритм $a$ для новых объектов $x$ выдаёт ответы $y = a(x)$.
\end{enumerate}
Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров модели, доставляющих оптимальное значение заданному функционалу качества.

Функция потерь (loss function) --- это неотрицательная функция $Z(a, x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если выполнено равенство $Z(a, x) = 0$, то ответ $a(x)$ называют корректным.

Функционал качества алгоритма $a$ на выборке $X^l$ представим в виде

\begin{equation}
Q\left(a, X^l\right) = \dfrac{1}{l} \sum_{i=1}^{l} Z(a, x_i).
\label{eq:empirical_risk}
\end{equation}
Функционал $Q$ называют также \emph{функционалом средних потерь} или эмпирическим риском, так как он вычисляется по эмпирическим данным $(x_i, y_i)_{i=1}^l$.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели $A$ алгоритм $a$, доставляющий минимальное значение функционалу качества $Q$ на заданной обучающей выборке $X^l$

$$
\mu\left(X^l\right) = \operatorname*{argmin}_{a \in A} Q(a, X^l).
$$

\subsubsection*{Вероятностная постановка задачи обучения}

В задачах обучения по прецедентам элементы множества $X$ --- это не реальные объекты, а лишь доступные данные о них. Данные могут быть неточными, поскольку измерения значений признаков $f_j(x)$ и целевой зависимости $y^* (x)$ обычно выполняются с погрешностями. Данные могут быть неполными, поскольку выполняют измерения не всех мыслимых признаков, а лишь физически доступных для измерения. В результате одному и тому же описанию $x$ могут соответствовать различные объекты и различные ответы. В таком случае $y^* (x)$, строго говоря, не является функцией. Устранить эту некорректность позволяет вероятностная постановка задачи.

Вместо существования неизвестной целевой зависимости $y^* (x)$ предположим существование неизвестного вероятностного распределения на множестве $X \times Y$ с плотностью $p(x, y)$, из которого случайно и независимо выбираются $l$ наблюдений $X^l = (x_i, y_i)_{i=1}^l$. Такие выборки называются простыми или случайными одинаково распределёнными (independent identically distributed, i.i.d.).

Вероятностная постановка задачи считается более общей, так как функциональную зависимость $y^* (x)$ можно представить в виде вероятностного распределения $p(x, y) = p(x)p(y|x)$, положив $p(y|x) = \delta(y - y^* (x))$, где функция $\delta(z)$ --- дельта--функция.

При вероятностной постановке задачи вместо модели алгоритмов $g(x, \theta)$, аппроксимирующей неизвестную зависимость $y^* (x)$, задаётся модель совместной плотности распределения объектов и ответов $\varphi(x, y, \theta)$, аппроксимирующая неизвестную плотность $p(x, y)$. Затем определяется значение параметра $\theta$, при котором выборка данных $X^l$ максимально правдоподобна, то есть наилучшим образом согласуется с моделью плотности.

Если наблюдения в выборке $X^l$ независимы, то совместная плотность распределения всех наблюдений равна произведению плотностей $p(x, y)$ в каждом наблюдении: $p(X^l) = p \big( (x_1, y_1), \ldots,  (x_l, y_l) \big)$.  Подставляя вместо $p(x, y)$ модель плотности $\varphi(x, y, \theta)$, получаем функцию правдоподобия (likelihood)

$$
L(\theta, X^l) = \prod\limits_{i=1}^l \varphi(x_i, y_i, \theta).
$$

Чем выше значение функции правдоподобия, тем лучше выборка согласуется с моделью. Значит, нужно искать значение параметра $\theta$, при котором значение $L\left(\theta, X^l\right)$ максимально. После того, как значение параметра $\theta$ найдено, построить искомый алгоритм $a_\theta(x)$ по плотности $\varphi(x, y, \theta)$ несложно.

Вместо максимизации $L$ удобнее минимизировать функционал $-\ln L$, поскольку он аддитивен по объектам выборки
$$
-\ln L(\theta, X^l) = - \sum_{i=1}^{l} \ln \varphi(x_i, y_i, \theta) \rightarrow \min_{\theta}.
$$

Этот функционал совпадает с функционалом эмпирического риска (\ref{eq:empirical_risk}), если определить вероятностную функцию потерь $L(a_{\theta}, x) = -l \ln \varphi(x_i, y_i, \theta)$. Такое определение потери вполне естественно --- чем хуже пара $(x_i, y_i)$ согласуется с моделью $\varphi$, тем меньше значение плотности $\varphi(x_i, y_i, \theta)$ и выше величина потери $L(a_{\theta}, x)$.

Верно и обратное --- для многих функций потерь возможно подобрать модель плотности $\varphi(x, y, \theta)$ таким образом, чтобы минимизация эмпирического риска была эквивалентна максимизации правдоподобия.

Таким образом, существуют два родственных подхода к формализации задачи обучения: первый основан на введении функции потерь, второй — на введении вероятностной модели порождения данных. Оба в итоге приводят к схожим (иногда даже в точности одинаковым) оптимизационным задачам.

\subsection{Метрики качества обучения}

Перед переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ошибок классификации --- матрица ошибок (confusion matrix). Допустим, что у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта одному из классов, тогда матрица ошибок классификации будет выглядеть следующим образом
\begin{table}[h!]
\caption{Матрица ошибок классификации}
\label{tab:metrics}
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
                   & $y = 1$ & $y = 0$ \\ \hline
     $\hat{y} = 1$ & True Positive $(TP)$ & False Positive $(FP)$ \\ \hline
     $\hat{y} = 0$ & False Negative $(FN)$ & True Negative $(TN)$ \\ \hline
  \end{tabular}
\end{center}
\end{table}
Здесь $y$ --- это ответ алгоритма на объекте, а $\hat{y}$ ---истинная метка класса на этом объекте. Таким образом, ошибки классификации бывают двух видов: False Positive $(FP)$ и False Negative $(FN)$. В статистике первый вид ошибок называют ошибкой I--го рода, а второй --- ошибкой II--го рода.

Интуитивно понятной и почти неиспользуемой метрикой является метрика accuracy --- доля правильных ответов алгоритма
$$
accuracy= \dfrac{TP+TN}{TP+TN+FP+FN}.
$$
Эта метрика бесполезна в задачах с неравными классами, что демонстрируется в \cite{Voron2021}.

Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики точности (precision) и полноты (recall) \cite{Bommannavar2014}
$$
precision = \dfrac{TP}{TP + FP}, \quad recall = \dfrac{TP}{TP + FN}.
$$
Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм (рис. \ref{fig:precision_recall}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.2]{precision_recall.png}
	\caption{Иллюстрация метрик precision и recall}
	\label{fig:precision_recall}
\end{figure}

Именно введение precision не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision --- способность отличать этот класс от других классов. Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок \cite{Gahov2014}.

Существует несколько различных способов объединить precision и recall в агрегированный критерий качества. F--мера (в общем случае $F_{\beta}$) --- среднее гармоническое precision и recall
$$
F_{\beta} = \dfrac{(1 + \beta^2) \cdot precision \cdot recall}{\beta^2 \cdot precision + recall},
$$
где $\beta$ --- параметр, определяющий вес точности в метрике.

Одним из способов оценить модель в целом, не привязываясь к конкретному порогу, является AUC--ROC (или ROC AUC) --- площадь (Area Under Curve) под кривой ошибок (Receiver Operating Characteristic curve). Данная кривая представляет из себя линию от $(0,0)$ до $(1,1)$ в координатах True Positive Rate $(TPR)$ и False Positive Rate $(FPR)$
$$
TPR = \dfrac{TP}{TP+FN}, \quad FPR = \dfrac{FP}{FP+TN}.
$$
$TPR$ нам уже известна --- это полнота, а $FPR$ показывает, какую долю из объектов negative класса алгоритм предсказал неверно. В идеальном случае, когда классификатор не делает ошибок $(FPR = 0, TPR = 1)$ мы получим площадь под кривой, равную единице; в противном случае, когда классификатор случайно выдает вероятности классов, AUC--ROC будет стремиться к 0.5, так как классификатор будет выдавать одинаковое количество $TP$ и $FP$.

Каждая точка на графике соответствует выбору некоторого порога. Площадь под кривой в данном случае показывает качество алгоритма (больше --- лучше), кроме этого, важной является крутизна самой кривой --- мы хотим максимизировать $TPR$, минимизируя $FPR$, а значит, наша кривая в идеале должна стремиться к точке $(0,1)$.

Критерий AUC--ROC устойчив к несбалансированным классам и может быть интерпретирован как вероятность того, что случайно выбранный positive объект будет проранжирован классификатором выше (будет иметь более высокую вероятность быть positive), чем случайно выбранный negative объект.

Таким образом при анализе метрик необходимо ориентироваться на следующие критерии:
\begin{itemize}
  \item  в случае многоклассовой классификации нужно внимательно следить за метриками каждого из классов и следовать логике решения задачи, а не оптимизации метрики.
  \item  в случае неравных классов нужно подбирать баланс классов для обучения и метрику, которая будет корректно отражать качество классификации.
  \item выбор метрики нужно делать с фокусом на предметную область, предварительно обрабатывая данные и, возможно, сегментируя.
\end{itemize}

\subsubsection*{Проблема переобучения}

Минимизацию эмпирического риска следует применять с известной долей осторожнсти. Если минимум функционала $Q\left(a, X^l\right)$ достигается на алгоритме $a$, то это ещё не гарантирует, что $a$ будет хорошо приближать целевую зависимость на произвольной контрольной выборке 
$X^k = \left(x'_i, y'_i\right)_{i=1}^k$.

Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте переобучения (overtraining) или переподгонки (overfitting). При решении практических задач с этим явлением приходится сталкиваться очень часто (рис. \ref{fig:overfitting}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.8]{overfitting.png}
	\caption{Пример переобучения нейронной сети}
	\label{fig:overfitting}
\end{figure}

Легко представить себе метод, который минимизирует эмпирический риск до нуля, но при этом абсолютно не способен обучаться. Получив обучающую выборку $X^l$, он запоминает её и строит алгоритм, который сравнивает предъявляемый объект $x$ с обучающими объектами $x_i$ из $X^l$. В случае совпадения $x = x_i$ алгоритм выдаёт правильный ответ $y_i$. Иначе выдаётся произвольный ответ. Эмпирический риск принимает наименьшее возможное значение, равное нулю. Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

Обобщающая способность (generalization ability) метода $\mu$ характеризуется величиной $Q\left(\mu(X^l), X^k\right)$ при условии, что выборки $X^l$ и $X^k$ являются представительными. Для формализации понятия ``представительная выборка'' обычно принимается стандартное предположение, что выборки $X^l$ и $X^k$ --- простые, полученные из одного и того же неизвестного вероятностного распределения на множестве $X$.

Метод обучения $\mu$ называют состоятельным, если при заданных достаточно малых значениях $\varepsilon$ и $\eta$ справедливо неравенство

\begin{equation}
P_{X^l, X^k} \big\{ Q(\mu(X^l), X^k  > \varepsilon \big\} < \eta.
\label{eq:estimate}
\end{equation}
Параметр $\varepsilon$ называется точностью, параметр $(1 - \eta)$ --- надёжностью.

Получение оценок вида (\ref{eq:estimate}) является фундаментальной проблемой статистической теории обучения. Первые оценки были получены в конце 60--х годов В. Н. Вапником и А. Я. Червоненкисом. В настоящее время статистическая  теория развивается очень активно, однако для многих  интересных для практики случаев оценки обобщающей способности либо неизвестны, либо сильно завышены.

Эмпирические оценки обобщающей способности применяются в тех случаях,
когда не удаётся воспользоваться теоретическими.


Пусть дана выборка $X^L = (x_i, y_i)_{i=1}^L$. Разобьём её $N$ различными способами на две непересекающиеся подвыборки --- обучающую $X_n^l$ длины $l$ и контрольную $X_n^k$ длины $k = L - l$. Для каждого разбиения $n = 1,\ldots,N$ построим алгоритм $a_n = \mu\left(X_n^l\right)$ и вычислим значение $Q_n = Q\left(a_n, X_n^k\right)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называется оценкой скользящего контроля (cross validation, CV)

\begin{equation*}
CV\left(\mu, X^L\right) =  \dfrac{1}{N} \sum_{i=1}^{N} Q\left(\mu(X_n^l\right), X_n^k).
\end{equation*}

Возможны различные варианты скользящего контроля, отличающиеся способами разбиения выборки $X^L$. В простейшем варианте разбиения генерируются случайным образом, число $N$ берётся в диапазоне от 20 до 100. Стандартом считают методику $(t \times q)$--кратного скользящего контроля,
когда выборка случайным образом разбивается на $q$ блоков равной (или почти равной) длины, каждый блок по очереди становится контрольной выборкой, а объединение всех остальных блоков --- обучающей. Выборка $X^L$ по--разному разбивается $t$ раз на $q$ блоков. Итого получается $N = tq$ разбиений. Данная методика даёт более точные
оценки за счёт того, что все объекты ровно по $t$ раз встречаются в контроле.

Недостатками скользящего контроля являются: вычислительная неэффективность, высокая дисперсия, неполное использование имеющихся данных для обучения из--за сокращения длины обучающей выборки с $L$ до $l$.


%\newpage
\subsection{Постановка задачи}

\subsubsection*{Естественная постановка}

В настоящее время существуют технологии создания фильтров--сервисов отсекания навязываемой информации. Их принято разделять на два класса: настраиваемые вручную и автоматизированные. Технологии из первого класса применяют списки доступа и настраиваются пользователем, выбирающему или запрещенные, при политике ``черного списка'', или разрешенные, при политике ``белого списка'', адреса. Но такие разделения навязываемой информации неэффективны так как необходимо частое обновление списков доступа. Кроме того, ручная категоризация неприменима, если необходимо классифицировать большой объем информации за ограниченное время.

Применение автоматизированных технологий фильтрации основано на использовании методов распознавания образов, искусственного интеллекта, применении математической статистики и т.д. Фильтрам, созданным с применением теории искусственного интеллекта, обучение необходимо лишь в самом начале. Они, в процессе эксплуатации, дообучаются самостоятельно. При этом заметно снижается нагрузка на пользователя.

Таким образом, исходя из вышесказанного, существует потребность в разработке методов и алгоритмов классификации информации для решения задачи фильтрации нежелательных сообщений, что подтверждает актуальность темы данной работы и приводит к постановке задачи.

В рамках данной работы требуется реализовать спам--фильтр для следующих продуктов Mail.Ru Group: почта, юла, мой мир, ответы, icq, пульс, агент. Ключевыми требованиями на фильтр являются:
\begin{itemize}
\item Высокая точность --- должно верно классифицироваться не менее 99\% писем.
\item Высокая отказоустойчивость --- сервис осуществляющий запуск фильтра спама должен отвечать не менее чем на 99.99\% запросов.
\item Высокая производительность --- полный цикл проверки письма не должен быть дольше 3--х секунд.
\end{itemize}

\subsubsection*{Формальная постановка}

Формальную постановку задачи можно разбить на 4 этапа:
\begin{enumerate}
\item Предобработка письма.
\item Построение отображения текстовой информации в векторное пространство (векторизация).
\item Классификация объектов.
\item Постоение микросервисной архитектуры для запуска спам--фильтра на реальных пользователях.
\end{enumerate}

На этапе предобработки письма требуется определить только необходимую для анализа информацию и реальзовать инструменты для её извлечения. Этот этап называется выделением признаков, который представляет из себя процесс снижения размерности, в котором исходный набор исходных переменных сокращается до более управляемых групп (признаков) для дальнейшей обработки, оставаясь при этом достаточным набором для точного и полного описания исходного набора данных.

На этапе построения отображения текстовой информации в векторное пространство требуется провести векторизацию извлеченных из письма признаков в ограниченное векторное пространоство из $\mathbb{R}^n$.

На этапе классификации требуется разметить обучающую и тестовую выборку и обучить по ним алгоритм $a(x)$ с высокой точностью. Процесс разметки выборки, обучения и валидации подробно описан в разделе 1.

На этапе построения микросервисной архитектуры для запуска спам--фильтра на реальных пользователях требуется спроектировать высоконагруженное, отказоустойчивое приложение, обеспечив требуемые производительность и надежность. Провести анализ работы классификатора на пользователях (жалобы, обращения в службу поддержки) и в зависимости от их реакции провести нужное количество итераций дообучения классификатора.

\newpage
\section{РЕШЕНИЕ ЗАДАЧИ КЛАССИФИКАЦИИ}

\subsection{Предобработка данных}

Содержимое письма очень сильно отличается от того, что видит пользователь в веб интерфейсе (рис. \ref{fig:web_eml}). Оно содержит очень много служебных заголовков, которые не несут никакого смысла для анализа (рис. \ref{fig:raw_eml}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml.jpg}
	\caption{Письмо в веб интерфейсе}
	\label{fig:web_eml}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml_raw.jpg}
	\caption{Исходный вид письма}
	\label{fig:raw_eml}
\end{figure}

В первую очередь требуется валидировать ту информацию, которую видит пользователь, поэтому для нас представляют интерес только заголовки тема письма (subject) и содержимое письма (body). При этом body делится на несколько частей. Каждая часть может иметь абсолютно любой тип: текст, изображения, pdf, docx, html, calendar, и т.д. Каждый из этих типов нуждается в индивидуальной обработке. Для определения типа используется вложенный заголовок Content--Type.

Поскольку письмо имеет сильно неоднородную структуру (служебные заголовки, вложеные документы различных форматов) и при этом одно слово может быть записано множеством разных способов (разный шрифт, кодировка, регистр и т.д.), но при этом иметь тот же смысл, то применяется множество различных методов предобработки.

\subsubsection*{Извлечение текстовых данных}

Для извлечения информации из документов имеющих текстовый формат, таких как docx, html, calendar используются собственные специализированные парсеры написанные на C++. Они производят декодирование и ивлекают только нужную информацию, удаляя из текста тэги и служебные символы. Пример html страницы изображен на (рис. \ref{fig:html})

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{html.jpg}
	\caption{Пример DOM дерева HTML}
	\label{fig:html}
\end{figure}

\subsubsection*{Извлечение графических данных}

Поскольку изображения и pdf не являются текстовыми форматами, то для автоматического извлечения текста необходимо использовать алгоритмы машинного обучения \cite{Churikov2004}. Так как извлечения текста из большинства изображений исходных писем имеет низкое качество, то было разработано две модели на языке Python с использованием фреймворка PyTorch. 

Первая модель отвечает за разметку и сегментацию изображения. Благодяря ей улучшается качество распознавания и увеличивается производительность, за счет того, что мы не пытаемся извлечь текст из тех фрагментов изображения, где его нет (рис. \ref{fig:segment}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{segmentation.png}
	\caption{Пример сегментации изображения}
	\label{fig:segment}
\end{figure}

Вторая модель реализована на основе полносвязной нейронной сети, которая возвращает вектор вероятностей по заданному фрагменту изображения \cite{Kravchenko2005}. С её помощью извлекается весь текст из изображения (рис. \ref{fig:fcnn_img}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{fcnn_img.jpg}
	\caption{Архитектура полносвязной нейронной сети для изображений}
	\label{fig:fcnn_img}
\end{figure}

Для обработки PDF используется известная библиотека poppler. Она конвертирует PDF в несколько изображения, которые далее отправляются в модели сегментации и извлечения текста.

\subsubsection*{Конкатенация и удаление стоп слов}

После извлечения текста из всех документов производится конкатенация всех его частей с заданными разделителями и декодирование в заданную кодировку. Затем приведение к нижнему регистру, удаление лишних пробелов и отступов. 

Текст часто содержит много символов, которые не несут смысловой нагрузки для общего смысла (два пробела, абзацный отступ), а также стоп слова (stop words).
Стоп слова --- это слова, которые не добавляют особого смысла предложению. К стоп словам относят знаки пунктуации, местоимения и предлоги. Часто распространители электронной корреспонденции нежелательного характера используют их для зашумления текстов с целью скрыть спам контент сообщения. Так как их можно спокойно игнорировать, не жертвуя смыслом предложения, то в задачах классификации часто прибегают к их удалению из исходного сообщения.

\subsubsection*{Нормализация}

Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Используя разные алгоритмы, такие как лемматизация и стемминг, преследуют цель привести все встречающиеся словоформы к одной, так называемой нормальной словарной форме.


Стемминг --- это грубый эвристический процесс, который отрезает ``лишнее'' от корня слов, часто это приводит к потере словообразовательных суффиксов. Основная проблема, возникающая при использовании стеммера --- это обработка слов, которые при образовании разных грамматических форм меняют не только окончание, но и основу слова. Например, существительное ``кошка'' в винительном и родительном падеже множественного числа имеет форму ``кошек''. Из--за таких беглых гласных стеммер должен либо игнорировать подобные формы, усекая ``кошки'' до ``кошк'' и теряя часть форм слова, либо усекать слово до безусловно неизменяющейся основы, получая ``кош'', что впоследствии может привести к полной потере контекста. Чтобы минимизировать негативные последствия слишком агрессивного усечения слов стеммером, необходимо выполнять стемминг искомого ключевого слова, а затем сравнивать результат с выходом стеммера для каждого из слов в обрабатываемом тексте. Но даже в этом случае буду встречаться совпадения стемов для совершенно несвязанных слов.


Лемматизация --- это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме (лемме). Однако он применяет упрощенный анализ слов, не учитывая контекст. Это приводит к неоднозначностям при определении части речи. Например, лемматизация слов в словосочетании ``мы роем яму'' даст для второго слова два варианта лемматизации: существительное `рой' и глагол `рыть'. Эта неоднозначность не может быть разрешена без привлечения морфологического анализатора.

Как правило лемматизация дает наиболее точные результаты и именно этот подход используется в работе.


%\newpage
\subsection{Векторизация данных}

Современные алгоримы машинного обучения не могут напрямую работать с текстом из исходных (необработанных) данных писем, поэтому необходимо построить отображение текста в векторное пространство. Этот процесс называется извлечением признаков. Рассмотрим несколько подходов для построения данного отображения.

\subsubsection*{Мешок слов}

Модель мешка слов (BOW) --- это упрощенное представления текстовой информации, используемое в задачах обработки естественных языков и поиска информации. В этой модели текст представляется в виде мешка (мультимножества) его слов или словосочетаний в случае комбинаций термов, игнорируя грамматику и в некоторых случаях даже порядок слов, но сохраняя множественность. Каждому такому терму (слову или словосочетанию) ставится в соответствие некоторое число. В этом случае текст определяется вектором $x=(w_1, ..., w_N)^T$, где $N$ --- размерность из конечного словаря $X_L$ состоящего из уникальных термов обучающей выборки (рис. \ref{fig:bow_ex}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{bow_ex.jpg}
	\caption{Векторизация при помощи мешка слов}
	\label{fig:bow_ex}
\end{figure}

Возможны следующие варинаты определения $w_i$.
\begin{itemize}
\item Булевский вес
$
\begin{cases} 
1, & \mbox{если элемент присутствует в письме}, \\ 
0, & \mbox{если элемент не присутствует в письме}.  
\end{cases}$
\item Количество вхождений $i$--го терма в тексте $w_i = n_i$.
\item Частота терма $w_i = n_i\left(\sum\limits_{j=1}^{N} n_j\right)^{-1}$.
\end{itemize}
В данной работе для определения $w_i$ взят булевский вес.


\subsubsection*{Алгоритм word2vec}

Основной проблемой BOW является потеря контекста между словами. Поскольку в естественном языке перестановка даже двух слов предложения  может полностью изменить его смысл, то данный подход к классификации может иметь низкую точность.

Алгоритм word2vec --- это инструмент векториции текста с учетом контекстной связи между словами. В основе алгоритма лежат такие методы как huffman binary tree, skip--gram \cite{Mikolov2013_Efficient}. Основной проблемой word2vec является поиск контекста для редких слов.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{skip_gram.png}
	\caption{Принцип работы skip--gram модели}
	\label{fig:skip_gram}
\end{figure}

Цель обучения модели word2vec это поиск skip--gram (рис. \ref{fig:skip_gram}), то есть нахождение представления слов, которые полезны для предсказания окружающих слов в письме. Более формально: учитывая последовательность обучающих слов $w_1, w_2, w_3, ..., w_N$, требуется максимизировать среднюю логарифмическую вероятность

$$
\dfrac{1}{N}\sum_{i=1}^{N}\sum_{-c \leqslant j \leqslant c, j \neq 0} \ln p(w_{i+j}|w_i) \rightarrow \max,
$$
где $c$ --- размер обучающего контекста для слова $w_i$. Вероятность $p(w_O|w_I)$ нахождения слова $w_O$ в контексте со словом $w_I$ определяется через фукцию softmax

\begin{equation}
p(w_O|w_I) = \dfrac{\exp({\vec{u}_{w_O}\cdot\vec{v}_{w_I}})}{\sum_{i=1}^{N} \exp({\vec{u}_{i} \cdot \vec{v}_{w_I}})},
\label{eq:softmax}
\end{equation}
где $\vec{v}_{w_I}$ --- некий контекстный вектор для слова $w_I$, $\vec{u}_{w_O}$ --- word2vec представление слова $w_O$.

Поскольку стоимость вычисления функции softmax пропорциональна $O(N)$, которое на практике является очень большим (порядка $10^6$--$10^9$), что вызывает очень много вычислительных затрат и времени, то обычно вместо применения (\ref{eq:softmax}), используют иерархический softmax (\ref{eq:hierarchical_softmax}). В контексте языковых моделей нейронных сетей он был впервые представлен Морином и Бенжио \cite{Mikolov2013_Distributed}. Основное преимущество заключается в том, что вместо оценки $N$ выходных узлов в нейронной сети для получения
распределения вероятностей, можно оценить только около $\log_2 N$ узлов.

Идея оптимизации заключается в том, что на основе словаря текста строится двоичное дерево. В каждом листе дерева закодированно слово. Обозначим расстояние от вершины (root) до слова $w$ как $L(w)$. Узел дерева под номером $j$ на пути от вершины до слова $w$ обозначим $n(w, j)$, при этом $n(w, 1) = $ root и $n(w, L(w)) = w$. Пусть $n_l(w,j)$ --- левый потомок для узла $n(w,j)$. Тогда выражение для вычисления вероятности $p(w_O|w_I)$ нахождения слова $w_O$ в контексте с $w_I$ имеет вид
\begin{equation}
p(w_O|w_I) = \prod\limits_{j=1}^{L(w)-1} \sigma \Big(\delta_{n(w,j+1), n_l(w,j)} \vec{u}_{n(w,j)} \cdot \vec{v}_{w_I} \Big),
\label{eq:hierarchical_softmax}
\end{equation}
где $\sigma(x) = 1 / (1 + e^{-x})$, $\delta_{i,j}$ --- символ Кронекера.

Структура дерева, используемая иерархическим softmax, оказывает значительное влияние на производительность. Мних и Хинтон исследовали ряд методов построения древовидной структуры и влияние как на время обучения, так и на точность получаемой модели \cite{Bojanowski2017}. В этой работе используется двоичное
дерево Хаффмана (рис. \ref{fig:huffman}), так как оно присваивает короткие коды частым словам, что приводит к более быстрому обучению.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{huffman.jpg}
	\caption{Бинарное дерево Хаффмана}
	\label{fig:huffman}
\end{figure}

Натренированная модель word2vec может улавливать некоторые семантические и синтаксические свойства слов (рис. \ref{fig:word2vec}), несмотря на то, что в модель явно не  заложено никакой семантики. Слово ``мужчина'' (man) относится к слову женщина (woman), также, как слово ``дядя'' (uncle) к слову ``тётя'' (aunt). Для человека это естественно и понятно, но в других ситуациях моделям добиться такого же соотношения векторов можно только с помощью специальных ухищрений.

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{word2vec.jpg}
	\caption{Семантическая близость слов в word2vec модели}
	\label{fig:word2vec}
\end{figure}

\subsubsection*{Алгоритм Fast Text}

FastText --- это расширение word2vec, предложенное Facebook в 2016 году. Вместо ввода отдельных слов в нейронную сеть, FastText разбивает слова на несколько $n$--грамм (подслов). Например, триграммы для слова ``apple''  ---  это ``app'', ``ppl'' и ``ple'' (без учета начала и конца границ слов). Вектор для слова ``apple'' образуется при помощи суммы всех $n$--грамм. После обучения нейронной сети у нас будут эмбединги слов для всех $n$--грамм из обучающего набора данных.

С помощью данного подхода алгоритм становится более чувствительным к редким словам, так как весьма вероятно, что некоторые из их $n$--грамм также присутствуют в других словах. Для обучения модели FastText требуется больше времени, но она работает лучше, чем word2vec, и позволяет правильно представлять редкие слова.


%\newpage
\subsection{Классификация данных}

После векторизации текста необходимо построить преобразование из множества признаков во множество классифицируемых объектов $a: X \rightarrow Y.$

\subsubsection*{Логистическая регрессия}

Пусть $X$ --- пространство объектов, $Y = \{-1, 1 \}$ --- множество допустимых ответов. Объекты описываются $n$ числовыми признакам в виде отображения $f_j: X \rightarrow \mathbb{R}^n, j = 1,\ldots,n$. Вектор $\vec{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n$, где $x_j = f_j(\vec{x})$, называется признаковым описанием объекта $\vec{x}$.

Если определить дискриминантную функцию  как скалярное произведение вектора $\vec{x}$ и вектора параметров $\vec{w} \in \mathbb{R}^n$, то получается линейный классификатор
\begin{equation}
a(\vec{x}, \vec{w}) = \sigma(\vec{w} \cdot \vec{x} - w_0) = \sigma \left( \sum_{j=1}^n x_j f_j(\vec{x}) - w_0\right).
\label{eq:lin_clf}
\end{equation}
Уравнение $(\vec{w} \cdot \vec{x}) = 0$ задаёт гиперплоскость, разделяющую классы в пространстве $\mathbb{R}^n$. Если вектор $\vec{x}$ находится по одну сторону гиперплоскости с её направляющим вектором $\vec{w}$, то объект $\vec{x}$ относится к классу $+1$, иначе --- к классу $-1$. 

Параметр $w_0$ иногда опускают. Иногда полагают, что среди признаков есть константа, $f_j(x) = -1$, и тогда роль свободного коэффициента $w_0$ играет параметр $w_j$.

Линейный классификатор или персептрон является простейшей математической моделью нервной клетки --- нейрона (рис. \ref{fig:nerve_cell}). Нейрон имеет множество разветвлённых отростков --- дендритов, и одно длинное тонкое волокно --- аксон, на конце которого находятся синапсы, примыкающие к дендритам других нервных клеток. Нервная клетка может находиться в двух состояниях: обычном и возбуждённом. Возбужденное состояние клетки обусловенно  накоплением достаточного количества положительных зарядов. В этом состоянии клетка генерирует электрический импульс величиной около 100 мВ и длительностью около 1 мс, который проходит по аксону до синапсов. Синапс при приходе импульса выделяет вещество, способствующее проникновению положительных зарядов внутрь соседней клетки, примыкающей к данному синапсу. Синапсы имеют разную способность концентрировать это вещество, причём некоторые даже препятствуют его выделению --- они называются тормозящими. После возбуждения клетки наступает период релаксации --- некоторое время она не способна генерировать новые импульсы.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{nerve_cell.jpg}
	\caption{Структура нервной клетки}
	\label{fig:nerve_cell}
\end{figure}

Нервную клетку можно рассматривать как устройство, которое на каждом такте своей работы принимает заряды величиной $x_j = f_j(\vec{x})$ от n входов --- синапсов, примыкающих к её дендритам. Поступающие заряды складываются с весами $w_j$. Если вес положительный, то $j$--й синапс возбуждающий, если отрицательный, то тормозящий. Если суммарный заряд превышает порог активации $w_0$, то нейрон возбуждается и выдаёт на выходе $+1$, иначе выдается $-1$.

Функцию $\sigma(z)$, преобразующую значение суммарного импульса в выходное значение нейрона, называют функцией активации. В общем случае это не обязательно пороговая функция.

Таким образом, линейный классификатор, определяемый формулой (\ref{eq:lin_clf}), является математической моделью нейрона. Эту модель предложили в 1943 году МакКаллок и Питтс.

\subsubsection*{Описание работы алгоритма}

Метод логистической регрессии основан на довольно сильных вероятностных предположениях, которые имеют сразу несколько интересных последствий. Во--первых, линейный алгоритм классификации оказывается оптимальным байесовским
классификатором. Во--вторых, однозначно определяется функция потерь. В--третьих,
возникает интересная дополнительная возможность наряду с классификацией объекта получать численные оценки вероятности его принадлежности каждому из классов.

В нормальном дискриминантном анализе доказывается, что если плотности классов нормальны и имеют равные матрицы ковариации, то оптимальный байесовский классификатор линеен. Покажем, что классификатор остается линейным и при менее жестких предположениях.

Пусть классов два, $Y = \{-1,+1\}$, объекты описываются $n$ числовыми признаками $f_j : X \to \mathbb{R}^n, j = 1, \ldots,n$. Будем полагать $X = \mathbb{R}^n$, отождествляя объекты с их признаковыми описаниями: $\vec{x} = (f_1(x), \ldots, f_n(x))$.

Примем следующие гипотезы.

1. Множество прецедентов $X \times Y$ является вероятностным пространством. Выборка прецедентов $X^l = \left(\vec{x}_i, y_i\right)^l_{i=1}$ получена случайно и независимо согласно вероятностному распределению с плотностью вероятностей $p(x,y) = P_y p_y(x) = P(y|x)p(x)$, где $P_y$ --- априорные вероятности, условные вероятности $P(y|x)$ --- апостериорные вероятности классов $y \in Y,$ а  функции правдоподобия --- это $p_y(x).$

Плотность распределения $p(x)$, $x \in \mathbb{R}^n$ называется экспонентной, если $p(x) = \exp(c(\delta) \langle \theta, x\rangle + b(\delta, \theta) + d(x, \delta)$, где параметр $\theta \in \mathbb{R}^n$ называется сдвигом, параметр $\delta$ называется разбросом, $b, c, d$ --- произвольные числовые функции. Класс экспонентных распределений очень широк. К нему относятся многие непрерывные и дискретные распределения: равномерное, нормальное, гипергеометрическое, пуассоновское, биномиальное, $\Gamma$--распределение, и другие.

2.  Если функции правдоподобия классов $p_y(x)$ принадлежат экспонентному семейству плотностей, то они имеют равные значения параметров $d$ и $\delta$, но отличаются значениями параметра сдвига $\theta_y$.

Оптимальный байесовский классификатор имеет вид 
$$
a(x) = \operatorname*{argmax}_{y \in Y} \lambda_y P(y|x),
$$
где $\lambda_y$ --- штраф за ошибку на объектах класса $y$.
В случае двух классов
$$
a(x) = \operatorname*{sign}\left(\lambda_+ P(+1|x) - \lambda_-P(-1|x)\right) = \operatorname*{sign} \left( \dfrac{P(+1|x) }{P(-1|x) } - \dfrac{\lambda_-}{\lambda_+} \right).
$$
Если справедливы гипотезы 1, 2, и среди признаков $f_1(x), \ldots , f_n(x)$ есть константа, то выполнены следующие утверждения.

\begin{itemize}
\item  Байесовский классификатор является линейным
$$
a(x) = \operatorname*{sign} ( (\vec{w} \cdot \vec{x}) - w_0),
$$
где $w_0 = \ln\left(\lambda_-/\lambda_+\right)$, а вектор $w$ не зависит от штрафов $\lambda_-, \lambda_+.$

\item Апостериорная вероятность принадлежности произвольного объекта из множества $x \in X$ классу $y \in \{-1, +1\}$ может быть вычислена по значению дискриминантной функции
$$
P(y|x) = \sigma ((\vec{w} \cdot \vec{x}) y),
$$
где $ \sigma(z) = \dfrac{1}{1+ e^{-z}}$ --- сигмоидная функция.

\end{itemize}

Рассмотрим отношение апостериорных вероятностей классов
и воспользуемся тем, что $p_y(\vec{x})$ --- экспонентные плотности с параметрами $\theta$ и $\delta$

\begin{align*}
& \dfrac{P\left(+1|\vec{x}\right)}{P\left(-1|\vec{x}\right)} = \dfrac{P_{+} p_{+}(\vec{x})}{P_{-} p_{-}(\vec{x})} = \\
& = \exp \left( (c_{+}(\delta) \vec{\theta}_{+} - c_{-}(\delta) \vec{\theta}_{-}) \cdot \vec{x} + b_{+}(\delta, \theta_{+}) - b_{-}(\delta, \vec{\theta}_{-}) + \ln\frac{P_{+}}{P_{-}} \right) = \\
& = \exp( \vec{w} \cdot \vec{x} + c).
\end{align*}

Здесь вектор $\vec{w}$ не зависит от $x$ и является вектором свободных коэффициентов при признаках. Все слагаемые под экспонентой, не зависящие от $x$, можно считать аддитивной добавкой к коэффициенту при константном признаке. Поскольку свободные коэффициенты настраиваются по обучающей выборке, вычислять эту аддитивную добавку нет никакого смысла, и её можно включить в $(\vec{w} \cdot \vec{x})$. Следовательно
$$
\dfrac{P(+1|\vec{x})}{P(-1|\vec{x})} = e^{\vec{w} \cdot \vec{x}},
$$

Используя формулу полной вероятности $P(-1|x) + P(+1|x) = 1$, нетрудно выразить апостериорные вероятности $P(-1|x)$ и $P(+1|x)$ через скалярное произведение $(\vec{w} \cdot \vec{x})$

$$
P(+1|x) = \sigma(+, \vec{w} \cdot \vec{x}),
\quad
P(-1|x) = \sigma(-, \vec{w} \cdot \vec{x}).
$$
Объединяя эти два равенства в одно, получаем исходное выражение
$$
P(y|x) = \sigma((\vec{w} \cdot \vec{x})y).
$$

Таким образом, разделяющая поверхность в Байесовском решающем правиле определяется уравнением $\lambda - P(-1|x) = \lambda + P(+1|x)$, которое равносильно уравнению 
$$
(\vec{w} \cdot \vec{x}) - \ln \frac{\lambda_{-}}{\lambda_{+}} = 0,
$$ 
следовательно, разделяющая поверхность линейна.

Для настройки вектора весов $w$ по обучающей выборке $X^l$ будем максимизировать логарифм правдоподобия выборки

$$
L(w, X^l) = \ln \prod\limits_{i=1}^l p(x_i, y_i)\rightarrow \max_{w}.
$$

Согласно определению условной вероятности, $p(x,y) = P(y|x)p(x)$, где плотности распределения объектов $p(x)$ не зависят от вектора параметров $w$. Апостериорные вероятности выражаются через линейную дискриминантную функцию: $P(y|x) = \sigma\left((\vec{w} \cdot \vec{x})y\right)$. Таким образом

$$
L\left(w, X^l\right) =  \sum_{i=1}^{n} \ln \sigma((\vec{w} \cdot \vec{x})y) + c \rightarrow \max_{w}.
$$
Максимизация правдоподобия $L\left(w, X^l\right)$ эквивалентна минимизации функционала $\tilde{Q}\left(w, X^l\right)$, гладко аппроксимирующего эмпирический риск
$$
\tilde{Q}\left(w, X^l\right) = 
\sum_{i=1}^{n} \ln{\left(1 + \exp{(-(\vec{w} \cdot \vec{x_i})y_i)}\right)} \rightarrow \min_{w}.
$$

Таким образом, логистическая функция потерь $Z(M)= \ln{\left(1 + e^{-M}\right)}$ является следствием экспонентности классов и принципа максимума правдоподобия.

Запишем градиент функционала $\tilde{Q}(w)$, воспользовавшись выражением для производной сигмоидной функции $\sigma'(z) = \sigma(z)(1 - \sigma(z)) = \sigma(z)\sigma(-z)$,
и получим логистическое правило обновления весов для градиентного шага в методе стохастического градиента \cite{Galanin2010}
$$
\vec{w} := \vec{w} + \eta y_i \vec{x_i} \sigma(-(\vec{w} \cdot \vec{x_i})y_i),
$$
где $(\vec{x}_i, y_i)$ --- предъявляемый прецедент, $\eta$ --- темп обучения.

\subsubsection*{Вычислительные возможности нейронных сетей}

Человеку и высшим животным буквально на каждом шагу приходится распознавать, принимать решения и обучаться. Нейросетевой подход возник из стремления
понять, каким образом мозг решает столь сложные задачи, и реализовать эти принципы в автоматических устройствах. Пока искусственные нейронные сети (artificial neural networks, ANN) являются лишь предельно упрощёнными аналогами естественных нейронных сетей. Нервные системы животных и человека гораздо сложнее тех устройств, которые можно создать с помощью современных технологий. Однако для успешного решения многих практических задач оказалось вполне достаточно ``подсмотреть'' лишь общие принципы функционирования нервной системы. Некоторые разновидности ANN представляют собой математические модели, имеющие лишь отдалённое сходство с нейрофизиологией, что отнюдь не препятствует их практическому применению.

Итак, отдельно взятый нейрон вида (\ref{eq:lin_clf}) позволяет реализовать линейный классификатор или линейную регрессию. При решении практических задач линейность
оказывается чрезмерно сильным ограничением. На ограниченность персептрона указывали Минский и Пайперт в своей знаменитой книге 
``Персептроны'' \cite{Minsky1968}.

Следующие утверждения показывают, что любую функцию можно аппроксимировать с помощью нейронной сети.\\
%\begin{enumerate}
1.~Любая булева функция представима в виде двухслойной сети. Это тривиальное следствие нейронной представимости логических функций И, ИЛИ, НЕ и представимости
произвольной булевой функции в виде дизъюнктивной нормальной формы \cite{Hastie2001}.\\
2.~Из простых геометрических соображений вытекает, что двухслойная сеть
с пороговыми функциями активации позволяет выделить произвольный выпуклый
многогранник в $n$--мерном пространстве признаков. Трёхслойная сеть позволяет вычислить любую конечную линейную комбинацию характеристических функций выпуклых многогранников, следовательно, аппроксимировать любые области с непрерывной границей, включая невыпуклые и даже неодносвязные, а также аппроксимировать любые непрерывные функции.\\
3.~В 1900 году Гильберт предложил список из 23 нерешённых задач, которые,
по его мнению, должны были стать вызовом для математиков XX века. Тринадцатая проблема заключалась в следующем: возможно ли произвольную непрерывную
функцию $n$ аргументов представить в виде суперпозиции функций меньшего числа
аргументов. Ответ был дан А. Н. Колмогоровым. Теорема Колмогорова утверждает, что любая непрерывная функция $n$ аргументов на единичном кубе $[0, 1]^n$ представима в виде суперпозиции непрерывных функций одного аргумента и операции сложения:
$$
f(x_1, \ldots, x_n) = \sum_{k=1}^{2n+1} h_k \left(\sum_{i=1}^{n} \varphi_{i,k}(x_i) \right),
$$
где $h_k$, $\varphi_{i,k}$ --- непрерывные функции, причём $\varphi_{i,k}$ не зависят от выбора $f$. Нетрудно видеть, что записанное здесь выражение имеет структуру нейронной сети с одним скрытым слоем из $2n + 1$ нейронов. Таким образом, двух слоёв уже
достаточно, чтобы вычислять произвольные непрерывные функции, и не приближённо, а точно. К сожалению, представление Колмогорова не является персептроном:
функции $\varphi_{i,k}$ не линейны, а функции $h_k$ зависят от $f$, и в общем случае не являются
дифференцируемыми.\\
4.~Известна классическая теорема Вейерштрасса о том, что любую непрерывную функцию $n$ переменных можно равномерно приблизить полиномом с любой степенью точности. Более общая теорема Стоуна утверждает, что любую непрерывную
функцию на произвольном компакте $X$ можно приблизить не только многочленом
от исходных переменных, но и многочленом от любого конечного набора функций $F$,
разделяющих точки \cite{Kolmogorov1958}.
%\end{enumerate}

Таким образом, нейронные сети являются универсальными аппроксиматорами
функций. Возможности сети возрастают с увеличением числа слоёв и числа нейронов в них. Двух--трёх слоёв, как правило, достаточно для решения подавляющего
большинства практических задач классификации, регрессии и прогнозирования.

\subsubsection*{Метод обратного распространения ошибки}

Рассмотрим многослойную сеть, в который каждый нейрон предыдущего слоя
связан со всеми нейронами последующего слоя (рис. \ref{fig:fcnn_ex}). Такая сеть называется полносвязной. Для большей общности положим $X = \mathbb{R}^n, Y = \mathbb{R}^M$.

Пусть выходной слой состоит из $M$ нейронов с функциями активации $\sigma_m$ и выходами $a^m,~m=1,\ldots,M$. Перед ним находится скрытый слой из $H$ нейронов с функциями активации $\sigma_h$ и выходами $u^h, h=1,\ldots,H$.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.55]{fcnn_ex.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:fcnn_ex}
\end{figure}

Веса синаптических связей между $h$--м нейроном скрытого слоя и $m$--м нейроном выходного слоя будем обозначать через $w_{h,m}$. Перед этим слоем может находиться либо входной слой признаков (называемый также распределительным слоем), либо ещё один скрытый слой с выходами $v^j, j = 1,\ldots, J$ и синаптическими весами $w_{j,h}$. В общем случае число слоёв может быть произвольным. Если сеть двухслойная, то $v^j$
есть просто $j$--й признак: $v^j(x) = f_j(x) = x^j$ и, $J = n$. Обозначим через $w$ вектор всех синаптических весов сети. 

Выходные значения сети на объекте $x_i$ вычисляются как суперпозиция:

$$
a^m(x_i) = \sigma_m \left( \sum_{h=0}^{H} w_{h,m} u^h(x_i) \right),
\quad
u^h(x_i) = \sigma_h \left( \sum_{j=0}^{J} w_{j,h} u^j(x_i) \right).
$$

Зафиксируем объект $x_i$ и запишем функционал среднеквадратичной ошибки
(для других функций потерь выкладки могут быть проделаны аналогично):

$$
Q(w) = \frac{1}{2} \sum_{m=1}^{M} (a^m(x_i) - y_i^m)^2.
$$

В дальнейшем нам понадобятся частные производные $Q$ по выходам нейронов.
Выпишем их сначала для выходного слоя
\begin{equation}
\dfrac{\partial Q}{\partial a^m} = a^m(x_i) - y_i^m = \varepsilon_i^m,
\label{eq:partial_q}
\end{equation}
Из данного выражения видно, что частная производная $Q$ по $a^m$ равна величине ошибки $\varepsilon_i^m$ на объекте $x_i$. Теперь выпишем частные производные по выходам скрытого слоя
$$
\dfrac{\partial Q}{\partial u^h} = \sum_{m=1}^{M} (a^m(x_i) - y_i^m) \sigma'_m w_{h,m} = \sum_{m=1}^{M} \varepsilon_i^m \sigma'_m w_{h,m} = \varepsilon_i^h.
$$

Эту величину, по аналогии с $\varepsilon_i^m$, будем называть ошибкой сети на скрытом слое и обозначать через $\varepsilon_i^h$. Через $\sigma'_m$ обозначена производная функции активации,
вычисленная при том же значении аргумента, что и в (\ref{eq:partial_q}). Если используется сигмоидная функция активации, то для эффективного вычисления производной можно
воспользоваться формулой
$$
\sigma'_m = \sigma_m (1 - \sigma_m) = a^m(x_i) (1 - a^m(x_i)).
$$

Стоит заметить, что $\varepsilon_i^h$ вычисляется по $\varepsilon_i^m$, если запустить сеть ``задом наперёд'', подав на выходы нейронов скрытого слоя значения $\varepsilon_i^m \sigma'_m$, а результат $\varepsilon_i^h$ получив на входе. При этом входной вектор скалярно умножается на вектор весов $w_{hm}$, находящихся справа от нейрона, а не слева, как при прямом вычислении (рис. \ref{fig:backpropagation}), отсюда и название алгоритма --- обратное распространение ошибок.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.7]{backpropagation.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:backpropagation}
\end{figure}

Имея частные производные по $a^m$ и $u^h$, можно выписать градиент $Q$ по весам:
\begin{align*}
 & \dfrac{\partial Q}{\partial w_{h,m}} = \dfrac{\partial Q}{\partial a^m} \dfrac{\partial a^m}{\partial w_{h,m}} = \varepsilon_i^m \sigma'_m u^h(x_i), \quad m=1,\ldots,M, \quad h=0,\ldots,H;\\
 & \dfrac{\partial Q}{\partial w_{j,h}} = \dfrac{\partial Q}{\partial u^h} \dfrac{\partial u^h}{\partial w_{j,h}} = \varepsilon_i^h \sigma'_h u^j(x_i), \quad h=1,\ldots,H, \quad j=0,\ldots,J;
\end{align*}
и так далее для каждого слоя. Если слоёв больше двух, то остальные частные производные вычисляются аналогично --- обратным ходом по слоям сети справа налево. 

Теперь мы обладаем всем необходимым, чтобы полностью выписать алгоритм обратного распространения

К достоинствам метода обратного распространения можно отнести следующие свойства

\begin{itemize}
  \item   Достаточно высокая эффективность. В случае двухслойной сети прямой ход, обратный ход и вычисления градиента требуют порядка $O(Hn+HM)$ операций.
  \item   Через каждый нейрон проходит информация только о связных с ним нейронах. Поэтому back--propagation легко реализуется на вычислительных устройствах с параллельной архитектурой
  \item  Высокая степень общности. Алгоритм легко записать для произвольного числа слоёв, произвольной размерности выходов и выходов, произвольной функции потерь и произвольных функций активации, возможно, различных у разных нейронов. Кроме того, back--propagation можно применять совместно с различными градиентными методами оптимизации: методом скорейшего спуска, сопряженных градиентов, Ньютона--Рафсона и др.
\end{itemize}

Недостатками метода обратного распространения являются следующие факты
\begin{itemize}
  \item Метод наследует известные недостатки градиентной настройки весов в однослойном персептроне. Здесь также возникают проблемы медленной сходимости или расходимости, ``застревания'' в локальных минимумах функционала $Q$, переобучения и паралича. Причём парализоваться могут отдельные связи, нейроны, или вся сеть в целом.
  \item Приходится заранее фиксировать число нейронов скрытого слоя $H$. В то же время, это критичный параметр сложности сети, от которого может существенно зависеть качество обучения и скорость сходимости.
\end{itemize}


\subsection{Результаты расчетов и сравнение моделей}

Согласно статье \cite{Yang2014} была произведена разметка уникальных точек на отрезке $[0, 1]$ с шагом $0.1$ и вычислена оптимальная пороговая точность $\alpha = 0.75$, которая обеспечивает оптимальный precision и recall для нашей модели и минимизует дисперсию ошибки.

\subsubsection*{Результаты расчетов для логистической регрессии}

В табл. \ref{tab:log_reg} отражены метрики классификации для различных способов векторизации текста.

\begin{table}[h!]
\caption{Метрики для логистической регрессии}
\label{tab:log_reg}
\begin{center}
  \begin{tabular}{ | c | c | c | c | c |}
    \hline
               & precision & recall & accuracy & $f_1$ \\ \hline
     BOW       & 0.91143 & 0.99961 & 0.91234 & 0.92325 \\ \hline
     Fast Text & 0.95523 & 0.89164 & 0.96254 & 0.93645 \\ \hline
  \end{tabular}
\end{center}
\end{table}

Из приведенной таблицы видно, что логистическая регрессия построенная поверх Fast Text эмбенигов работает лучше, относительно BOW метода векторизации. Однако этой точности недостаточно для решения задачи.

\subsubsection*{Результаты расчетов для сверточной сети}

Полносвязная нейронная сеть для нашей задачи имеет 3 слоя. На каждом слое производится регуляризация данных. В нашем случае нейронную сеть можно определить формулой:
\begin{align*}
& a(x) = h_2 \left(\sum_{k=0}^{n_2} w''_k h_1\left(\sum_{j=0}^{n_1} w'_j h_0\left( \sum_{i=0}^{n_0} w_i x_i \right)\right)\right), \\
& h_2(x) = \dfrac{1}{1+e^{-x}}, \quad h_0(x) = h_1(x) = 
\begin{cases} 
x, & x > 0, \\
0, & x \leqslant 0.
\end{cases}
\end{align*}
где $h_i$ --- функция активации для соответствующего слоя. Для нахождения весов $\{w_i\}_{i=0}^{n_0}$, $\{w'_j\}_{j=0}^{n_1}$, $\{w''_k\}_{k=0}^{n_2}$ на этапе обучения модели используется градиентный метод Адама.

В табл. \ref{tab:fcnn} отражены метрики классификации для различных способов векторизации текста.

\begin{table}[h!]
\caption{Метрики для $FCNN$ моедли}
\label{tab:fcnn}
\begin{center}
  \begin{tabular}{ | c | c | c | c | c |}
    \hline
               & precision & recall & accuracy & $f_1$ \\ \hline
     BOW       & 0.93604 & 0.95643 & 0.97234 & 0.99474 \\ \hline
     Fast Text & 0.99931 & 0.91263 & 0.99468 & 0.99875 \\ \hline
  \end{tabular}
\end{center}
\end{table}

Из приведенной таблицы видно, на тех же методах векторизации $FCNN$ модель имеет намного лучшие результаты. При этом вектрозизация при помощи метода Fast Text соответствует установленным в задаче требованиям на точность классификатора.

На рис. \ref{fig:train_loss} отражена сходимость функции потерь на тренировочных данных, коррелирующая с ростом precision (рис. \ref{fig:train_precision}). На рис. \ref{fig:test_loss}, \ref{fig:test_precision} отображены результаты валидации модели на тестовых данных. Анализируя эти графики можно сделать вывод, что не смотря на большое количество итераций требуемых для обучения модели, алгоритм является сходящимся минуя эффект переобучения. 
\begin{figure}[h!]
	\center
	\includegraphics[scale=1.5]{train_loss.jpg}
	\caption{Изменение функции потерь на тренировочной выборке}
	\label{fig:train_loss}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.5]{train_precision.jpg}
	\caption{Изменение precision на тренировочной выборке}
	\label{fig:train_precision}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.5]{test_loss.jpg}
	\caption{Изменение функции потерь на тестовой выборке}
	\label{fig:test_loss}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.5]{test_precision.jpg}
	\caption{Изменение precision на тестовой выборке}
	\label{fig:test_precision}
\end{figure}

На рис. \ref{fig:dist_prob} отображено распределение вероятностей классификатора с шагом $0.1$ на реальных потоковых письмах пользователей. Метрики $ham$ и $spam$ отображают количество писем, отмеченных классификатором как ``не спам'' и ``спам'' соответственно.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.65]{dist_prob.jpg}
	\caption{Распределение вероятностей классификатора}
	\label{fig:dist_prob}
\end{figure}


\subsubsection*{Сравнение моделей}

Сравним метрики классификатора, построенного на логистической регрессии при помощи векторизации BOW (old clf) и классификатора, построенного на полносвязной нейросети при помощи векторизации word2vec (new clf).

На рис. \ref{fig:old_vs_new_fp} отображено количество жалоб на старый и новый классификатор за сутки. Из него видно, что на новый классификатор пользователи жалуются почти в 2.5 раза меньше.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.65]{old_vs_new_fp.jpg}
	\caption{Сравнение жалоб на старый и новый классификатор}
	\label{fig:old_vs_new_fp}
\end{figure}

На рис. \ref{fig:old_vs_new_ps} отображено количество писем, которые старый и новый классификатор отметили как ``спам'' за сутки. Анализируя графики на рис. \ref{fig:old_vs_new_fp} и рис. \ref{fig:old_vs_new_ps} можно увидеть, что новый классификатор работает существенно лучше старого, за счет того, что он блокирует в 1.5 раза больше писем, при этом на его решения поступает в 2.5 раза меньше жалоб.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.65]{old_vs_new_ps.jpg}
	\caption{Сравнение блокировок старого и нового классификатора}
	\label{fig:old_vs_new_ps}
\end{figure}

На рис. \ref{fig:old_vs_new_status} отображено пересечение статусов старого и нового классификатора за сутки. Метрика $spam2ham$ отображает количество писем, которые старый классификатор отметил как $spam$, а новый как $ham$ (не спам). Метрика $ham2spam$ наоборот, показывает сколько писем старый классификатор отметил как $ham$, а новый отправил в $spam$. В метрике $spam2spam$ оба классификатора сочли письмо спамом. Из данного графика видно, что классификаторы имеют достаточно сильное перечение (около 60\%), но при этом отличаются в части блокировок, что вносит ключевой эффект на количество жалоб на рис. \ref{fig:old_vs_new_fp}.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{old_vs_new_status.jpg}
	\caption{Сравнение статусов старого и нового классификатора}
	\label{fig:old_vs_new_status}
\end{figure}

На рис. \ref{fig:is_not_spam_yeas_2_yeas} и рис. \ref{fig:is_spam_yeas_2_yeas} отображено общее количество жалоб пользователей на письма попавшие в спам по ошибке и наоборот, на спам, который попал во входящие за этот и прошлый год. Из графиков видно, что количество жалоб существенно снизилось относительно прошлого года, в том числе благодаря новому классификатору.
\begin{figure}[h!]
	\center
	\includegraphics[scale=0.7]{is_not_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб ``это не спам'' за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.65, width=16cm]{is_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб ``это спам'' за этот и прошлый год}
	\label{fig:is_spam_yeas_2_yeas}
\end{figure}


\newpage
\section{ПОСТРОЕНИЕ АРХИТЕКТУРЫ ПРИЛОЖЕНИЯ}

\subsection{Обзор библиотек}

Поскольку от сервисов требуется высокая производительность, то для его написания выбран язык C++ (stl17, grpc, boost), как один из самых производительных современных языков \cite{Kleppmann2018},\,\cite{Meyers2014}. Для анализа данных и обучения fcnn модели использовался язык Python3 и фреймврок pyTorch за счет высокой эффективности и возможности проведения параллельных вычислений, как на cpu, так и на gpu ядрах машины \cite{Muller2014}.

Отказоустойчивость микросервисов обеспечивается за счет их развертки в kubernetes (k8s) кластере, так как при падении любого пода по какой--либо причине запросы равномерно сбалансируются по оставшимся живым подам, до тех пор, пока кластер самостоятельно не вернется к прежнему состоянию \cite{Elder2019}. Внутри него можно настроить: автоматическую балансировку нагрузки с помощью постоянного мониторинга сведений о производительности и используемых ресурсах (autoscaling) и грамотное размещение подов внутри кластера по дата центрам (affinity).

\subsection{Построение микросервисной архитектуры}

Так как сервис должен работать под высокими нагрузками важно обеспечить архитектуру, при которой выход из строя одной компоненты не приведет к деградации всей системы \cite{Newman2019}. Реализована следующая клиент--серверная архитектура (рис. \ref{fig:app_arch}). Antispam daemon (mrasd) парсит входящие сообщение и извлекает оттуда текст, изображения, файлы.  Поскольку нежелательные данные часто содержатся внутри вложенных изображений и документов, то из них также необходимо извлечь текст. Для этого через отложенную redis очередь документы оправляются в OCR (optical character recognition, отпическое распознавание текста) сервис, который извлекает текст и сохраняет результат в redis cache \cite{Petrov2019}.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.25]{deploy.jpg}
	\caption{Архитектура приложения}
	\label{fig:app_arch}
\end{figure}

В связи с тем, что с большой вероятностью письмо может быть дубликатом (например в случае ddos атаки или оффлайн перепроверки), то чтобы не нагрузать лишний раз OCR сервис, производится первичная проверка redis cache на наличие уже обработанных данных по заданному хэшу документа.

После полного извлечения текста сервис mrasd производит все этапы предобработки текста (приведение к одному регистру, удаление стоп слов, нормализация), а затем отправляет текст в сервис mlapi по протоколу grpc для векторизации текста при помощи Fast Text и дальнейшего получения предсказания fcnn модели по которому принимается решение о ``нежелательности''  входящего сообщения.

Предложенная архитектура хороша тем, что при выходе из строя OCR сериса, одного (или нескольких) инстансов redis сluster, не деградирует вся система в целом.

\subsection{Результаты работы приложения}

На рис. \ref{fig:processed_messages} отображено среднее количество обрабатываемых сообщений для одной из ферм спам--фильтра в течении суток. На рис. \ref{fig:timings} отражено среднее время обработки одного письма в течении суток. Из приведенных графиков видно, что не смотря на высокую нагрузку в течении суток система успешно справляется с обработкой потоковых данных в среднем менее, чем за 500 мс. 

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{processed_messages.png}
	\caption{Среднее количество запросов в минуту с одной из ферм}
	\label{fig:processed_messages}
\end{figure}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{timings.png}
	\caption{Среднее время обработки письма}
	\label{fig:timings}
\end{figure}

На рис. \ref{fig:pdf_flow}, \ref{fig:image_flow} отображено среднее количество отправляемых pdf и изображений в сервис OCR для распознавания. На рис. \ref{fig:ocr_time} демонстрируется время обработки и извлечение текста сервисом OCR. Анализируя эти графики можно увидеть сильную неоднородность потока изображений и pdf в течении суток, но несмотря на это достаточно быстрое время отклика от сервиса OCR, во многом благодаря распределенной системе построенной на redis очереди.

\begin{figure}[H]
	\center
	\includegraphics[width=.8\linewidth]{pdf_flow.jpg}
	\caption{Поток pdf в сервис OCR}
	\label{fig:pdf_flow}
\end{figure}

\begin{figure}[H]
	\center
	\includegraphics[width=1.\linewidth]{image_flow.jpg}
	\caption{Поток изображений в сервис OCR}
	\label{fig:image_flow}
\end{figure}

На рис. \ref{fig:mlapi_flow}, отображено среднее количество запросов в сервис mlapi. В их число входят запросы на векторизацию текста и на предсказания модели. На рис. \ref{fig:mlapi_time} отражено среднее время отклика сервисом mlapi. Из приведенных графиков также видно, что не смотря на большую потоковую нагрузку сервис успешно справляется со своей задачей.

\begin{figure}[tbh!]
	\center
	\includegraphics[width=1.\linewidth]{extract_time.jpg}
	\caption{Среднее время обработки изображения сервисом OCR}
	\label{fig:ocr_time}
\end{figure}

\begin{figure}[tbh!]
	\center
	\includegraphics[width=.9\linewidth]{mlapi_flow.jpg}
	\caption{Количество запросов в сервис mlapi}
	\label{fig:mlapi_flow}
\end{figure}

\begin{figure}[tbh!]
	\center
	\includegraphics[width=.9\linewidth]{mlapi_time.jpg}
	\caption{Среднее время ответа на запрос сервисом mlapi}
	\label{fig:mlapi_time}
\end{figure}

\newpage\null\newpage
\section-{ЗАКЛЮЧЕНИЕ}
В данной работе проведено исследование различных подходов к предобработке, векторизации и классификации данных. Произведена разметка данных для провеки качества модели. Приведены результаты, полученные в ходе обучения модели на реальных потоковых данных пользователей. Проведено сравнение исследуемых алгоритмов. По приведенным данным можно сделать заключение о том, что $FCNN$ модель на основе алгоритма Fast Text эмбедингов имеет наивысшую точность классификации, по сравнению с методами классической логистической регрессии и $FCNN$ модели на основе мешка слов.

Спроектирована и реализована высокопризводительное отказоустойчивое приложенение имеющее микросервисную архитектуру, которое выдерживает в среднем более $10^6$ запросов в минуту, имеет высокое время отклика и надежность. При этом деградация конкретной компоненты, машины или датацентра не приводит к полному отказу всей системы. Данное приложение было покрыто всеми видами тестов и запущено в нескольких датацентрах.

Произведен запуск приложения на реальных пользователях продуктов Mail.ru Group, что увеличило количество блокировок спама на 10\%. Выполнен анализ реакции пользователей на новую подсистему. Анализируя данные о жалобах за этот и прошлый год можно увидеть, что существенно снизилось количество жалоб ``это спам'' на письма в папке входящие и жалоб ``это не спам'' в папке ``спам''. Внедрение модели увеличило удобство использования продуктов компании.

\newpage
\begin{thebibliography}{17}
\bibitem{Makkar2021} 
\textbf{Makkar A., Ghosh U., Sharma P.K.} Artificial Intelligence and Edge Computing-enabled Web Spam Detection for Next Generation IoT Applications. IEEE Sensors Journal. 2021. 

\bibitem{Taylor2020}
\textbf{Taylor O.E., Ezekiel P.S.} A Model to Detect Spam Email Using Support Vector Classifier and Random Forest Classifier.
International Journal of Computer Science and Mathematical Theory. 2020.

\bibitem{Garg2021}
\textbf{Garg P., Girdhar N.} A systematic review on spam filtering techniques based on natural language processing framework. 11th International Conference on Cloud Computing, Data Science Engineering. 2021.

\bibitem{Sidn2019}
\textbf{Сидняев Н.И.} Теория вероятностей и математическая статистика. Учебник для СПО. Москва. Юрайт. 2019. 220 с.

\bibitem{Parmar2020}
\textbf{Parmar N., Sharma A., Jain H., Kadam K.A.} Email Spam Detection using Nave Bayes and Particle Swarm Optimization. IJIRT. 2020.

\bibitem{Mohammad2020}
\textbf{Mohammad R.M.} A lifelong spam emails 	classification model. Applied Computing and Informatics. 2020.

\bibitem{Mikolov2013_Efficient}
\textbf{Mikolov T., Chen K., Corrado G., Dean J.} Efficient estimation of word representations in vector space. arXiv:1301.3781v3. 2013.

\bibitem{Mikolov2013_Distributed}
\textbf{Mikolov T., Chen K., Corrado G., Dean J.} Distributed representations of words and phrases and their compositionality. 27th Annual Conference on Neural Information Processing System. 2013.

\bibitem{Bojanowski2017}
\textbf{Bojanowski P., Grave E., Joulin A., Mikolov T.} Enriching word vectors with subword information. arXiv:1607.04606v2. 2017.

\bibitem{Bommannavar2014}
\textbf{Bommannavar P., Kolcz A., Rajaraman A.} Recall estimation for rare topic retrieval from large corpuses.  IEEE International Conference on Big Data. 2014.

\bibitem{Voron2021}
\textbf{Воронцов К.В.} Математические методы обучения по прецедентам (теория обучения машин). Москва. МФТИ. 2021.

\bibitem{Yang2014}
\textbf{Yang S., Kolcz A., Schlaikjer A., Gupta P.} Large-scale high-precision topic modeling on twitter. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 2014.

\bibitem{Petrov2019}
\textbf{Petrov A.} Database Internals. O'Reilly Media, Inc. Williams. 2019.

\bibitem{Churikov2004} \textbf{Churikov D.V.} Atomic functions and combined algorithm of image filtration in conditions of high intensity noise. Radiotekhnika 9. Russian. 2004.

\bibitem{Kravchenko2005}
\textbf{Kravchenko V.F., Fedorov I.B., Churikov D.V. and Rvachev V.L.} $R-$functions and the atomic functions in problems of complex-shaped contour objects description and digital image processing. EW \& ES. Russian. 2005.

\bibitem{Gahov2014}
\textbf{Гахов A.K.} Интеллектуальный анализ данных. ХГНУ им. В.Н. Карамзина. Харьков. 2014.

\bibitem{Minsky1968}
\textbf{Minsky M., Papert S.} Perceptrons an Introduction to Computational Geometry. MIT Press. 1968.

\bibitem{Zagugoiko1985}
\textbf{Загоруйко Н.Г., Ёлкина В.Н., Лбов Г.С.} Алгоритмы обнаружения эмпирических закономерностей. Наука. Новосибирск. 1985.

\bibitem{Kolmogorov1958}
\textbf{Колмогоров А.Н.} О представлении непрерывных функций нескольких переменных в виде суперпозиции непрерывных функций одного переменного. Докл. АН СССР. Т. 114. С. 953-956. 1958.

\bibitem{Elder2019}
\textbf{Elder M., Jake Kitchener J., Topol D.B.} Kubernetes in the enterprise. O'Reilly Media, Inc. Williams. 2019.

\bibitem{Newman2019}
\textbf{Newman S.} Monolith to Microservices. O'Reilly Media, Inc. Williams. 2019.

\bibitem{Galanin2010}
\textbf{Галанин М.П., Савенков Е.Б.} Методы численного анализа математических моделей. Москва: Изд-во МГТУ им. Н.Э. Баумана, 591~с. 2010.

\bibitem{Hastie2001}
\textbf{Hastie T., Tibshirani R., Friedman J.} The Elements of Statistical Learning. Springer. 533 p. 2001.

\bibitem{Kleppmann2018}
\textbf{Kleppmann M.} Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems. O'Reilly Media, Inc. Williams. 120-200 p. 2018.

\bibitem{Meyers2014}
\textbf{Meyers S.} Effective Modern C++. Recommendations for using C++ 11 and C++ 14. O'Reilly Media, Inc. Williams. 2014.

\bibitem{Muller2014}
\textbf{Muller A. C., Guido S.} Introduction to Machine Learning with Python: A Guide for Data Scientists. O'Reilly Media, Inc. Williams. 2017.

\end{thebibliography}

\newpage
\section-{ПРИЛОЖЕНИЕ А}

\begin{lstlisting}[language=Python, caption=Класс модели]
import torch
from torch import nn

from pytorch_lightning.core.lightning import LightningModule
from pytorch_lightning.metrics.classification import Precision, Recall


class NiggerClassifier(LightningModule):
    TRAIN = 'train'
    VALID = 'valid'
    metric_classes = {
        'precision': Precision,
        'recall': Recall,
        # 'fpr': FPR
    }

    def __init__(
            self,
            layers_size,
            dropout,mystyle
            optimizer_lr,
            scheduler_factor,
            scheduler_patience,
            clf_thr=0.75,
    ):
        super().__init__()

        self.layers_size = layers_size
        self.dropout = dropout
        self.optimizer_lr = optimizer_lr
        self.scheduler_factor = scheduler_factor
        self.scheduler_patience = scheduler_patience
        self.clf_thr = clf_thr

        self.fcnn = nn.Sequential(
            nn.Linear(self.layers_size[0], self.layers_size[1]),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(self.layers_size[1], self.layers_size[2]),
            nn.ReLU(),
            nn.Dropout(self.dropout),
            nn.Linear(self.layers_size[2], self.layers_size[3]),
            nn.Sigmoid(),
        )

        self.loss = nn.BCELoss()  # MSELoss

        metrics = {}
        for prefix in (self.TRAIN, self.VALID):
            for metric_name, metric_class in self.metric_classes.items():
                metrics[f'{prefix}_{metric_name}'] = metric_class()
        self.metrics = nn.ModuleDict(metrics)
        self.epoch_metric_names = list(self.metrics.keys())

        self.save_hyperparameters()

    def forward(self, input_vector: torch.Tensor) -> torch.Tensor:
        return self.fcnn(input_vector)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.optimizer_lr)
        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, factor=self.scheduler_factor, patience=self.scheduler_patience)

        return {
            'optimizer': optimizer,
            'lr_scheduler': lr_scheduler,
            'monitor': f'{self.VALID}_loss',
        }

    def step(self, batch, batch_idx, prefix):
        x, y = batch

        y_raw_pred = self(x)
        y_pred = (y_raw_pred >= self.clf_thr).long()  # [batch_size, 1]

        for key in self.metric_classes.keys():
            self.metrics[f'{prefix}_{key}'](y_pred, y)

        return {'loss': self.loss(y_raw_pred, y.float())}

    def epoch_end(self, outputs, prefix):
        epoch_metrics = {}

        epoch_metrics[f'{prefix}_loss'] = torch.stack(
            [item['loss'] for item in outputs]).mean()
        for key, value in self.metrics.items():
            if key.startswith(prefix):
                epoch_metrics[key] = value.compute()

        self.log_dict(epoch_metrics, logger=True, prog_bar=True)

    def training_step(self, batch, batch_idx):
        return self.step(batch, batch_idx, self.TRAIN)

    def training_epoch_end(self, outputs):
        return self.epoch_end(outputs, self.TRAIN)

    def validation_step(self, batch, batch_idx):
        return self.step(batch, batch_idx, self.VALID)

    def validation_epoch_end(self, outputs):
        return self.epoch_end(outputs, self.VALID)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Класс для хранения выборки]
import numpy as np
import pandas as pd
import json
import torch
from common import config
from sklearn.model_selection import train_test_split

OLD_DATASET = 0
NEW_DATASET = 1


def get_old_dataset(path_to_dataset, input_size):
    data = pd.read_csv(path_to_dataset, sep=',')
    x = np.zeros((0, input_size))
    y = np.empty(0, dtype=bool)

    for idx in range(data['index'].size):
        elem = data['embed'][idx]
        if type(elem) != str:
            # print('invalid type')
            continue

        vec = json.loads(elem)
        if not np.any(vec):
            # print('zero vector')
            continue

        x = np.zeros((0, input_size))
        y = np.append(y, data['email'][idx].endswith('_1.eml'))

    return x, y

def get_new_dataset(path_to_dataset, input_size):
    data = pd.read_csv(path_to_dataset, sep=',')
    x = np.zeros((0, input_size))
    y = np.empty(0, dtype=bool)

    num_ham, hum_spam = 0, 0
    for idx in range(data['y'].size):
        elem = data['x'][idx]
        if type(elem) != str:
            # print('invalid type')
            continue

        vec = json.loads(elem)
        if not np.any(vec):
            # print('zero vector')
            continue

        x = np.vstack((x, vec))

        is_spam = data['y'][idx]
        y = np.append(y, is_spam)
        if is_spam:
            hum_spam += 1
        else:
            num_ham += 1

    config.LOG('ham: ' + str(num_ham) + ' spam: ' +
               str(hum_spam) + ' sum: ' + str(num_ham + hum_spam))

    return x, y

def get_train_loaders(path_to_old_dataset, path_to_new_dataset,
                      input_size, batch_size, device, num_workers, dataset_type):
    x = np.zeros((0, input_size))
    y = np.empty(0, dtype=bool)
    if dataset_type == OLD_DATASET:
        x, y = get_old_dataset(path_to_old_dataset, input_size)
    if dataset_type == NEW_DATASET:
        x, y = get_new_dataset(path_to_new_dataset, input_size)

    x_train, x_val, y_train, y_val = train_test_split(
        x, y, test_size=0.2, random_state=42, stratify=y)

    x_train = torch.from_numpy(x_train).float().to(device)
    y_train = torch.from_numpy(y_train).long().unsqueeze(1).to(device)
    x_val = torch.from_numpy(x_val).float().to(device)
    y_val = torch.from_numpy(y_val).long().unsqueeze(1).to(device)

    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)

    val_dataset = torch.utils.data.TensorDataset(x_val, y_val)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)

    return [train_dataloader, val_dataloader]


def get_test_loaders(path_to_dataset, input_size, batch_size, device, num_workers):
    data = pd.read_json(path_to_dataset, lines=True)
    features = pd.json_normalize(data=data['Features'])
    data = pd.concat([data, features], axis=1)

    x = np.zeros((0, input_size))
    y_pred_old = np.empty(0)

    subject = []
    body = []
    msg_id = []

    for idx in range(data['FTEmbeddings'].size):
        elem = data['FTEmbeddings'][idx]
        if type(elem) != str:
            # print('error type data for idx: ', idx)
            continue

        vec = json.loads(elem)
        if len(vec) != input_size or not np.any(vec):
            # print('error size or data for idx: ', idx)
            continue

        nigger_score = float(data['NiggerMlScore'][idx])
        if nigger_score < 0.0:
            # print('error nigger score for idx: ', idx)
            continue

        x = np.vstack((x, vec))
        y_pred_old = np.append(y_pred_old, nigger_score)

        subject.append(data['Subject'][idx])
        body.append(data['BodyText'][idx])
        msg_id.append(data['MsgID'][idx])

    x = torch.from_numpy(x).float().to(device)
    y_pred_old = torch.from_numpy(y_pred_old).float().unsqueeze(1).to(device)
    dataset = torch.utils.data.TensorDataset(x, y_pred_old)
    dataloader = torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)

    return [dataloader, {'subject': subject, 'body': body, 'msg_id': msg_id}]

def get_test2_loaders(path_to_dataset, input_size, batch_size, device, num_workers):
    x, y = get_new_dataset(path_to_dataset, input_size)

    x = torch.from_numpy(x).float().to(device)
    y = torch.from_numpy(y).long().unsqueeze(1).to(device)

    dataset = torch.utils.data.TensorDataset(x, y)

    return torch.utils.data.DataLoader(
        dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Запуск обучающего скрипта]
from pytorch_lightning import loggers, callbacks, Trainer
from common import config, metric
from models import dataset, model
config.LOG('read dataset')
train_dataloader, val_dataloader = dataset.get_train_loaders(
    config.OLD_DATASET_FILE, config.NEW_DATASET_FILE, config.LAYERS_SIZE[0],
    config.BATCH_SIZE, config.DEVICE, config.NUM_CPU, dataset.NEW_DATASET)
config.LOG('create model')
nigger_model = model.NiggerClassifier(
    layers_size=config.LAYERS_SIZE, dropout=config.DROPOUT, optimizer_lr=config.OPTIMIZER_LEARN_RATE,
    scheduler_factor=config.SCHEDULER_FACTOR, scheduler_patience=config.SCHEDULER_PATIENCE,
    clf_thr=config.CLF_THR).to(config.DEVICE)

config.LOG('fit model')
tensor_logger = loggers.TensorBoardLogger(
    save_dir=config.DATA_PATH, name=config.LOGGER_NAME, version=config.VERSION)
checkpoint_callback = callbacks.ModelCheckpoint(
    dirpath=config.CHECKPOINTS_PATH, verbose=True, filename='{epoch}')
trainer = Trainer(max_epochs=config.MAX_EPOCHS, logger=tensor_logger, callbacks=[
    checkpoint_callback], progress_bar_refresh_rate=1)
trainer.fit(nigger_model, train_dataloader, val_dataloader)

config.LOG('collect metrics')
metric.save_metrics(nigger_model.epoch_metric_names,
                    config.VERSION_PATH, config.CHECKPOINT_METRIC_FILE)
\end{lstlisting}

\end{document}