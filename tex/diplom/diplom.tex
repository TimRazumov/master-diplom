\documentclass[14pt,a4paper]{article}

\usepackage[cp1251]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[footnotes,oglav,spisok,boldsect,eqwhole,kursrab,remarks,hyperprint]{project}

\usepackage{hhline}
\usepackage{multirow}
\usepackage{anyfontsize}
\usepackage{t1enc}
\usepackage{cancel}
\usepackage{float}

\usepackage{extsizes}
\linespread{1.5}
\parindent=1.25cm

\usepackage{geometry}
\geometry{left=3cm, right=1cm, top=2cm, bottom=2cm}

\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand{\thetable}{\arabic{table}}  

\usepackage{comment}

\usepackage{subcaption}
\renewcommand\thesubfigure{\asbuk{subfigure}}

\usepackage{xcolor}
\definecolor{amaranth}{rgb}{0.9, 0.17, 0.31}
\definecolor{amethyst}{rgb}{0.6, 0.4, 0.8}
\definecolor{ao}{rgb}{0.0, 0.0, 1.0}

\graphicspath{ {./images/} }

\begin{document}

\thispagestyle{empty}

\begin{minipage}{0.05\textwidth}
	\hspace{-1.4cm}\vspace{0.5cm}\includegraphics[scale=0.1]{emblema}
\end{minipage}
\hfill
\begin{minipage}{0.95\textwidth}
	\centering
	\linespread{1.0}
	\fontsize{11}{14pt}\selectfont
	\textbf{Министерство образования и науки Российской Федерации \\
	Федеральное государственное бюджетное образовательное учреждение\\высшего профессионального образования\\%
	<<Московский\ государственный\ технический\ университет\\ имени\ Н.\,Э.\,Баумана\\(национальный исследовательский университет)>>\\(МГТУ им. Н.\,Э.\,Баумана)}\\[3mm]
\end{minipage}
\hrule height .7mm

\bigskip

\noindentФАКУЛЬТЕТ <<Фундаментальные науки>> \\
КАФЕДРА <<Высшая математика>>

\bigskip

\begin{center}
	\begingroup
	\fontsize{20pt}{20pt}\selectfont
	\textbf{РАСЧЁТНО-ПОЯСНИТЕЛЬНАЯ ЗАПИСКА} \\ 
	\fontsize{16pt}{20pt}\selectfont
	\textbf{\textit{К~ВЫПУСКНОЙ~КВАЛИФИКАЦИОННОЙ~РАБОТЕ}}\\ 
	\textbf{\textit{НА ТЕМУ:}}
	
	\medskip
	\fontsize{16pt}{20pt}\selectfont 
	\textbf{\textit{
		\underline{ПРИМЕНЕНИЕ МЕТОДОВ МАШИННОГО} 
		\underline{ОБУЧЕНИЯ ДЛЯ РЕШЕНИЯ ЗАДАЧИ}
		\underline{ФИЛЬТРАЦИИ НЕЖЕЛАТЕЛЬНЫХ ДАННЫХ}
	}}
	\endgroup
\end{center}

\bigskip

\noindent
\begin{tabular}{lp{6em}cl}
Студент группы ФН1-41М & & \hspace{3.5cm} & Т.Е. Разумов\\ \cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Руководитель ВКР & & \hspace{3.5cm} & В.Ф. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Консультант & & \hspace{3.5cm} & О.В. Кравченко\\ 
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\

Нормоконтролер & & \hspace{3.5cm} & Н.И. Сидняев\\
\cline{3-3} & & \fontsize{8pt}{8pt}\selectfont(Подпись, дата) &\\
\end{tabular}

\vspace*{\fill}

\begin{center}
	2021 г.
\end{center}



\newpage
\section-{АННОТАЦИЯ}

В настоящей работе решается задача построения модели для обнаружения и фильтрации нежелательных спам-сообщений. В качестве модели классификатора нежелательных писем в электронной почте выбрана полносвязная свёрточная нейронная сеть (\textsf{FCNN}). Она позволяет разделить письма на две категории: \emph{спам} и \emph{не спам}. 

Основным результатом исследования является программное приложение на языке \textsf{C++}, имеющее микро-сервисную архитектуру, и решающее задачу классификации писем. Приложение способно выдерживать более $10^6$ запросов в минуту в режиме реального времени.


\tableofcontents


\newpage
\section-{ВВЕДЕНИЕ}

В настоящее время, объемы производимой человечеством информации
увеличиваются в геометрической прогрессии. Значительную пользу из этой информации можно извлечь лишь при правильной обработке и анализе этих данных. 

С другой стороны, актуальной задачей обработки данных является задача
фильтрации нежелательных данных, а применительно к IT-технологиям --- это задача фильтрации спам-сообщений. Последнее связано с тем, что обмена информацией различной информации по умолчанию используется электронная почта. Электронная почта является одним из самых дешевых, простых в использовании, легкодоступных, наиболее официальных и надежных способов обмена информацией. 

Спам-сообщения, в общем случае могут содержать разнородную тестово-визуальную информацию. Алгоритмы глубокого обучения применяются для анализа спам-писем с различной информацией, поступающих в реальном времени, в \cite{Makkar2021}. При этом, сначала из изображения извлекаются признаки (характеристики), а затем происходит принятие решения. 


Среди других подходов классификации можно выделить, метод опорных векторов и метод случайного леса. В работе \cite{Taylor2020} приводится сравнение этих методов для решения задачи фильтрации спам-сообщений.

Алгоритмы фильтрации являются, как правило, стохастическими \cite{Garg2021} 
и применяются в комбинации с методами оптимизации некоторой целевой функции. 
Для решения задачи классификации электронной почты применяют различные вероятностные модели. Наиболее употребимой среди них является наивный байесовский классификатор. Метод роя частиц является одним из численных методов стохастической оптимизации, его применяют в задачах фильтрации данных, так как не требуется задавать аналитическое выражение градиента оптимизируемой функции. 
Метод роя частиц относится к методам стохастической оптимизации и применяется для эвристической глобальной оптимизации параметров наивного Байесовского классификатора. Комплексный подход с использованием наивного алгоритма Байеса вместе с методом оптимизации роя частиц применялся в \cite{Parmar2020}. 
Эволюционная модель классификации спама представлена в \cite{Mohammad2020}. 


{
\bf\color{amaranth}
Добавить абзацы про задачу и её решение настоящей статьи.
}


\newpage
\section{ОСНОВНЫЕ СВЕДЕНИЯ}

\subsection{Объекты и признаки}

Пусть задано множество объектов $X$, множество допустимых ответов $Y$, и существует целевая функция (target function) $y^*:X \rightarrow Y$, значения которой $ y_i = y^*(x_i)$ известны только на конечном подмножестве объектов $\{x_1, \ldots, x_k\} \subset X$. Пары "объект-ответ" $(x_i, y_i)$ называются прецедентами. Совокупность пар $X^l = (x_i, y_i)_{i=1}^l$ называется обучающей выборкой (training sample).

Задача обучения по прецедентам заключается в том, чтобы по выборке $X^l$ восстановить зависимость $y^*$, то есть построить решающую функцию (decision function) $a: X \rightarrow Y$, которая приближала бы целевую функцию $y^*(x)$, причём
не только на объектах обучающей выборки, но и на всём множестве X. Решающая функция $a$ должна допускать эффективную компьютерную реализацию, по этой причине её называют алгоритмом.

Признак (feature) $f$ объекта $x$ --- это результат измерения некоторой характеристики объекта. Формально признаком называется отображение $f: X \rightarrow D_f$, где $D_f$ --- множество допустимых значений признака. В частности, любой алгоритм $a: X \rightarrow Y$ также можно рассматривать как признак.

В зависимости от природы множества $D_f$ признаки делятся на несколько типов:

\begin{itemize}
  \item  Если $D_f = \{0,1\}$, то $f$ --- бинарный признак
  \item  Если $D_f$ --- конечное множество, то $f$ --- номинальный признак
  \item Если $D_f$ --- конечное упорядоченное множество, то $f$ --- порядковый признак
  \item Если $D_f = \mathbb{R}$, то $f$ --- количественный признак
\end{itemize}

Если все признаки имеют одинаковый тип, $D_{f_1} = \ldots = D_{f_n}$, то исходные данные называются однородными, в противном случае --- разнородными.

Пусть имеется набор признаков $f_1, \ldots , f_n$. Вектор $\big( f1(x), \ldots , fn(x) \big)$ называют признаковым описанием объекта $x \in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания, полагая $X = D_{f_1} \times \ldots \times D_{f_n}$. Совокупность признаковых описаний всех объектов выборки $X^l$, записанную в виде таблицы размера $l \times n$, называют матрицей объектов-признаков:

\begin{equation*}
F = \| f_j(x_i) \|_{l \times n} = \left(
\begin{array}{ccc}
f_1 (x_1) & \ldots & f_n (x_1)\\
\vdots & \ddots & \vdots\\
f_1 (x_l) & \ldots & f_n (x_l)
\end{array}
\right).
\end{equation*}

\subsection{Обучение и функционал качества}

Моделью алгоритмов называется параметрическое семейство отображений $A = \{g(x, \theta) | \theta \in \Theta \}$, где $g : X \times \Theta \rightarrow Y$ --- некоторая фиксированная функция,
$\Theta$ --- множество допустимых значений параметра $\theta$, называемое пространством параметров или пространством поиска (search space).

Процесс подбора оптимального параметра модели $\theta$ по обучающей выборке $X^l$ называют настройкой (fitting) или обучением (training, learning) алгоритма $a \in A$. Метод обучения (learning algorithm) --- это отображение $\mu: (X \times Y)^l \rightarrow A$, которое произвольной конечной выборке $X^l = (x_i, y_i)_{i=1}^l$ ставит в соответствие некоторый алгоритм $a \in A$. Метод обучения должен допускать эффективную программную реализацию.

Итак, в задачах обучения по прецедентам чётко различаются два этапа:
\begin{enumerate}
  \item На этапе обучения метод $\mu$ по выборке $X^l$
строит алгоритм $a = \mu(X^l)$
  \item На этапе применения алгоритм $a$ для новых объектов $x$ выдаёт ответы $y = a(x)$
\end{enumerate}

Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров модели, доставляющих оптимальное значение заданному функционалу качества.

Функция потерь (loss function) --- это неотрицательная функция $Z(a, x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если $Z(a, x) = 0$, то ответ $a(x)$ называется корректным.

Функционал качества алгоритма $a$ на выборке $X^l$:

\begin{equation}
Q(a, X^l) = \dfrac{1}{l} \sum_{i=1}^{l} Z(a, x_i).
\label{eq:empirical_risk}
\end{equation}
Функционал $Q$ называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным $(x_i, y_i)_{i=1}^l$.

Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели $A$ алгоритм $a$, доставляющий минимальное значение функционалу качества $Q$ на заданной обучающей выборке $X^l$:

$$
\mu(X^l) = \operatorname*{argmin}_{a \in A} Q(a, X^l).
$$

\subsection{Вероятностная постановка задачи обучения}

В задачах обучения по прецедентам элементы множества $X$ --- это не реальные объекты, а лишь доступные данные о них. Данные могут быть неточными, поскольку измерения значений признаков $f_j(x)$ и целевой зависимости $y^* (x)$ обычно выполняются с погрешностями. Данные могут быть неполными, поскольку измеряются не все мыслимые признаки, а лишь физически доступные для измерения. В результате одному и тому же описанию $x$ могут соответствовать различные объекты и различные ответы. В таком случае $y^* (x)$, строго говоря, не является функцией. Устранить эту некорректность позволяет вероятностная постановка задачи.

Вместо существования неизвестной целевой зависимости $y^* (x)$ предположим существование неизвестного вероятностного распределения на множестве $X \times Y$ с плотностью $p(x, y)$, из которого случайно и независимо выбираются $l$ наблюдений $X^l = (x_i, y_i)_{i=1}^l$. Такие выборки называются простыми или случайными одинаково распределёнными (independent identically distributed, i.i.d.).

Вероятностная постановка задачи считается более общей, так как функциональную зависимость $y^* (x)$ можно представить в виде вероятностного распределения $p(x, y) = p(x)p(y|x)$, положив $p(y|x) = \delta(y - y^* (x))$, где $\delta(z)$ --- дельта-функция.

При вероятностной постановке задачи вместо модели алгоритмов $g(x, \theta)$, аппроксимирующей неизвестную зависимость $y^* (x)$, задаётся модель совместной плотности распределения объектов и ответов $\varphi(x, y, \theta)$, аппроксимирующая неизвестную плотность $p(x, y)$. Затем определяется значение параметра $\theta$, при котором выборка данных $X^l$ максимально правдоподобна, то есть наилучшим образом согласуется с моделью плотности.

Если наблюдения в выборке $X^l$ независимы, то совместная плотность распределения всех наблюдений равна произведению плотностей $p(x, y)$ в каждом наблюдении: $p(X^l) = p \big( (x_1, y_1), \ldots,  (x_l, y_l) \big)$.  Подставляя вместо $p(x, y)$ модель плотности $\varphi(x, y, \theta)$, получаем функцию правдоподобия (likelihood):

$$
L(\theta, X^l) = \prod\limits_{i=1}^l \varphi(x_i, y_i, \theta).
$$

Чем выше значение правдоподобия, тем лучше выборка согласуется с моделью. Значит, нужно искать значение параметра $\theta$, при котором значение $L(\theta, X^l)$ максимально. После того, как значение параметра $\theta$ найдено, искомый алгоритм $a_\theta(x)$ строится по плотности $\varphi(x, y, \theta)$ несложно.

Вместо максимизации $L$ удобнее минимизировать функционал --- $\ln L$, поскольку он аддитивен по объектам выборки:
$$
-\ln L(\theta, X^l) = - \sum_{i=1}^{l} \ln \varphi(x_i, y_i, \theta) \rightarrow \min_{\theta}
$$

Этот функционал совпадает с функционалом эмпирического риска (\ref{eq:empirical_risk}), если определить вероятностную функцию потерь $L(a_{\theta}, x) = -l \ln \varphi(x_i, y_i, \theta)$. Такое определение потери вполне естественно --- чем хуже пара $(x_i, y_i)$ согласуется с моделью $\varphi$, тем меньше значение плотности $\varphi(x_i, y_i, \theta)$ и выше величина потери $L(a_{\theta}, x)$.

Верно и обратное --- для многих функций потерь возможно подобрать модель плотности $\varphi(x, y, \theta)$ таким образом, чтобы минимизация эмпирического риска была эквивалентна максимизации правдоподобия.

Таким образом, существуют два родственных подхода к формализации задачи обучения: первый основан на введении функции потерь, второй — на введении вероятностной модели порождения данных. Оба в итоге приводят к схожим (иногда даже в точности одинаковым) оптимизационным задачам.

\subsection{Метрики качества обучения}

Перед переходом к самим метрикам необходимо ввести важную концепцию для описания этих метрик в терминах ошибок классификации --- confusion matrix (матрица ошибок). Допустим, что у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта одному из классов, тогда матрица ошибок классификации будет выглядеть следующим образом:
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
                   & $y = 1$ & $y = 0$ \\ \hline
     $\hat{y} = 1$ & True Positive $(TP)$ & False Positive $(FP)$ \\ \hline
     $\hat{y} = 0$ & False Negative $(FN)$ & True Negative $(TN)$ \\ \hline
  \end{tabular}
\end{center}
Здесь $y$ --- это ответ алгоритма на объекте, а $\hat{y}$ ---истинная метка класса на этом объекте. Таким образом, ошибки классификации бывают двух видов: False Positive $(FP)$ и False Negative $(FN)$. В статистике первый вид ошибок называют ошибкой I-го рода, а второй --- ошибкой II-го рода.

Интуитивно понятной и почти неиспользуемой метрикой является accuracy --- доля правильных ответов алгоритма
$$
accuracy= \dfrac{TP+TN}{TP+TN+FP+FN},
$$
Эта метрика бесполезна в задачах с неравными классами, что демонстируется в [.....].

Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота).
$$
precision = \dfrac{TP}{TP + FP}, \quad recall = \dfrac{TP}{TP + FN}
$$
Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм (рис. \ref{fig:precision_recall}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.2]{precision_recall.png}
	\caption{Иллюстрация метрик precision и recall}
	\label{fig:precision_recall}
\end{figure}

Именно введение precision не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision --- способность отличать этот класс от других классов. Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.

Существует несколько различных способов объединить precision и recall в агрегированный критерий качества. F-мера (в общем случае $F_{\beta}$) --- среднее гармоническое precision и recall:
$$
F_{\beta} = \dfrac{(1 + \beta^2) \cdot precision \cdot recall}{\beta^2 \cdot precision + recall},
$$
где $\beta$ --- параметр, определяющий вес точности в метрике.

Одним из способов оценить модель в целом, не привязываясь к конкретному порогу, является AUC-ROC (или ROC AUC) --- площадь (Area Under Curve) под кривой ошибок (Receiver Operating Characteristic curve). Данная кривая представляет из себя линию от $(0,0)$ до $(1,1)$ в координатах True Positive Rate $(TPR)$ и False Positive Rate $(FPR)$
$$
TPR = \dfrac{TP}{TP+FN}, \quad FPR = \dfrac{FP}{FP+TN}.
$$
$TPR$ нам уже известна --- это полнота, а $FPR$ показывает, какую долю из объектов negative класса алгоритм предсказал неверно. В идеальном случае, когда классификатор не делает ошибок $(FPR = 0, TPR = 1)$ мы получим площадь под кривой, равную единице; в противном случае, когда классификатор случайно выдает вероятности классов, AUC-ROC будет стремиться к 0.5, так как классификатор будет выдавать одинаковое количество $TP$ и $FP$.

Каждая точка на графике соответствует выбору некоторого порога. Площадь под кривой в данном случае показывает качество алгоритма (больше --- лучше), кроме этого, важной является крутизна самой кривой --- мы хотим максимизировать $TPR$, минимизируя $FPR$, а значит, наша кривая в идеале должна стремиться к точке $(0,1)$.

Критерий AUC-ROC устойчив к несбалансированным классам и может быть интерпретирован как вероятность того, что случайно выбранный positive объект будет проранжирован классификатором выше (будет иметь более высокую вероятность быть positive), чем случайно выбранный negative объект.

Таким образом при анализе метрик необходимо ориентироваться на следующие критерии:
\begin{itemize}
  \item  в случае многоклассовой классификации нужно внимательно следить за метриками каждого из классов и следовать логике решения задачи, а не оптимизации метрики;
  \item  в случае неравных классов нужно подбирать баланс классов для обучения и метрику, которая будет корректно отражать качество классификации;
  \item выбор метрики нужно делать с фокусом на предметную область, предварительно обрабатывая данные и, возможно, сегментируя;
\end{itemize}

\subsection{Проблема переобучения}

Минимизацию эмпирического риска следует применять с известной долей осторожнсти. Если минимум функционала $Q(a, X^l)$ достигается на алгоритме $a$, то это ещё не гарантирует, что $a$ будет хорошо приближать целевую зависимость на произвольной контрольной выборке $X^k = (x'_i, y'_i)_{i=1}^k$.

Когда качество работы алгоритма на новых объектах, не вошедших в состав обучения, оказывается существенно хуже, чем на обучающей выборке, говорят об эффекте переобучения (overtraining) или переподгонки (overfitting). При решении практических задач с этим явлением приходится сталкиваться очень часто (рис. \ref{fig:overfitting}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.8]{overfitting.png}
	\caption{Пример переобучения нейронной сети}
	\label{fig:overfitting}
\end{figure}

Легко представить себе метод, который минимизирует эмпирический риск до нуля, но при этом абсолютно не способен обучаться. Получив обучающую выборку $X^l$, он запоминает её и строит алгоритм, который сравнивает предъявляемый объект $x$ с обучающими объектами $x_i$ из $X^l$. В случае совпадения $x = x_i$ алгоритм выдаёт правильный ответ $y_i$. Иначе выдаётся произвольный ответ. Эмпирический риск принимает наименьшее возможное значение, равное нулю. Однако этот алгоритм не способен восстановить зависимость вне материала обучения. Отсюда вывод: для успешного обучения необходимо не только запоминать, но и обобщать.

Обобщающая способность (generalization ability) метода $\mu$ характеризуется величиной $Q(\mu(X^l), X^k)$ при условии, что выборки $X^l$ и $X^k$ являются представительными. Для формализации понятия "представительная выборка" обычно принимается стандартное предположение, что выборки $X^l$ и $X^k$ --- простые, полученные из одного и того же неизвестного вероятностного распределения на множестве $X$.

Метод обучения $\mu$ называется состоятельным, если при заданных достаточно малых значениях $\varepsilon$ и $\eta$ справедливо неравенство

\begin{equation}
P_{X^l, X^k} \big\{ Q(\mu(X^l), X^k  > \varepsilon \big\} < \eta.
\label{eq:estimate}
\end{equation}
Параметр $\varepsilon$ называется точностью, параметр $(1 - \eta)$ --- надёжностью.

Получение оценок вида (\ref{eq:estimate}) является фундаментальной проблемой статистической теории обучения. Первые оценки были получены в конце 60-х годов В. Н. Вапником и А. Я. Червоненкисом. В настоящее время статистическая  теория развивается очень активно, однако для многих практически интересных случаев оценки обобщающей способности либо неизвестны, либо сильно завышены.

Эмпирические оценки обобщающей способности применяются в тех случаях,
когда не удаётся воспользоваться теоретическими.


Пусть дана выборка $X^L = (x_i, y_i)_{i=1}^L$. Разобьём её $N$ различными способами на две непересекающиеся подвыборки --- обучающую $X_n^l$ длины $l$ и контрольную $X_n^k$ длины $k = L - l$. Для каждого разбиения $n = 1,\ldots,N$ построим алгоритм $a_n = \mu(X_n^l)$ и вычислим значение $Q_n = Q(a_n, X_n^k)$. Среднее арифметическое значений $Q_n$ по всем разбиениям называется оценкой скользящего контроля (cross validation, CV):

$$
CV(\mu, X^L) =  \dfrac{1}{N} \sum_{i=1}^{N} Q(\mu(X_n^l), X_n^k).
$$

Возможны различные варианты скользящего контроля, отличающиеся способами разбиения выборки $X^L$. В простейшем варианте разбиения генерируются случайным образом, число $N$ берётся в диапазоне от 20 до 100. Стандартом считается методика $(t \times q)$-кратного скользящего контроля,
когда выборка случайным образом разбивается на $q$ блоков равной (или почти равной) длины, каждый блок по очереди становится контрольной выборкой, а объединение всех остальных блоков --- обучающей. Выборка $X^L$ по-разному $t$ раз разбивается на $q$ блоков. Итого получается $N = tq$ разбиений. Данная методика даёт более точные
оценки за счёт того, что все объекты ровно по $t$ раз встречаются в контроле.

Недостатками скользящего контроля являются: вычислительная неэффективность, высокая дисперсия, неполное использование имеющихся данных для обучения из-за сокращения длины обучающей выборки с $L$ до $l$.


\newpage
\section{ПОСТАНОВКА ЗАДАЧИ}

\subsection{Естественная постановка}

\subsection{Математическая постановка}

Пусть задано некоторое множество объектов $X = X_L \cup X_T $, где 
$X_L$ --- обучающая выборка, 
$X_T$ --- тестовая выборка, 
$Y$ --- множество допустимых ответов. Считаем, что существует некоторая целевая функция $g: X \rightarrow Y$, значения которой известны только на множестве $X_L$. Пусть данные распределены в соответствии с некоторым неизвестным распределением $P(x,y) = P(x) P(y|x)$, при этом задана некоторая функция потерь
$$
R(g(x), y) = 
\begin{cases} 
\phantom{>}0, & y = g(x), \\
> 0, & y \neq g(x).
\end{cases}
$$

В соответствии с принципом минимизации эмпирического риска нам надо минимизировать функцию потерь, то есть найти такую решающую функцию $g(x)$, которая в среднем будет приводить к наименьшей погрешности. Формально, требуется решить следующую задачу минимизации
$$
g(x) = \operatorname*{argmin}_{f: X \rightarrow Y} E_{X,Y} R(f(x), y).
$$

Для задачи фильтрации нежелательных данных множество $Y$ состоит из двух элементов $\{0, 1\}$, где $0$ и $1$ желательные и нежелательные данные соответственно. В силу грубости методов дискретных вычислений, на практике обычно используется $Y = R[0, 1]$, а результат работы классификатора $y' = g(x)$ отноcится к нужному классу с заданной пороговой вероятностью $\alpha$, минимизирующей ошибку первого и второго рода.


От момента получения сообщения до момента принятия решения о его типе, вся информация из письма проходит через несколько этапов обработки:

\begin{enumerate}
\item Предобработка.
\item Векторизация.
\item Классификация.
\end{enumerate}


\newpage
\section{ПРЕДОБРАБОТКА ДАННЫХ}

\subsection{Струкртура письма}

Содержимое письма очень сильно отличается от того, что видит пользователь в веб интерфейсе (рис. \ref{fig:web_eml}). Оно содержит очень много служебных заголовков, которые не несут никакого смысла для анализа (рис. \ref{fig:raw_eml}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml.jpg}
	\caption{Письмо в веб интерфейсе}
	\label{fig:web_eml}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{eml_raw.jpg}
	\caption{Сырое письмо}
	\label{fig:raw_eml}
\end{figure}

В первую очередь требуется валидировать ту инфрмацию, которую видит пользователь, поэтому для нас представляют интерес только заголовки subject (тема письма) и body (содержимое письма). При этом body делится на несколько частей (партов). Каждый парт может иметь абсолютно любой тип: текст, изображения, pdf, docx, html, calenar, итд. Каждый из этих типов нуждается в индивидуальной обработке. Для определения типа используется вложенный заголовок Content-Type.

Поскольку письмо имеет сильно неоднородную структуру (служебные заголовки, вложеные документы различных форматов) и при этом одно слово может быть записано множеством разных способов (разный шрифт, кодировка, регистр итд), но при этом иметь тот же смысл, то применяется множество различных методов предобработки.

\subsection{Извлечение данных}

\subsubsection{Текстовый формат}
Для извлечения информации из документов имеющих текстовый формат, таких как docx, html, calendar используются собственные специализированные парсеры написанные на C++. Они производят декодирование и ивлекают только нужную информацию, удаляя из текста тэги и служебные символы. Пример html страницы изображен на (рис. \ref{fig:html})

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{html.jpg}
	\caption{Пример DOM дерева HTML}
	\label{fig:html}
\end{figure}

\subsubsection{Изображения и PDF}

Поскольку изображения и PDF не являются текстовыми форматами, то для извлечения текста необходимо использовать машинное обучение. Так как извлечения текста из многих сырых изображений имеет низкое качество, то было разработано две модели на языке Python с использованием фреймворка PyTorch. 

Первая модель отвечает за разметку и сегментацию изображения. Благодяря ей улучшается качество распознавания и увеличивается производительность, за счет того, что мы не пытаемся извлечь текст из тех фрагментов изображения, где его нет (рис. \ref{fig:segment}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{segmentation.png}
	\caption{Пример сегментации изображения}
	\label{fig:segment}
\end{figure}

Вторая модель реализована на основе полносвязной нейронной сети, которая возвращает вектор вероятностей по заданному фрагменту изображения. С её помощью извлекается весь текст из изображения (рис. \ref{fig:fcnn_img}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{fcnn_img.jpg}
	\caption{Архитектура полносвязной нейронной сети для изображений}
	\label{fig:fcnn_img}
\end{figure}

Для обработки PDF используется известная библиотека poppler. Она конвектирует PDF в несколько изображения, которые далее отправляются в модели сегментации и извлечения текста.

\subsection{Конкатенация и удаление стоп слов}

После извлечения текста из всех документов производится конкатенация всех его частей с заданными разделителями и декодирование в заданную кодировку. Затем приведение к нижнему регистру, удаление лишних пробелов, отступов. 

Текст часто содержит много символов, которые не несут смысловой нагрузки для общего смысла (два пробела, абзацный отступ), а также стоп слова (stop words).
Стоп слова --- это слова, которые не добавляют особого смысла предложению. К стоп словам относят знаки пунктуации, местоимения и предлоги. Часто спамеры используют их для зашумления текстов с целью скрыть спам контент сообщения. Так как их можно спокойно игнорировать, не жертвуя смыслом предложения, то в задачах классификации часто прибегают к их удалению из исходного сообщения.

\subsection{Нормализация}

Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Используя разные алгоритмы лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме.


Стемминг --- это грубый эвристический процесс, который отрезает "лишнее" от корня слов, часто это приводит к потере словообразовательных суффиксов. Основная проблема, возникающая при использовании стеммера --- это обработка слов, которые при образовании разных грамматических форм меняют не только окончание, но и основу слова. Например, существительное "кошка" в винительном и родительном падеже множественного числа имеет форму "кошек". Из-за таких беглых гласных стеммер должен либо игнорировать подобные формы, усекая "кошки" до "кошк" и теряя часть форм слова, либо усекать слово до безусловно неизменяющейся основы, получая "кош", что впоследствии может привести к полной потере контекста. Чтобы минимизировать негативные последствия слишком агрессивного усечения слов стеммером, необходимо выполнять стемминг искомого ключевого слова, а затем сравнивать результат с выходом стеммера для каждого из слов в обрабатываемом тексте. Но даже в этом случае буду встречаться совпадения стемов для совершенно несвязанных слов.


Лемматизация --- это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме (лемме). Однако он применяет упрощенный анализ слов, не учитывая контекст. Это приводит к неоднозначностям при определении части речи. Например, лемматизация слов в словосочетании "мы роем яму" даст для второго слова два варианта лемматизации: существительное рой и глагол рыть. Эта неоднозначность не может быть разрешена без привлечения морфологического анализатора.

Как правило лемматизация дает наиболее точные результаты и именно этот подход используется в работе.


\newpage
\section{ВЕКТОРИЗАЦИЯ ДАННЫХ}

Современные алгоримы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо построить отображение текста в векторное пространство. Это называется извлечением признаков. Рассмотрим несколько подходов для построения данного отображения.

\subsection{Мешок слов}

Модель мешока слов (BOW) --- это упрощенное представления текстовой информации, используемое в задачах обработки естественных языков и поиска информации. В этой модели текст представляется в виде мешка (мультимножества) его слов или словосочетаний в случае комбинаций термов, игнорируя грамматику и в некоторых случаях даже порядок слов, но сохраняя множественность. Каждому такому терму (слову или словосочетанию) ставится в соответствие некоторое число. В этом случае текст определяется вектором $x=(w_1, ..., w_N)^T$, где $N$ - размерность из конечного словаря $X_L$ состоящего из уникальных термов обучающей выборки (рис. \ref{fig:bow_ex}).

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{bow_ex.jpg}
	\caption{Векторизация при помощи мешка слов}
	\label{fig:bow_ex}
\end{figure}

Возможны следующие варинаты определения $w_i$
\begin{itemize}
\item Булевский вес: $\begin{cases} 1, & \mbox{если элемент присутствует в письме} \\ 0, & \mbox{если элемент не присутствует в письме}  \end{cases}$
\item Количество вхождений i-го терма в тексте: $w_i = n_i$
\item Частота терма: $w_i = \dfrac{n_i}{\sum_{j=1}^{N} n_j}$
\end{itemize}
В данной работе для определения $w_i$ взят булевский вес.


\subsection{Word2Vec}

Основной проблемой BOW является потеря контекста между словами. Поскольку в естественном языке перестановка даже двух слов предложения  может полностью изменить его смысл, то данный подход к классификации может иметь низкую точность.

Word2Vec иструмент векториции текста с учетом контекстной связи между словами. В основе алгоритма лежат такие методы как huffman binary tree, skip-gram. Основной проблемой Word2Vec является поиск контекста для редких слов.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{skip_gram.png}
	\caption{Принцип работы skip-gram модели}
	\label{fig:skip_gram}
\end{figure}

Цель обучения модели word2Vec это поиск skip-gram (рис. \ref{fig:skip_gram}), то есть нахождение представления слов, которые полезны для предсказания окружающих слов в письме. Более формально: учитывая последовательность обучающих слов $w_1, w_2, w_3, ..., w_N$, требуется максимизировать среднюю логарифмическую вероятность

$$
\dfrac{1}{N}\sum_{i=1}^{N}\sum_{-c \leqslant j \leqslant c, j \neq 0} \ln p(w_{i+j}|w_i) \rightarrow \max,
$$
где $c$ --- размер обучающего контекста для слова $w_i$. Вероятность $p(w_O|w_I)$ нахождения слова $w_O$ в контексте со словом $w_I$ определяется через фукцию softmax

\begin{equation}
p(w_O|w_I) = \dfrac{\exp({\vec{u}_{w_O}\cdot\vec{v}_{w_I}})}{\sum_{i=1}^{N} \exp({\vec{u}_{i} \cdot \vec{v}_{w_I}})},
\label{eq:softmax}
\end{equation}
где $\vec{v}_{w_I}$ --- некий контекстный вектор для слова $w_I$, $\vec{u}_{w_O}$ --- word2vec представление слова $w_O$.

Поскольку стоимость вычисления функции softmax пропорциональна $O(N)$, которое на практике является очень большим (порядка $10^6$-$10^9$), что вызывает очень много вычислительных затрат и времени, то обычно вместо (\ref{eq:softmax}), используют иерархический softmax (\ref{eq:hierarchical_softmax}). В контексте языковых моделей нейронных сетей он был впервые представлен Морином и Бенжио [..]. Основное преимущество заключается в том, что вместо оценки $N$ выходных узлов в нейронной сети для получения
распределения вероятностей, можно оценить только около $\log_2 N$ узлов.

Идея оптимизации заключается в том, что на основе словаря текста строится двоичное дерево. В каждом листе дерева закодированно слово. Обозначим расстояние от вершины (root) до слова $w$ как $L(w)$. Узел дерева под номером $j$ на пути от вершины до слова $w$ как $n(w, j)$, при этом $n(w, 1) = $ root и $n(w, L(w)) = w$. Пусть $n_l(w,j)$ --- левый потомок для узла $n(w,j)$. Тогда выражение для вычисления вероятности $p(w_O|w_I)$ нахождения слова $w_O$ в контексте с $w_I$ имеет вид:
\begin{equation}
p(w_O|w_I) = \prod\limits_{j=1}^{L(w)-1} \sigma \Big(\delta_{n(w,j+1), n_l(w,j)} \vec{u}_{n(w,j)} \cdot \vec{v}_{w_I} \Big),
\label{eq:hierarchical_softmax}
\end{equation}
где $\sigma(x) = 1 / (1 + e^{-x})$, $\delta_{i,j}$ --- символ Кронекера.

Структура дерева, используемая иерархическим softmax, оказывает значительное влияние на производительность. Мних и Хинтон исследовали ряд методов построения древовидной структуры и влияние как на время обучения, так и на точность получаемой модели [...]. В этой работе используется двоичное
дерево Хаффмана (рис. \ref{fig:huffman}), так как оно присваивает короткие коды частым словам, что приводит к более быстрому обучению.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.9]{huffman.jpg}
	\caption{Бинарное дерево Хаффмана}
	\label{fig:huffman}
\end{figure}

Натренированная модель word2vec может улавливать некоторые семантические и синтаксические свойства слов (рис. \ref{fig:word2vec}), несмотря на то, что в модель явно не  заложено никакой семантики. Слово "мужчина" (man) относится к слову женщина (woman), также, как слово "дядя"(uncle) к слову "тётя"(aunt). Для человека это естественно и понятно, но в других ситуациях моделям добиться такого же соотношения векторов можно только с помощью специальных ухищрений.

\begin{figure}[h!]
	\center
	\includegraphics[scale=1.1]{word2vec.jpg}
	\caption{Семантическая близость слов в word2vec модели}
	\label{fig:word2vec}
\end{figure}

\subsection{Fast Text}

FastText --- это расширение Word2Vec, предложенное Facebook в 2016 году. Вместо ввода отдельных слов в нейронную сеть, FastText разбивает слова на несколько n-грамм (подслов). Например, триграммы для слова "apple"  ---  это "app", "ppl" и "ple" (без учета начала и конца границ слов). Вектор для слова "apple" образуется при помощи суммы всех n-грамм. После обучения нейронной сети у нас будут эмбединги слов для всех n-грамм из обучающего набора данных.

С помощью данного подхода алгоритм становится более чувствительным к редким словам, так как весьма вероятно, что некоторые из их n-грамм также присутствуют в других словах. Для обучения модели FastText требуется больше времени, но она работает лучше, чем Word2Vec, и позволяет правильно представлять редкие слова.


\newpage
\section{КЛАССИФИКАЦИЯ ДАННЫХ}

После векторизации текста мы должны построить преобразование из множества признаков во множество классифицируемых объектов $g: X \rightarrow Y$

\subsection{Логистическая регрессия}

Пусть $X$ --- пространство объектов, $Y = \{-1, 1 \}$ --- множество допустимых ответов. Объекты описываются $n$ числовыми признакам $f_j: X \rightarrow \mathbb{R}^n, j = 1,\ldots,n$. Вектор $\vec{x} = (x_1, \ldots, x_n) \in \mathbb{R}^n$, где $x_j = f_j(\vec{x})$, называется признаковым описанием объекта $\vec{x}$.

Если определить дискриминантную функцию  как скалярное произведение вектора $\vec{x}$ и вектора параметров $\vec{w} \in \mathbb{R}^n$, то получается линейный классификатор
\begin{equation}
a(\vec{x}, \vec{w}) = \sigma(\vec{w} \cdot \vec{x} - w_0) = \sigma \left( \sum_{j=1}^n x_j f_j(\vec{x}) - w_0\right).
\label{eq:lin_clf}
\end{equation}
Уравнение $(\vec{w} \cdot \vec{x}) = 0$ задаёт гиперплоскость, разделяющую классы в пространстве $\mathbb{R}^n$. Если вектор $\vec{x}$ находится по одну сторону гиперплоскости с её направляющим вектором $\vec{w}$, то объект $\vec{x}$ относится к классу $+1$, иначе --- к классу $-1$. 

Параметр $w_0$ иногда опускают. Иногда полагают, что среди признаков есть константа, $f_j(x) = -1$, и тогда роль свободного коэффициента $w_0$ играет параметр $w_j$.

Устройство нервной клетки и модель МакКаллока-Питтса. Линейный классификатор или персептрон является простейшей математической моделью нервной клетки --- нейрона (рис. \ref{fig:nerve_cell}). Нейрон имеет множество разветвлённых отростков --- дендритов, и одно длинное тонкое волокно --- аксон, на конце которого находятся синапсы, примыкающие к дендритам других нервных клеток. Нервная клетка может находиться в двух состояниях: обычном и возбуждённом. Клетка возбуждается, когда
в ней накапливается достаточное количество положительных зарядов. В возбуждённом состоянии клетка генерирует электрический импульс величиной около 100 мВ и длительностью около 1 мс, который проходит по аксону до синапсов. Синапс при приходе импульса выделяет вещество, способствующее проникновению положительных зарядов внутрь соседней клетки, примыкающей к данному синапсу. Синапсы имеют разную способность концентрировать это вещество, причём некоторые даже препятствуют его выделению --- они называются тормозящими. После возбуждения клетки наступает период релаксации --- некоторое время она не способна генерировать новые импульсы.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.75]{nerve_cell.jpg}
	\caption{Структура нервной клетки}
	\label{fig:nerve_cell}
\end{figure}

Нервную клетку можно рассматривать как устройство, которое на каждом такте своей работы принимает заряды величиной величиной $x_j = f_j(\vec{x})$ от n входов --- синапсов, примыкающих к её дендритам. Поступающие заряды складываются с весами $w_j$. Если вес положительный, то $j$-й синапс возбуждающий, если отрицательный, то тормозящий. Если суммарный заряд превышает порог активации $w_0$, то нейрон возбуждается и выдаёт на выходе $+1$, иначе выдается $-1$.

Функцию $\sigma(z)$, преобразующую значение суммарного импульса в выходное значение нейрона, называют функцией активации. В общем случае это не обязательно пороговая функция.

Таким образом, линейный классификатор (\ref{eq:lin_clf}) является математической моделью нейрона. Эту модель предложили в 1943 году МакКаллок и Питтс [52].

\subsubsection{Описание работы алгоритма}

Метод логистической регрессии основан на довольно сильных вероятностных предположениях, которые имеют сразу несколько интересных последствий. Во-первых, линейный алгоритм классификации оказывается оптимальным байесовским
классификатором. Во-вторых, однозначно определяется функция потерь. В-третьих,
возникает интересная дополнительная возможность наряду с классификацией объекта получать численные оценки вероятности его принадлежности каждому из классов.

В нормальном дискриминантном анализе доказывается, что если плотности классов нормальны и имеют равные матрицы ковариации, то оптимальный байесовский классификатор линеен. Покажем, что классификатор остается линейным при менее жестких предположениях.

Пусть классов два, $Y = \{-1,+1\}$, объекты описываются $n$ числовыми признаками $f_j : X \to \mathbb{R}^n, j = 1, \ldots,n$. Будем полагать $X = \mathbb{R}^n$, отождествляя объекты с их признаковыми описаниями: $\vec{x} = (f_1(x), \ldots, f_n(x))$.

Примем следующие гипотезы:

1. Множество прецедентов $X \times Y$ является вероятностным пространством. Выборка прецедентов $X^l = (\vec{x}_i, y_i)^l_{i=1}$ получена случайно и независимо согласно вероятностному распределению с плотностью $p(x,y) = P_y p_y(x) = P(y|x)p(x)$, где $P_y$ --- априорные вероятности, $p_y(x)$ --- функции правдоподобия, $P(y|x)$ --- апостериорные вероятности классов $y \in Y$ .

Плотность распределения $p(x)$, $x \in \mathbb{R}^n$ называется экспонентной, если $p(x) = \exp(c(\delta) \langle \theta, x\rangle + b(\delta, \theta) + d(x, \delta)$, где параметр $\theta \in \mathbb{R}^n$ называется сдвигом, параметр $\delta$ называется разбросом, $b, c, d$ --- произвольные числовые функции. Класс экспонентных распределений очень широк. К нему относятся многие непрерывные и дискретные распределения: равномерное, нормальное, гипергеометрическое, пуассоновское, биномиальное, Г-распределение, и другие.

2.  Если функции правдоподобия классов $p_y(x)$ принадлежат экспонентному семейству плотностей, то они имеют равные значения параметров $d$ и $\delta$, но отличаются значениями параметра сдвига $\theta_y$.

Оптимальный байесовский классификатор имеет вид 
$$
a(x) = \operatorname*{argmax}_{y \in Y} \lambda_y P(y|x),
$$
где $\lambda_y$ — штраф за ошибку на объектах класса $y$.
В случае двух классов
$$
a(x) = \operatorname*{sign}(\lambda_+ P(+1|x) - \lambda_-P(-1|x)) = \operatorname*{sign} \Big( \dfrac{P(+1|x) }{P(-1|x) } - \dfrac{\lambda_-}{\lambda_+} \Big).
$$
Если справедливы гипотезы 1, 2 и среди признаков $f_1(x), \ldots , f_n(x)$ есть константа, то:

\begin{itemize}
\item  Байесовский классификатор является линейным: 
$$
a(x) = \operatorname*{sign} ( (\vec{w} \cdot \vec{x}) - w_0),
$$
где $w_0 = \ln(\lambda_-/\lambda_+)$, а вектор $w$ не зависит от штрафов $\lambda_-, \lambda_+$

\item Апостериорная вероятность принадлежности произвольного объекта $x \in X$ классу $y \in \{-1, +1\}$ может быть вычислена по значению дискриминантной функции: 
$$
P(y|x) = \sigma ((\vec{w} \cdot \vec{x}) y),
$$
где $ \sigma(z) = \dfrac{1}{1+ e^{-z}}$ --- сигмоидная функция

\end{itemize}

Рассмотрим отношение апостериорных вероятностей классов
и воспользуемся тем, что $p_y(\vec{x})$ --- экспонентные плотности с параметрами $\theta$ и $\delta$

\begin{align*}
& \dfrac{P(+1|\vec{x})}{P(-1|\vec{x})} = \dfrac{P_{+} p_{+}(\vec{x})}{P_{-} p_{-}(\vec{x})} = \\
& = \exp \Big( (c_{+}(\delta) \vec{\theta}_{+} - c_{-}(\delta) \vec{\theta}_{-}) \cdot \vec{x} + b_{+}(\delta, \theta_{+}) - b_{-}(\delta, \vec{\theta}_{-}) + \ln\frac{P_{+}}{P_{-}} \Big) = \\
& = \exp( \vec{w} \cdot \vec{x} + c).
\end{align*}

Здесь вектор $w$ не зависит от $x$ и является вектором свободных коэффициентов при признаках. Все слагаемые под экспонентой, не зависящие от $x$, можно считать аддитивной добавкой к коэффициенту при константном признаке. Поскольку свободные коэффициенты настраиваются по обучающей выборке, вычислять эту аддитивную добавку нет никакого смысла, и её можно включить в $(\vec{w} \cdot \vec{x})$. Следовательно
$$
\dfrac{P(+1|\vec{x})}{P(-1|\vec{x})} = e^{\vec{w} \cdot \vec{x}},
$$

Используя формулу полной вероятности $P(-1|x) + P(+1|x) = 1$, нетрудно выразить апостериорные вероятности $P(-1|x)$ и $P(+1|x)$ через скалярное произведение $(\vec{w} \cdot \vec{x})$

$$
P(+1|x) = \sigma(+, \vec{w} \cdot \vec{x}),
\quad
P(-1|x) = \sigma(-, \vec{w} \cdot \vec{x}).
$$
Объединяя эти два равенства в одно, получаем исходное выражение
$$
P(y|x) = \sigma((\vec{w} \cdot \vec{x})y).
$$

Таким образом y разделяющая поверхность в Байесовском решающем правиле определяется уравнением $\lambda - P(-1|x) = \lambda + P(+1|x)$, которое равносильно $(\vec{w} \cdot \vec{x}) - \ln \frac{\lambda_{-}}{\lambda_{+}} = 0$, следовательно, разделяющая поверхность линейна.

Для настройки вектора весов $w$ по обучающей выборке $X^l$ будем максимизировать логарифм правдоподобия выборки

$$
L(w, X^l) = \ln \prod\limits_{i=1}^l p(x_i, y_i)\rightarrow \max_{w}.
$$

Согласно определению условной вероятности, $p(x,y) = P(y|x)p(x)$, где плотности распределения объектов $p(x)$ не зависят от вектора параметров $w$. Апостериорные вероятности выражаются через линейную дискриминантную функцию: $P(y|x) = \sigma((\vec{w} \cdot \vec{x})y)$. Таким образом

$$
L(w, X^l) =  \sum_{i=1}^{n} \ln \sigma((\vec{w} \cdot \vec{x})y) + c \rightarrow \max_{w}.
$$

Максимизация правдоподобия $L(w, X^l)$ эквивалентна минимизации функционала $\tilde{Q}(w, X^l)$, гладко аппроксимирующего эмпирический риск
$$
\tilde{Q}(w, X^l) = \sum_{i=1}^{n} \ln (1 + \exp(-(\vec{w} \cdot \vec{x_i})y_i) ) \rightarrow \min_{w}.
$$

Таким образом, логистическая функция потерь $Z(M)= \ln (1 + e^{-M})$ является следствием экспонентности классов и принципа максимума правдоподобия.

Запишем градиент функционала $\tilde{Q}(w)$, воспользовавшись выражением для производной сигмоидной функции $\sigma'(z) = \sigma(z)(1 - \sigma(z)) = \sigma(z)\sigma(-z)$,
и получим логистическое правило обновления весов для градиентного шага в методе стохастического градиента
$$
\vec{w} := \vec{w} + \eta y_i \vec{x_i} \sigma(-(\vec{w} \cdot \vec{x_i})y_i),
$$
где $(\vec{x}_i, y_i)$ --- предъявляемый прецедент, $\eta$ --- темп обучения.

\subsubsection{Результаты расчетов}

Согласно статье [twitter threshold p. 4.6] была произведена разметка уникальных точек по бинам и вычеслена оптимальная пороговая точность $\alpha = 0.75$, которая обеспечивает оптимальный pressision и recall для нашей модели и минимизует дисперсию ошибки.

Для BOW и Fast Text эмбедингов мы имеем следующие метрики классификации:
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
               & precision & recall \\ \hline
     BOW       & 0.91143 & 0.99961 \\ \hline
     Fast Text & 0.95523 & 0.89164  \\ \hline
  \end{tabular}
\end{center}

\subsection{Искусственная нейронная сеть}

\subsubsection{Вычислительные возможности нейронных сетей}

Человеку и высшим животным буквально на каждом шагу приходится распознавать, принимать решения и обучаться. Нейросетевой подход возник из стремления
понять, каким образом мозг решает столь сложные задачи, и реализовать эти принципы в автоматических устройствах. Пока искусственные нейронные сети (artificial neural networks, ANN) являются лишь предельно упрощёнными аналогами естественных нейронных сетей. Нервные системы животных и человека гораздо сложнее тех устройств, которые можно создать с помощью современных технологий. Однако для успешного решения многих практических задач оказалось вполне достаточно "подсмотреть" лишь общие принципы функционирования нервной системы. Некоторые разновидности ANN представляют собой математические модели, имеющие лишь отдалённое сходство с нейрофизиологией, что отнюдь не препятствует их практическому применению.

Итак, отдельно взятый нейрон вида (\ref{eq:lin_clf}) позволяет реализовать линейный классификатор или линейную регрессию. При решении практических задач линейность
оказывается чрезмерно сильным ограничением. На ограниченность персептрона указывали Минский и Пайперт в своей знаменитой книге "Персептроны" [...].

Следующие факты показывают, что любую функцию можно аппроксимировать с помощью нейронной сети.

\begin{enumerate}
\item Любая булева функция представима в виде двухслойной сети. Это тривиальное следствие нейронной представимости функций И, ИЛИ, НЕ и представимости
произвольной булевой функции в виде дизъюнктивной нормальной формы [...].
\item Из простых геометрических соображений вытекает, что двухслойная сеть
с пороговыми функциями активации позволяет выделить произвольный выпуклый
многогранник в $n$-мерном пространстве признаков. Трёхслойная сеть позволяет вычислить любую конечную линейную комбинацию характеристических функций выпуклых многогранников, следовательно, аппроксимировать любые области с непрерывной границей, включая невыпуклые и даже неодносвязные, а также аппроксимировать любые непрерывные функции.
\item В 1900 году Гильберт предложил список из 23 нерешённых задач, которые,
по его мнению, должны были стать вызовом для математиков XX века. Тринадцатая проблема заключалась в следующем: возможно ли произвольную непрерывную
функцию n аргументов представить в виде суперпозиции функций меньшего числа
аргументов. Ответ был дан А. Н. Колмогоровым в [14]. Теорема Колмогорова утверждает, что любая непрерывная функция $n$ аргументов на единичном кубе $[0, 1]^n$ представима в виде суперпозиции непрерывных функций одного аргумента и операции сложения:
$$
f(x_1, \ldots, x_n) = \sum_{k=1}^{2n+1} h_k \left(\sum_{i=1}^{n} \varphi_{i,k}(x_i) \right),
$$
где $h_k$, $\varphi_{i,k}$ --- непрерывные функции, причём $\varphi_{i,k}$ не зависят от выбора $f$. Нетрудно видеть, что записанное здесь выражение имеет структуру нейронной сети с одним скрытым слоем из $2n + 1$ нейронов. Таким образом, двух слоёв уже
достаточно, чтобы вычислять произвольные непрерывные функции, и не приближённо, а точно. К сожалению, представление Колмогорова не является персептроном:
функции $\varphi_{i,k}$ не линейны, а функции $h_k$ зависят от $f$, и в общем случае не являются
дифференцируемыми.

\item Известна классическая теорема Вейерштрасса о том, что любую непрерывную функцию $n$ переменных можно равномерно приблизить полиномом с любой степенью точности. Более общая теорема Стоуна утверждает, что любую непрерывную
функцию на произвольном компакте $X$ можно приблизить не только многочленом
от исходных переменных, но и многочленом от любого конечного набора функций $F$,
разделяющих точки [.....].
\end{enumerate}

Таким образом, нейронные сети являются универсальными аппроксиматорами
функций. Возможности сети возрастают с увеличением числа слоёв и числа нейронов в них. Двух-трёх слоёв, как правило, достаточно для решения подавляющего
большинства практических задач классификации, регрессии и прогнозирования.

\subsubsection{Метод обратного распространения ошибки}

Рассмотрим многослойную сеть, в который каждый нейрон предыдущего слоя
связан со всеми нейронами последующего слоя (рис. \ref{fig:fcnn_ex}). Такая сеть называется полносвязной. Для большей общности положим $X = \mathbb{R}^n, Y = \mathbb{R}^M$.

Пусть выходной слой состоит из $M$ нейронов с функциями активации $\sigma_m$ и выходами $a^m, m=1,\ldots,M$. Перед ним находится скрытый слой из $H$ нейронов с функциями активации $\sigma_h$ и выходами $u^h, h=1,\ldots,H$.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.55]{fcnn_ex.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:fcnn_ex}
\end{figure}

Веса синаптических связей между $h$-м нейроном скрытого слоя и $m$-м нейроном выходного слоя будем обозначать через $w_{h,m}$. Перед этим слоем может находиться либо входной слой признаков (называемый также распределительным слоем), либо ещё один скрытый слой с выходами $v^j, j = 1,\ldots, J$ и синаптическими весами $w_{j,h}$. В общем случае число слоёв может быть произвольным. Если сеть двухслойная, то $v^j$
есть просто $j$-й признак: $v^j(x) = f_j(x) = x^j$ и, $J = n$. Обозначим через $w$ вектор всех синаптических весов сети. 

Выходные значения сети на объекте $x_i$ вычисляются как суперпозиция:

$$
a^m(x_i) = \sigma_m \left( \sum_{h=0}^{H} w_{h,m} u^h(x_i) \right),
\quad
u^h(x_i) = \sigma_h \left( \sum_{j=0}^{J} w_{j,h} u^j(x_i) \right).
$$

Зафиксируем объект $x_i$ и запишем функционал среднеквадратичной ошибки
(для других функций потерь выкладки могут быть проделаны аналогично):

$$
Q(w) = \frac{1}{2} \sum_{m=1}^{M} (a^m(x_i) - y_i^m)^2.
$$

В дальнейшем нам понадобятся частные производные $Q$ по выходам нейронов.
Выпишем их сначала для выходного слоя
\begin{equation}
\dfrac{\partial Q}{\partial a^m} = a^m(x_i) - y_i^m = \varepsilon_i^m,
\label{eq:partial_q}
\end{equation}
Из данного выражения видно, что частная производная $Q$ по $a^m$ равна величине ошибки $\varepsilon_i^m$ на объекте $x_i$. Теперь выпишем частные производные по выходам скрытого слоя
$$
\dfrac{\partial Q}{\partial u^h} = \sum_{m=1}^{M} (a^m(x_i) - y_i^m) \sigma'_m w_{h,m} = \sum_{m=1}^{M} \varepsilon_i^m \sigma'_m w_{h,m} = \varepsilon_i^h.
$$

Эту величину, по аналогии с $\varepsilon_i^m$, будем называть ошибкой сети на скрытом слое и обозначать через $\varepsilon_i^h$. Через $\sigma'_m$ обозначена производная функции активации,
вычисленная при том же значении аргумента, что и в (\ref{eq:partial_q}). Если используется сигмоидная функция активации, то для эффективного вычисления производной можно
воспользоваться формулой
$$
\sigma'_m = \sigma_m (1 - \sigma_m) = a^m(x_i) (1 - a^m(x_i)).
$$

Стоит заметить, что $\varepsilon_i^h$ вычисляется по $\varepsilon_i^m$, если запустить сеть "задом наперёд", подав на выходы нейронов скрытого слоя значения $\varepsilon_i^m \sigma'_m$, а результат $\varepsilon_i^h$ получив на входе. При этом входной вектор скалярно умножается на вектор весов $w_{hm}$, находящихся справа от нейрона, а не слева, как при прямом вычислении (рис. \ref{fig:backpropagation}), отсюда и название алгоритма --- обратное распространение ошибок.

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.7]{backpropagation.jpg}
	\caption{Пример полносвязной нейронной сети}
	\label{fig:backpropagation}
\end{figure}

Имея частные производные по $a^m$ и $u^h$, можно выписать градиент $Q$ по весам:
\begin{align*}
 & \dfrac{\partial Q}{\partial w_{h,m}} = \dfrac{\partial Q}{\partial a^m} \dfrac{\partial a^m}{\partial w_{h,m}} = \varepsilon_i^m \sigma'_m u^h(x_i), \quad m=1,\ldots,M, \quad h=0,\ldots,H;\\
 & \dfrac{\partial Q}{\partial w_{j,h}} = \dfrac{\partial Q}{\partial u^h} \dfrac{\partial u^h}{\partial w_{j,h}} = \varepsilon_i^h \sigma'_h u^j(x_i), \quad h=1,\ldots,H, \quad j=0,\ldots,J;
\end{align*}
и так далее для каждого слоя. Если слоёв больше двух, то остальные частные производные вычисляются аналогично --- обратным ходом по слоям сети справа налево. 

Теперь мы обладаем всем необходимым, чтобы полностью выписать алгоритм обратного распространения


К достоинствам метода обратного распространения можно отнести следующие свойства

\begin{itemize}
  \item   Достаточно высокая эффективность. В случае двухслойной сети прямой ход, обратный ход и вычисления градиента требуют порядка $O(Hn+HM)$ операций.
  \item   Через каждый нейрон проходит информация только о связных с ним нейронах. Поэтому back-propagation легко реализуется на вычислительных устройствах с параллельной архитектурой
  \item  Высокая степень общности. Алгоритм легко записать для произвольного числа слоёв, произвольной размерности выходов и выходов, произвольной функции потерь и произвольных функций активации, возможно, различных у разных нейронов. Кроме того, back-propagation можно применять совместно с различными градиентными методами оптимизации: методом скорейшего спуска, сопряженных градиентов, Ньютона-Рафсона и др.
\end{itemize}

Недостатками метода обратного распространения являются следующие факты
\begin{itemize}
  \item Метод наследует известные недостатки градиентной настройки весов в однослойном персептроне. Здесь также возникают проблемы медленной сходимости или расходимости, "застревания" в локальных минимумах функционала $Q$, переобучения и паралича. Причём парализоваться могут отдельные связи, нейроны, или вся сеть в целом.
  \item Приходится заранее фиксировать число нейронов скрытого слоя $H$. В то же время, это критичный параметр сложности сети, от которого может существенно зависеть качество обучения и скорость сходимости.
\end{itemize}


\subsubsection{Выбор параметров и результаты расчетов}

Fully convolutional neural network для нашей задачи имеет 3 слоя. На первых двух используется функция активации $ReLU$, на последнем $Sigmoid$. На каждом слое производится регуляризация данных. В нашем случае нейронную сеть можно определить формулой:

$$
g(x) = h_2 \left(\sum_{k=0}^{n_2} w''_k h_1\left(\sum_{j=0}^{n_1} w'_j h_0\left( \sum_{i=0}^{n_0} w_i x_i \right)\right)\right),
$$

где $h_i$ --- функция активации для соответствующего слоя. Для нахождения весов $\{w_i\}$, $\{w'_j\}$, $\{w''_k\}$ на этапе обучения модели используется метод Адама.

Для BOW и Fast Text эмбедингов мы имеем следующие метрики классификации:
\begin{center}
  \begin{tabular}{ | c | c | c |}
    \hline
               & precision & recall \\ \hline
     BOW       & 0.93604 & 0.95643 \\ \hline
     Fast Text & 0.99931 & 0.91263 \\ \hline
  \end{tabular}
\end{center}

\begin{figure}[H]
	\center
	\includegraphics[scale=1.5]{train_loss.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

\begin{figure}[H]
	\center
	\includegraphics[scale=1.5]{train_precision.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

\begin{figure}[H]
	\center
	\includegraphics[scale=1.5]{test_loss.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

\begin{figure}[H]
	\center
	\includegraphics[scale=1.5]{test_precision.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

На рис. \ref{fig:dist_prob} отображенно распределние вероятностей классификатора с шагом $0.1$ на реальных потоковых письмах пользователей. Метрики $ham$ и $spam$ отображают колличество писем, отмеченных классификатором как "не спам" и "спам" соответственно.

\begin{figure}[H]
	\center
	\includegraphics[scale=0.65]{dist_prob.jpg}
	\caption{Распределение вероятностей классификатора}
	\label{fig:dist_prob}
\end{figure}

\subsection{Сравнение моделей}

Сравним метрики классификатора, построенного на логистической регрессии при помощи векторизации BOW (old clf) и классификатора, постоенного на полносвязной нейросети при помощи векторизации word2vec (new clf).

На рис. \ref{fig:old_vs_new_fp} отображено колличество жалоб на старый и новый классификатор за сутки. Из него видно, что на новый классификатор пользователи жалуются почти в 2.5 раза меньше.

\begin{figure}[H]
	\center
	\includegraphics[scale=0.65]{old_vs_new_fp.jpg}
	\caption{Сравнение жалоб на старый и новый классификатор}
	\label{fig:old_vs_new_fp}
\end{figure}

На рис. \ref{fig:old_vs_new_ps} отображено колличество писем, которые старый и новый классификатор отметили как "спам" за сутки. Анализируя графики на рис. \ref{fig:old_vs_new_fp} и рис. \ref{fig:old_vs_new_ps} можно увидеть, что новый классификатор работает существенно лучше старого, за счет того, что он блокирует в 1.5 раза больше писем, при этом на его решения поступает в 2.5 раза меньше жалоб.

\begin{figure}[H]
	\center
	\includegraphics[scale=0.65]{old_vs_new_ps.jpg}
	\caption{Сравнение блокировок старого и нового классификатора}
	\label{fig:old_vs_new_ps}
\end{figure}

На рис. \ref{fig:old_vs_new_status} отображено пересечение статусов старого и нового классификатора за сутки. Метрика $spam2ham$ отображает количество писем, которые старый классификатор отметил как $spam$, а новый как $ham$ (не спам). Метрика $ham2spam$ наоборот, показывает сколько писем старый классификатор отметил как $ham$, а новый отправил в $spam$. В метрике $spam2spam$ оба классификатора сочли письмо спамом. Из данного графика видно, что классификаторы имеют достаточно сильное перечение (около 60\%), но при этом отличаются в части блокировок, что вносит ключевой эффект на количество жалоб на рис. \ref{fig:old_vs_new_fp}.

\begin{figure}[H]
	\center
	\includegraphics[scale=0.75]{old_vs_new_status.jpg}
	\caption{Сравнение статусов старого и нового классификатора}
	\label{fig:old_vs_new_status}
\end{figure}

На рис. \ref{fig:is_not_spam_yeas_2_yeas} и рис. \ref{fig:is_spam_yeas_2_yeas} отображено общее количество жалоб пользователей на письма попавашие в спам по ошибке и наборот, на спам, который попал во входящие за этот и прошлый год. Из графиков видно, что количество жалоб существенно снизилось относительно прошлого года, в том числе благодаря новому классификатору.
\begin{figure}[H]
	\center
	\includegraphics[scale=0.7]{is_not_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб "это не спам" за этот и прошлый год}
	\label{fig:is_not_spam_yeas_2_yeas}
\end{figure}

\begin{figure}[H]
	\center
	\includegraphics[scale=0.65, width=16cm]{is_spam_yeas_2_yeas.jpg}
	\caption{Количество жалоб "это спам" за этот и прошлый год}
	\label{fig:is_spam_yeas_2_yeas}
\end{figure}


\newpage
\section{ПОСТРОЕНИЕ МИКРОСЕРВИСНОЙ АРХИТЕКТУРЫ}

\subsection{Обзор библиотек}

Поскольку от сервисов требуется высокая производительность, то для его написания выбран язык C++ (stl17, grpc, boost), как один из самых производительных современных языков. Для анализа данных и обучения fcnn модели использовался язык Python3 и фреймврок pyTorch за счет высокой эффективности и возможности проведения параллельных вычислений, как на cpu, так и на gpu ядрах машины.

Отказоустойчивость микросервисов обеспечивается за счет их развертки в kubernetes (k8s) кластере, так как при падении любого пода по какой-либо причине запросы равномерно сбалансируются по оставшимся живым подам, до тех пор, пока кластер самостоятельно не вернется к прежнему состоянию. Внутри него можно настроить: автоматическую балансировку нагрузки с помощью постоянного мониторинга сведений о производительности и используемых ресурсах (autoscaling) и грамотное размещение подов внутри кластера по дата центрам (affinity).

\subsection{Построение архитектуры приложения}

Так как сервис должен работать под высокими нагрузками важно обеспечить архитектуру, при которой выход из строя одной компоненты не приведет к деградации всей системы. Реализована следующая клиент-серверная архитектура (рис. \ref{fig:app_arch}). Antispam daemon (mrasd) парсит входящие сообщение и извлекает оттуда текст, изображения, файлы.  Поскольку нежелательные данные часто содержатся внутри вложенных изображений и документов, то из них также необходимо извлечь текст. Для этого через отложенную redis очередь документы оправляются в OCR сервис, который извлекает текст и сохраняет результат в redis cache.

В связи с тем, что с большой вероятностью письмо может быть дубликатом (например в случае ddos атаки или оффлайн перепроверки), то чтобы не нагрузать лишний раз OCR сервис, производится первичная проверка redis cache на наличие уже обработанных данных по заданному хэшу документа.

После полного извлечения текста сервис mrasd производит все этапы предобработки текста (приведение к одному регистру, удаление стоп слов, нормализация), а затем отправляет текст в сервис mlapi по протоколу grpc для векторизации текста при помощи fast text и дальнейшего получения предсказания fcnn модели по котому принимается решение о "нежелательности"  входящего сообщения.

Предложенная архитектура хороша тем, что при выходе из строя OCR сериса, одного (или нескольких) инстансов redis сluster, не деградирует вся система в целом.
 
\begin{figure}[h!]
	\center
	\includegraphics[scale=0.25]{deploy.jpg}
	\caption{Архитектура приложения}
	\label{fig:app_arch}
\end{figure}

\subsection{Результаты работы приложения}

\begin{figure}[h!]
	\center
	\includegraphics[scale=0.6]{timings.png}
	\caption{Среднее время обработки письма}
	\label{fig:03}
\end{figure}


\begin{figure}[h!]
	\center
	\includegraphics[scale=0.5]{processed_messages.png}
	\caption{Среднее количество запросов в минуту с одной из ферм}
	\label{fig:04}
\end{figure}


\newpage
\section-{ЗАКЛЮЧЕНИЕ}

В данной работе приведены результаты, полученные в ходе обучения модели на реальных потоковых данных пользователей. По приведенным данным можно сделать заключение о том, что $FCNN$ модель на основе $Fast Text$ эмбедингов имеет наивысшую точность классификации, по сравнению с методами классической логистической регрессии и $FCNN$ модели на основе мешка слов.


Приведена высокопризводительная отказоустойчивая микросервисная архитектура, которая выдерживает в среднем более $10^6$ запросов в минуту. При этом деградация конкретной компоненты, машины или датацентра не приводит к полной неработоспособности приложения.


\newpage
\begin{thebibliography}{17}
\bibitem{Makkar2021} 
Aaisha Makkar, Uttam Ghosh, Pradip Kumar Sharma.
2021. \emph{Artificial Intelligence and Edge Computing-enabled
	Web Spam Detection for Next Generation IoT
	Applications} // IEEE Sensors Journal

\bibitem{Taylor2020}
Taylor O.E., Ezekiel P.S.
2020. \emph{A Model to Detect Spam Email Using Support Vector Classifier and Random Forest Classifier} //
International Journal of Computer Science and Mathematical Theory

\bibitem{Garg2021}
Pranjul Garg, Nancy Girdhar.
2021. \emph{A systematic review on spam filtering techniques based on
natural language processing framework} // 2021 11th International Conference on Cloud Computing, Data Science \& Engineering (Confluence 2021)

\bibitem{Parmar2020}
Nandan Parmar, Ankita Sharma, Harshita Jain, Amol K. Kadam.
2020. \emph{Email Spam Detection using Nave Bayes and Particle Swarm Optimization} // IJIRT

\bibitem{Mohammad2020}
Rami Mustafa A. Mohammad.
2020. \emph{A lifelong spam emails 	classification model} //
Applied Computing and Informatics

\end{thebibliography}

\newpage
\section-{ПРИЛОЖЕНИЕ А}

\end{document}